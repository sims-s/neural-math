{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics to look at:\n",
    "* Metrics over time\n",
    "* Comparison of Hyperparameters\n",
    "* Metrics at the beginning of training:\n",
    "    * Why does scaling embeddings screw things up so much? Even when it's just the initialization --> must be an issue at the beginning of training, could be something interesting to look into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_colwidth', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = []\n",
    "test_metric_list = []\n",
    "oos_metric_list = []\n",
    "loss_hist_list = []\n",
    "test_factor_df_list = []\n",
    "\n",
    "\n",
    "def find_metrics_in_dir(base_path):\n",
    "    for f in os.listdir(base_path):\n",
    "        if f in ['300s', '.gitignore', 'addition_baselines', 'addition_small_as_possible']: continue\n",
    "        print(f)\n",
    "        subdir_path = base_path + f + '/'\n",
    "        \n",
    "        if os.path.exists(subdir_path + 'checkpoints/'):\n",
    "            config_path = subdir_path + 'config.yaml'\n",
    "            metrics_path = subdir_path + 'metrics_test.json'\n",
    "            metrics_oos_path = subdir_path + 'metrics_oos.json'\n",
    "            loss_hist_path = subdir_path + 'loss_hist.csv'\n",
    "            \n",
    "            if not os.path.exists(metrics_path):\n",
    "                continue\n",
    "\n",
    "            config_list.append(load_yaml(config_path))\n",
    "            test_metric_list.append(load_json(metrics_path))\n",
    "            oos_metric_list.append(load_json(metrics_oos_path))\n",
    "            loss_hist_list.append(pd.read_csv(loss_hist_path))\n",
    "            \n",
    "            test_factor_df_list.append(pd.read_csv(subdir_path + 'factor_df_test.csv'))\n",
    "            \n",
    "        elif os.path.isdir(subdir_path) and not f=='checkpoints':\n",
    "            find_metrics_in_dir(subdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPARAM_search\n",
      "baseline_10_enc_dec_layers\n",
      "baseline_12_enc_dec_layers\n",
      "baseline_16_enc_dec_layers\n",
      "baseline_24_enc_dec_layers\n",
      "baseline_2_enc_dec_layers\n",
      "baseline_4_enc_dec_layers\n",
      "baseline_8_enc_dec_layers\n",
      "baseline_base30\n",
      "baseline_base30_high_attn_init\n",
      "baseline_base30_no_relative_pe\n",
      "baseline_base30_repeat_pe\n",
      "baseline_base30_repeat_pe_qk_only\n",
      "baseline_base7\n",
      "baseline_base8\n",
      "baseline_base_210\n",
      "baseline_base_237\n",
      "baseline_base_7_rerun\n",
      "baseline_base_90\n",
      "baseline_embed_dim_256\n",
      "baseline_embed_dim_512\n",
      "baseline_embed_dim_64\n",
      "baseline_higher_dropout\n",
      "baseline_min_lr_scale\n",
      "baseline_norm_first\n",
      "baseline_no_extra_attn\n",
      "baseline_no_shared_embeddings\n",
      "baseline_scale_embeddings\n",
      "baseline_weight_decay\n",
      "baseline_weight_decay_larger\n",
      "baseline_weight_decay_larger_2\n",
      "baseline_weight_decay_larger_3\n",
      "baseline_xavier_init\n",
      "baseline_xavier_init_scale_embeddings\n",
      "baseline_xavier_init_scale_embeddings_init\n",
      "basline_batch_128\n",
      "basline_batch_256\n",
      "basline_batch_512\n",
      "basline_batch_512_3200_epoch\n",
      "basline_batch_512_6400_epoch\n",
      "basline_batch_512_800_epoch\n",
      "debugging_lossprop_sampling\n",
      "scaled_v0\n"
     ]
    }
   ],
   "source": [
    "find_metrics_in_dir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 38, 38, 38, 38)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config_list), len(test_metric_list), len(oos_metric_list), len(loss_hist_list), len(test_factor_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_config(config_item):\n",
    "    expanded = {}\n",
    "    expanded['base'] = config_item['data']['base']\n",
    "    expanded['train_data'] = config_item['data']['train_path']\n",
    "    expanded['train_batch_size'] = config_item['loader']['train']['batch_size']\n",
    "    for k, v in config_item['model_args'].items():\n",
    "        expanded[k] = v\n",
    "    if not 'embedding_initialization' in expanded:\n",
    "        expanded['embedding_initialization'] = 'normal'\n",
    "    expanded['optimizer'] = config_item['optimizer']['type']\n",
    "    for k, v in config_item['optimizer']['opt_args'].items():\n",
    "        expanded[k] = v\n",
    "    if not 'weight_decay' in expanded:\n",
    "        expanded['weight_decay'] = 0\n",
    "    expanded['gradient_accumulation_steps'] = config_item['optimizer']['gradient_accumulation_steps']\n",
    "#     handle all model args\n",
    "#     handle all opt args\n",
    "    try:\n",
    "        expanded['num_warmup_steps'] = config_item['scheduler']['n_warmup_steps']\n",
    "    except KeyError:\n",
    "        expanded['num_warmup_steps'] = config_item['scheduler']['scheduler_args']['num_warmup_steps']\n",
    "    expanded['nb_epochs'] = config_item['scheduler']['nb_epochs']\n",
    "    expanded['max_grad_norm'] = config_item['optimizer']['max_grad_norm']\n",
    "    \n",
    "    expanded['effective_train_batch_size'] = expanded['train_batch_size'] * expanded['gradient_accumulation_steps']\n",
    "    del expanded['train_batch_size']\n",
    "    del expanded['gradient_accumulation_steps']\n",
    "    \n",
    "    \n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [flatten_config(c) for c in config_list]\n",
    "config_df = pd.DataFrame.from_dict(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>train_data</th>\n",
       "      <th>attn_weight_xavier_init_constant</th>\n",
       "      <th>dim_feedforward</th>\n",
       "      <th>dropout</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>embedding_initialization</th>\n",
       "      <th>extra_positional_encoding_relative_decoder_mha</th>\n",
       "      <th>learn_positional_encoding</th>\n",
       "      <th>max_decode_size</th>\n",
       "      <th>...</th>\n",
       "      <th>scale_embeddings</th>\n",
       "      <th>scale_embeddings_at_init</th>\n",
       "      <th>shared_embeddings</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>num_warmup_steps</th>\n",
       "      <th>nb_epochs</th>\n",
       "      <th>max_grad_norm</th>\n",
       "      <th>effective_train_batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>237</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>256</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>512</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.10</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3000</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>3200</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12000</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^20.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1200</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    base                train_data  attn_weight_xavier_init_constant  \\\n",
       "0     30  data/train_data_2^16.npy                               0.5   \n",
       "1     30  data/train_data_2^16.npy                               0.5   \n",
       "2     30  data/train_data_2^16.npy                               0.5   \n",
       "3     30  data/train_data_2^16.npy                               0.5   \n",
       "4     30  data/train_data_2^16.npy                               0.5   \n",
       "5     30  data/train_data_2^16.npy                               0.5   \n",
       "6     30  data/train_data_2^16.npy                               0.5   \n",
       "7     30  data/train_data_2^16.npy                               1.0   \n",
       "8     30  data/train_data_2^16.npy                               0.5   \n",
       "9     30  data/train_data_2^16.npy                               0.5   \n",
       "10    30  data/train_data_2^16.npy                               0.5   \n",
       "11     7  data/train_data_2^16.npy                               0.5   \n",
       "12     8  data/train_data_2^16.npy                               0.5   \n",
       "13   210  data/train_data_2^16.npy                               0.5   \n",
       "14   237  data/train_data_2^16.npy                               0.5   \n",
       "15     7  data/train_data_2^16.npy                               0.5   \n",
       "16    90  data/train_data_2^16.npy                               0.5   \n",
       "17    30  data/train_data_2^16.npy                               0.5   \n",
       "18    30  data/train_data_2^16.npy                               0.5   \n",
       "19    30  data/train_data_2^16.npy                               0.5   \n",
       "20    30  data/train_data_2^16.npy                               0.5   \n",
       "21    30  data/train_data_2^16.npy                               0.5   \n",
       "22    30  data/train_data_2^16.npy                               0.5   \n",
       "23    30  data/train_data_2^16.npy                               0.5   \n",
       "24    30  data/train_data_2^16.npy                               0.5   \n",
       "25    30  data/train_data_2^16.npy                               0.5   \n",
       "26    30  data/train_data_2^16.npy                               0.5   \n",
       "27    30  data/train_data_2^16.npy                               0.5   \n",
       "28    30  data/train_data_2^16.npy                               0.5   \n",
       "29    30  data/train_data_2^16.npy                               0.5   \n",
       "30    30  data/train_data_2^16.npy                               0.5   \n",
       "31    30  data/train_data_2^16.npy                               0.5   \n",
       "32    30  data/train_data_2^16.npy                               0.5   \n",
       "33    30  data/train_data_2^16.npy                               0.5   \n",
       "34    30  data/train_data_2^16.npy                               0.5   \n",
       "35    30  data/train_data_2^16.npy                               0.5   \n",
       "36    30  data/train_data_2^16.npy                               0.5   \n",
       "37    30  data/train_data_2^20.npy                               0.5   \n",
       "\n",
       "    dim_feedforward  dropout  embed_dim embedding_initialization  \\\n",
       "0               512     0.05        128                   normal   \n",
       "1               512     0.05        128                   normal   \n",
       "2               512     0.05        128                   normal   \n",
       "3               512     0.05        128                   normal   \n",
       "4               512     0.05        128                   normal   \n",
       "5               512     0.05        128                   normal   \n",
       "6               512     0.05        128                   normal   \n",
       "7               512     0.05        128                   normal   \n",
       "8               512     0.05        128                   normal   \n",
       "9               512     0.05        128                   normal   \n",
       "10              512     0.05        128                   normal   \n",
       "11              512     0.05        128                   normal   \n",
       "12              512     0.05        128                   normal   \n",
       "13              512     0.05        128                   normal   \n",
       "14              512     0.05        128                   normal   \n",
       "15              512     0.05        128                   normal   \n",
       "16              512     0.05        128                   normal   \n",
       "17              512     0.05        256                   normal   \n",
       "18              512     0.05        512                   normal   \n",
       "19              512     0.05         64                   normal   \n",
       "20              512     0.10        128                   normal   \n",
       "21              512     0.05        128                   normal   \n",
       "22              512     0.05        128                   normal   \n",
       "23              512     0.05        128                   normal   \n",
       "24              512     0.05        128                   normal   \n",
       "25              512     0.05        128                   normal   \n",
       "26              512     0.05        128                   normal   \n",
       "27              512     0.05        128                   normal   \n",
       "28              512     0.05        128                   normal   \n",
       "29              512     0.05        128                   xavier   \n",
       "30              512     0.05        128                   xavier   \n",
       "31              512     0.05        128                   xavier   \n",
       "32              512     0.05        128                   normal   \n",
       "33              512     0.05        128                   normal   \n",
       "34              512     0.05        128                   normal   \n",
       "35              512     0.05        128                   normal   \n",
       "36              512     0.05        128                   normal   \n",
       "37              512     0.05        128                   xavier   \n",
       "\n",
       "    extra_positional_encoding_relative_decoder_mha  learn_positional_encoding  \\\n",
       "0                                             True                      False   \n",
       "1                                             True                      False   \n",
       "2                                             True                      False   \n",
       "3                                             True                      False   \n",
       "4                                             True                      False   \n",
       "5                                             True                      False   \n",
       "6                                             True                      False   \n",
       "7                                             True                      False   \n",
       "8                                             True                      False   \n",
       "9                                             True                      False   \n",
       "10                                            True                      False   \n",
       "11                                            True                      False   \n",
       "12                                            True                      False   \n",
       "13                                            True                      False   \n",
       "14                                            True                      False   \n",
       "15                                            True                      False   \n",
       "16                                            True                      False   \n",
       "17                                            True                      False   \n",
       "18                                            True                      False   \n",
       "19                                            True                      False   \n",
       "20                                            True                      False   \n",
       "21                                            True                      False   \n",
       "22                                           False                      False   \n",
       "23                                            True                      False   \n",
       "24                                            True                      False   \n",
       "25                                            True                      False   \n",
       "26                                            True                      False   \n",
       "27                                            True                      False   \n",
       "28                                            True                      False   \n",
       "29                                            True                      False   \n",
       "30                                            True                      False   \n",
       "31                                            True                      False   \n",
       "32                                            True                      False   \n",
       "33                                            True                      False   \n",
       "34                                            True                      False   \n",
       "35                                            True                      False   \n",
       "36                                            True                      False   \n",
       "37                                            True                      False   \n",
       "\n",
       "    max_decode_size  ...  scale_embeddings  scale_embeddings_at_init  \\\n",
       "0                64  ...             False                     False   \n",
       "1                64  ...             False                     False   \n",
       "2                64  ...             False                     False   \n",
       "3                64  ...             False                     False   \n",
       "4                64  ...             False                     False   \n",
       "5                64  ...             False                     False   \n",
       "6                64  ...             False                     False   \n",
       "7                64  ...             False                     False   \n",
       "8                64  ...             False                     False   \n",
       "9                64  ...             False                     False   \n",
       "10               64  ...             False                     False   \n",
       "11               64  ...             False                     False   \n",
       "12               64  ...             False                     False   \n",
       "13               64  ...             False                     False   \n",
       "14               64  ...             False                     False   \n",
       "15               64  ...             False                     False   \n",
       "16               64  ...             False                     False   \n",
       "17               64  ...             False                     False   \n",
       "18               64  ...             False                     False   \n",
       "19               64  ...             False                     False   \n",
       "20               64  ...             False                     False   \n",
       "21               64  ...             False                     False   \n",
       "22               64  ...             False                     False   \n",
       "23               64  ...             False                     False   \n",
       "24               64  ...              True                     False   \n",
       "25               64  ...             False                     False   \n",
       "26               64  ...             False                     False   \n",
       "27               64  ...             False                     False   \n",
       "28               64  ...             False                     False   \n",
       "29               64  ...             False                     False   \n",
       "30               64  ...              True                     False   \n",
       "31               64  ...              True                      True   \n",
       "32               64  ...             False                     False   \n",
       "33               64  ...             False                     False   \n",
       "34               64  ...             False                     False   \n",
       "35               64  ...             False                     False   \n",
       "36               64  ...             False                     False   \n",
       "37               64  ...             False                     False   \n",
       "\n",
       "    shared_embeddings  optimizer     lr  weight_decay  num_warmup_steps  \\\n",
       "0                True      AdamW  0.001          0.10              6000   \n",
       "1                True      AdamW  0.001          0.10              6000   \n",
       "2                True      AdamW  0.001          0.10              6000   \n",
       "3                True      AdamW  0.001          0.10              6000   \n",
       "4                True      AdamW  0.001          0.10              6000   \n",
       "5                True      AdamW  0.001          0.10              6000   \n",
       "6                True       adam  0.001          0.00             24000   \n",
       "7                True       adam  0.001          0.00             24000   \n",
       "8                True       adam  0.001          0.00             24000   \n",
       "9                True       adam  0.001          0.00             24000   \n",
       "10               True       adam  0.001          0.00             24000   \n",
       "11               True       adam  0.001          0.00             24000   \n",
       "12               True       adam  0.001          0.00             24000   \n",
       "13               True      AdamW  0.001          0.10             24000   \n",
       "14               True      AdamW  0.001          0.10             24000   \n",
       "15               True      AdamW  0.001          0.10             24000   \n",
       "16               True      AdamW  0.001          0.10             24000   \n",
       "17               True      AdamW  0.001          0.10              6000   \n",
       "18               True      AdamW  0.001          0.10              6000   \n",
       "19               True      AdamW  0.001          0.10              6000   \n",
       "20               True      AdamW  0.001          0.10              6000   \n",
       "21               True      AdamW  0.001          0.10             10000   \n",
       "22               True      AdamW  0.001          0.10             10000   \n",
       "23              False      AdamW  0.001          0.10              6000   \n",
       "24               True       adam  0.001          0.00             24000   \n",
       "25               True      AdamW  0.001          0.01             24000   \n",
       "26               True      AdamW  0.001          0.05             24000   \n",
       "27               True      AdamW  0.001          0.10             24000   \n",
       "28               True      AdamW  0.001          0.25             24000   \n",
       "29               True      AdamW  0.001          0.10              6000   \n",
       "30               True      AdamW  0.001          0.10              6000   \n",
       "31               True      AdamW  0.001          0.10              6000   \n",
       "32               True      AdamW  0.001          0.10             12000   \n",
       "33               True      AdamW  0.001          0.10              6000   \n",
       "34               True      AdamW  0.001          0.10              3000   \n",
       "35               True      AdamW  0.001          0.10             24000   \n",
       "36               True      AdamW  0.001          0.10             12000   \n",
       "37               True      AdamW  0.001          0.10              1200   \n",
       "\n",
       "    nb_epochs  max_grad_norm effective_train_batch_size  \n",
       "0         200              1                        256  \n",
       "1         200              1                        256  \n",
       "2         200              1                        256  \n",
       "3         200              1                        256  \n",
       "4         200              1                        256  \n",
       "5         200              1                        256  \n",
       "6         200              1                         64  \n",
       "7         200              1                         64  \n",
       "8         200              1                         64  \n",
       "9         200              1                         64  \n",
       "10        200              1                         64  \n",
       "11        200              1                         64  \n",
       "12        200              1                         64  \n",
       "13        200              1                         64  \n",
       "14        200              1                         64  \n",
       "15        200              1                         64  \n",
       "16        200              1                         64  \n",
       "17        200              1                        256  \n",
       "18        200              1                        256  \n",
       "19        200              1                        256  \n",
       "20        200              1                        256  \n",
       "21        200              1                         64  \n",
       "22        200              1                         64  \n",
       "23        200              1                        256  \n",
       "24        200              1                         64  \n",
       "25        200              1                         64  \n",
       "26        200              1                         64  \n",
       "27        200              1                         64  \n",
       "28        200              1                         64  \n",
       "29        200              1                        256  \n",
       "30        200              1                        256  \n",
       "31        200              1                        256  \n",
       "32        200              1                        128  \n",
       "33        200              1                        256  \n",
       "34        200              1                        512  \n",
       "35       3200              1                        512  \n",
       "36        800              1                        512  \n",
       "37        300              1                       2048  \n",
       "\n",
       "[38 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nice_metrics(metric_list, suffix = ''):\n",
    "    correct = pd.DataFrame.from_dict([l['correct'] for l in metric_list])\n",
    "    n_beams = pd.DataFrame.from_dict([l['meta']['n_beams'] for l in metric_list])\n",
    "    \n",
    "    def get_loss(metric_dict):\n",
    "        try:\n",
    "            return metric_dict['loss']\n",
    "        except KeyError:\n",
    "            return metric_dict['test_loss']\n",
    "        \n",
    "    loss_df = pd.DataFrame.from_dict([get_loss(l) for l in metric_list])\n",
    "    \n",
    "    n_beams.columns = ['n_beams']\n",
    "    loss_df.columns = ['loss']\n",
    "    to_return = [correct, n_beams, loss_df]\n",
    "    if suffix:\n",
    "        for tmp_df in to_return:\n",
    "            tmp_df.columns = [str(c) + f'_{suffix}' for c in tmp_df.columns]\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([config_df] + get_nice_metrics(test_metric_list, 'test') + get_nice_metrics(oos_metric_list, 'oos'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (merged['n_beams_test']==merged['n_beams_oos']).all()\n",
    "merged['n_beams'] = merged['n_beams_oos']\n",
    "merged.drop(['n_beams_test', 'n_beams_oos'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all confiuraiton columns that have no variantion b/c that's not super helpful\n",
    "drop_cols = []\n",
    "for c in list(config_df) + ['n_beams']:\n",
    "    if not c in merged: continue\n",
    "    if merged[c].nunique()==1:\n",
    "        drop_cols.append(c)\n",
    "metric_df = merged.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>train_data</th>\n",
       "      <th>attn_weight_xavier_init_constant</th>\n",
       "      <th>dropout</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>embedding_initialization</th>\n",
       "      <th>extra_positional_encoding_relative_decoder_mha</th>\n",
       "      <th>norm_first</th>\n",
       "      <th>num_decoder_layers</th>\n",
       "      <th>num_encoder_layers</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>num_warmup_steps</th>\n",
       "      <th>nb_epochs</th>\n",
       "      <th>effective_train_batch_size</th>\n",
       "      <th>correct_product_test</th>\n",
       "      <th>correct_factorization_test</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>correct_product_oos</th>\n",
       "      <th>correct_factorization_oos</th>\n",
       "      <th>loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.979356</td>\n",
       "      <td>0.861415</td>\n",
       "      <td>0.047529</td>\n",
       "      <td>0.933594</td>\n",
       "      <td>0.694824</td>\n",
       "      <td>0.119473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.974954</td>\n",
       "      <td>0.857468</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>0.677246</td>\n",
       "      <td>0.124622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.974803</td>\n",
       "      <td>0.857013</td>\n",
       "      <td>0.048752</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.595703</td>\n",
       "      <td>0.158729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.945507</td>\n",
       "      <td>0.561779</td>\n",
       "      <td>0.110729</td>\n",
       "      <td>0.806152</td>\n",
       "      <td>0.370117</td>\n",
       "      <td>0.174067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.962356</td>\n",
       "      <td>0.796752</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>0.770020</td>\n",
       "      <td>0.521973</td>\n",
       "      <td>0.151557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.979053</td>\n",
       "      <td>0.860049</td>\n",
       "      <td>0.047189</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.691406</td>\n",
       "      <td>0.123346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.959168</td>\n",
       "      <td>0.727838</td>\n",
       "      <td>0.070385</td>\n",
       "      <td>0.896973</td>\n",
       "      <td>0.516113</td>\n",
       "      <td>0.166403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.934730</td>\n",
       "      <td>0.658470</td>\n",
       "      <td>0.088125</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.448242</td>\n",
       "      <td>0.166683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.949909</td>\n",
       "      <td>0.659836</td>\n",
       "      <td>0.086440</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.185352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.948543</td>\n",
       "      <td>0.696418</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.896484</td>\n",
       "      <td>0.498535</td>\n",
       "      <td>0.144379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.960990</td>\n",
       "      <td>0.716302</td>\n",
       "      <td>0.073048</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>0.143515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874772</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.181037</td>\n",
       "      <td>0.643555</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.296095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.985580</td>\n",
       "      <td>0.398452</td>\n",
       "      <td>0.150913</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>0.116699</td>\n",
       "      <td>0.535876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.987553</td>\n",
       "      <td>0.906497</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.287109</td>\n",
       "      <td>0.211426</td>\n",
       "      <td>0.512774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>237</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.957498</td>\n",
       "      <td>0.853673</td>\n",
       "      <td>0.047474</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.509020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.913783</td>\n",
       "      <td>0.438373</td>\n",
       "      <td>0.124756</td>\n",
       "      <td>0.827637</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>0.163973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.985124</td>\n",
       "      <td>0.848057</td>\n",
       "      <td>0.042097</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.222875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>256</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.980419</td>\n",
       "      <td>0.887826</td>\n",
       "      <td>0.045192</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>0.656738</td>\n",
       "      <td>0.161693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>512</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.790861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.798695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.957650</td>\n",
       "      <td>0.668033</td>\n",
       "      <td>0.087711</td>\n",
       "      <td>0.887695</td>\n",
       "      <td>0.463867</td>\n",
       "      <td>0.150055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.966910</td>\n",
       "      <td>0.822860</td>\n",
       "      <td>0.051705</td>\n",
       "      <td>0.922852</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>0.117378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.978597</td>\n",
       "      <td>0.861263</td>\n",
       "      <td>0.040617</td>\n",
       "      <td>0.805664</td>\n",
       "      <td>0.633301</td>\n",
       "      <td>0.127682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.967517</td>\n",
       "      <td>0.835003</td>\n",
       "      <td>0.048632</td>\n",
       "      <td>0.895508</td>\n",
       "      <td>0.631348</td>\n",
       "      <td>0.118688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.980115</td>\n",
       "      <td>0.862174</td>\n",
       "      <td>0.045891</td>\n",
       "      <td>0.925293</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0.131770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.960231</td>\n",
       "      <td>0.716910</td>\n",
       "      <td>0.073398</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>0.522461</td>\n",
       "      <td>0.144273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.959927</td>\n",
       "      <td>0.761081</td>\n",
       "      <td>0.063798</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.530273</td>\n",
       "      <td>0.150084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.964784</td>\n",
       "      <td>0.826351</td>\n",
       "      <td>0.049212</td>\n",
       "      <td>0.900879</td>\n",
       "      <td>0.627930</td>\n",
       "      <td>0.134887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.971160</td>\n",
       "      <td>0.824833</td>\n",
       "      <td>0.050255</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>0.623535</td>\n",
       "      <td>0.125664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.968579</td>\n",
       "      <td>0.709624</td>\n",
       "      <td>0.073895</td>\n",
       "      <td>0.923828</td>\n",
       "      <td>0.521973</td>\n",
       "      <td>0.118576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>0.855798</td>\n",
       "      <td>0.046261</td>\n",
       "      <td>0.945801</td>\n",
       "      <td>0.697754</td>\n",
       "      <td>0.114236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.969186</td>\n",
       "      <td>0.850789</td>\n",
       "      <td>0.048823</td>\n",
       "      <td>0.905273</td>\n",
       "      <td>0.655273</td>\n",
       "      <td>0.128929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.976776</td>\n",
       "      <td>0.852307</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.903320</td>\n",
       "      <td>0.653320</td>\n",
       "      <td>0.126217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12000</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>0.970097</td>\n",
       "      <td>0.840164</td>\n",
       "      <td>0.047680</td>\n",
       "      <td>0.879883</td>\n",
       "      <td>0.642578</td>\n",
       "      <td>0.117346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.854736</td>\n",
       "      <td>0.045719</td>\n",
       "      <td>0.920898</td>\n",
       "      <td>0.666016</td>\n",
       "      <td>0.128519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3000</td>\n",
       "      <td>200</td>\n",
       "      <td>512</td>\n",
       "      <td>0.969945</td>\n",
       "      <td>0.833789</td>\n",
       "      <td>0.052237</td>\n",
       "      <td>0.878418</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.150475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>3200</td>\n",
       "      <td>512</td>\n",
       "      <td>0.987705</td>\n",
       "      <td>0.899666</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>0.907715</td>\n",
       "      <td>0.720703</td>\n",
       "      <td>0.143123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12000</td>\n",
       "      <td>800</td>\n",
       "      <td>512</td>\n",
       "      <td>0.976624</td>\n",
       "      <td>0.859745</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.901855</td>\n",
       "      <td>0.656738</td>\n",
       "      <td>0.140578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^20.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1200</td>\n",
       "      <td>300</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.984165</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>0.055534</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>0.628174</td>\n",
       "      <td>0.090952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    base                train_data  attn_weight_xavier_init_constant  dropout  \\\n",
       "0     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "1     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "2     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "3     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "4     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "5     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "6     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "7     30  data/train_data_2^16.npy                               1.0     0.05   \n",
       "8     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "9     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "10    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "11     7  data/train_data_2^16.npy                               0.5     0.05   \n",
       "12     8  data/train_data_2^16.npy                               0.5     0.05   \n",
       "13   210  data/train_data_2^16.npy                               0.5     0.05   \n",
       "14   237  data/train_data_2^16.npy                               0.5     0.05   \n",
       "15     7  data/train_data_2^16.npy                               0.5     0.05   \n",
       "16    90  data/train_data_2^16.npy                               0.5     0.05   \n",
       "17    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "18    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "19    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "20    30  data/train_data_2^16.npy                               0.5     0.10   \n",
       "21    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "22    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "23    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "24    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "25    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "26    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "27    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "28    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "29    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "30    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "31    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "32    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "33    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "34    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "35    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "36    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "37    30  data/train_data_2^20.npy                               0.5     0.05   \n",
       "\n",
       "    embed_dim embedding_initialization  \\\n",
       "0         128                   normal   \n",
       "1         128                   normal   \n",
       "2         128                   normal   \n",
       "3         128                   normal   \n",
       "4         128                   normal   \n",
       "5         128                   normal   \n",
       "6         128                   normal   \n",
       "7         128                   normal   \n",
       "8         128                   normal   \n",
       "9         128                   normal   \n",
       "10        128                   normal   \n",
       "11        128                   normal   \n",
       "12        128                   normal   \n",
       "13        128                   normal   \n",
       "14        128                   normal   \n",
       "15        128                   normal   \n",
       "16        128                   normal   \n",
       "17        256                   normal   \n",
       "18        512                   normal   \n",
       "19         64                   normal   \n",
       "20        128                   normal   \n",
       "21        128                   normal   \n",
       "22        128                   normal   \n",
       "23        128                   normal   \n",
       "24        128                   normal   \n",
       "25        128                   normal   \n",
       "26        128                   normal   \n",
       "27        128                   normal   \n",
       "28        128                   normal   \n",
       "29        128                   xavier   \n",
       "30        128                   xavier   \n",
       "31        128                   xavier   \n",
       "32        128                   normal   \n",
       "33        128                   normal   \n",
       "34        128                   normal   \n",
       "35        128                   normal   \n",
       "36        128                   normal   \n",
       "37        128                   xavier   \n",
       "\n",
       "    extra_positional_encoding_relative_decoder_mha  norm_first  \\\n",
       "0                                             True       False   \n",
       "1                                             True       False   \n",
       "2                                             True       False   \n",
       "3                                             True       False   \n",
       "4                                             True       False   \n",
       "5                                             True       False   \n",
       "6                                             True       False   \n",
       "7                                             True       False   \n",
       "8                                             True       False   \n",
       "9                                             True       False   \n",
       "10                                            True       False   \n",
       "11                                            True       False   \n",
       "12                                            True       False   \n",
       "13                                            True       False   \n",
       "14                                            True       False   \n",
       "15                                            True       False   \n",
       "16                                            True       False   \n",
       "17                                            True       False   \n",
       "18                                            True       False   \n",
       "19                                            True       False   \n",
       "20                                            True       False   \n",
       "21                                            True        True   \n",
       "22                                           False       False   \n",
       "23                                            True       False   \n",
       "24                                            True       False   \n",
       "25                                            True       False   \n",
       "26                                            True       False   \n",
       "27                                            True       False   \n",
       "28                                            True       False   \n",
       "29                                            True       False   \n",
       "30                                            True       False   \n",
       "31                                            True       False   \n",
       "32                                            True       False   \n",
       "33                                            True       False   \n",
       "34                                            True       False   \n",
       "35                                            True       False   \n",
       "36                                            True       False   \n",
       "37                                            True       False   \n",
       "\n",
       "    num_decoder_layers  num_encoder_layers  ...  weight_decay  \\\n",
       "0                   10                  10  ...          0.10   \n",
       "1                   12                  12  ...          0.10   \n",
       "2                   16                  16  ...          0.10   \n",
       "3                    2                   2  ...          0.10   \n",
       "4                    4                   4  ...          0.10   \n",
       "5                    8                   8  ...          0.10   \n",
       "6                    6                   6  ...          0.00   \n",
       "7                    6                   6  ...          0.00   \n",
       "8                    6                   6  ...          0.00   \n",
       "9                    6                   6  ...          0.00   \n",
       "10                   6                   6  ...          0.00   \n",
       "11                   6                   6  ...          0.00   \n",
       "12                   6                   6  ...          0.00   \n",
       "13                   6                   6  ...          0.10   \n",
       "14                   6                   6  ...          0.10   \n",
       "15                   6                   6  ...          0.10   \n",
       "16                   6                   6  ...          0.10   \n",
       "17                   6                   6  ...          0.10   \n",
       "18                   6                   6  ...          0.10   \n",
       "19                   6                   6  ...          0.10   \n",
       "20                   6                   6  ...          0.10   \n",
       "21                   6                   6  ...          0.10   \n",
       "22                   6                   6  ...          0.10   \n",
       "23                   6                   6  ...          0.10   \n",
       "24                   6                   6  ...          0.00   \n",
       "25                   6                   6  ...          0.01   \n",
       "26                   6                   6  ...          0.05   \n",
       "27                   6                   6  ...          0.10   \n",
       "28                   6                   6  ...          0.25   \n",
       "29                   6                   6  ...          0.10   \n",
       "30                   6                   6  ...          0.10   \n",
       "31                   6                   6  ...          0.10   \n",
       "32                   6                   6  ...          0.10   \n",
       "33                   6                   6  ...          0.10   \n",
       "34                   6                   6  ...          0.10   \n",
       "35                   6                   6  ...          0.10   \n",
       "36                   6                   6  ...          0.10   \n",
       "37                  10                  10  ...          0.10   \n",
       "\n",
       "    num_warmup_steps  nb_epochs  effective_train_batch_size  \\\n",
       "0               6000        200                         256   \n",
       "1               6000        200                         256   \n",
       "2               6000        200                         256   \n",
       "3               6000        200                         256   \n",
       "4               6000        200                         256   \n",
       "5               6000        200                         256   \n",
       "6              24000        200                          64   \n",
       "7              24000        200                          64   \n",
       "8              24000        200                          64   \n",
       "9              24000        200                          64   \n",
       "10             24000        200                          64   \n",
       "11             24000        200                          64   \n",
       "12             24000        200                          64   \n",
       "13             24000        200                          64   \n",
       "14             24000        200                          64   \n",
       "15             24000        200                          64   \n",
       "16             24000        200                          64   \n",
       "17              6000        200                         256   \n",
       "18              6000        200                         256   \n",
       "19              6000        200                         256   \n",
       "20              6000        200                         256   \n",
       "21             10000        200                          64   \n",
       "22             10000        200                          64   \n",
       "23              6000        200                         256   \n",
       "24             24000        200                          64   \n",
       "25             24000        200                          64   \n",
       "26             24000        200                          64   \n",
       "27             24000        200                          64   \n",
       "28             24000        200                          64   \n",
       "29              6000        200                         256   \n",
       "30              6000        200                         256   \n",
       "31              6000        200                         256   \n",
       "32             12000        200                         128   \n",
       "33              6000        200                         256   \n",
       "34              3000        200                         512   \n",
       "35             24000       3200                         512   \n",
       "36             12000        800                         512   \n",
       "37              1200        300                        2048   \n",
       "\n",
       "    correct_product_test  correct_factorization_test loss_test  \\\n",
       "0               0.979356                    0.861415  0.047529   \n",
       "1               0.974954                    0.857468  0.048018   \n",
       "2               0.974803                    0.857013  0.048752   \n",
       "3               0.945507                    0.561779  0.110729   \n",
       "4               0.962356                    0.796752  0.057410   \n",
       "5               0.979053                    0.860049  0.047189   \n",
       "6               0.959168                    0.727838  0.070385   \n",
       "7               0.934730                    0.658470  0.088125   \n",
       "8               0.949909                    0.659836  0.086440   \n",
       "9               0.948543                    0.696418  0.079208   \n",
       "10              0.960990                    0.716302  0.073048   \n",
       "11              0.874772                    0.259259  0.181037   \n",
       "12              0.985580                    0.398452  0.150913   \n",
       "13              0.987553                    0.906497  0.032362   \n",
       "14              0.957498                    0.853673  0.047474   \n",
       "15              0.913783                    0.438373  0.124756   \n",
       "16              0.985124                    0.848057  0.042097   \n",
       "17              0.980419                    0.887826  0.045192   \n",
       "18              0.000152                    0.000152  0.790861   \n",
       "19              0.957650                    0.668033  0.087711   \n",
       "20              0.966910                    0.822860  0.051705   \n",
       "21              0.978597                    0.861263  0.040617   \n",
       "22              0.967517                    0.835003  0.048632   \n",
       "23              0.980115                    0.862174  0.045891   \n",
       "24              0.960231                    0.716910  0.073398   \n",
       "25              0.959927                    0.761081  0.063798   \n",
       "26              0.964784                    0.826351  0.049212   \n",
       "27              0.971160                    0.824833  0.050255   \n",
       "28              0.968579                    0.709624  0.073895   \n",
       "29              0.978901                    0.855798  0.046261   \n",
       "30              0.969186                    0.850789  0.048823   \n",
       "31              0.976776                    0.852307  0.046058   \n",
       "32              0.970097                    0.840164  0.047680   \n",
       "33              0.978142                    0.854736  0.045719   \n",
       "34              0.969945                    0.833789  0.052237   \n",
       "35              0.987705                    0.899666  0.044012   \n",
       "36              0.976624                    0.859745  0.044800   \n",
       "37              0.984165                    0.776742  0.055534   \n",
       "\n",
       "    correct_product_oos  correct_factorization_oos  loss_oos  \n",
       "0              0.933594                   0.694824  0.119473  \n",
       "1              0.912598                   0.677246  0.124622  \n",
       "2              0.757812                   0.595703  0.158729  \n",
       "3              0.806152                   0.370117  0.174067  \n",
       "4              0.770020                   0.521973  0.151557  \n",
       "5              0.943848                   0.691406  0.123346  \n",
       "6              0.896973                   0.516113  0.166403  \n",
       "7              0.859375                   0.448242  0.166683  \n",
       "8              0.812500                   0.414062  0.185352  \n",
       "9              0.896484                   0.498535  0.144379  \n",
       "10             0.917969                   0.523926  0.143515  \n",
       "11             0.643555                   0.177734  0.296095  \n",
       "12             0.394531                   0.116699  0.535876  \n",
       "13             0.287109                   0.211426  0.512774  \n",
       "14             0.164062                   0.106445  0.509020  \n",
       "15             0.827637                   0.275391  0.163973  \n",
       "16             0.587891                   0.341797  0.222875  \n",
       "17             0.869629                   0.656738  0.161693  \n",
       "18             0.000000                   0.000000  0.798695  \n",
       "19             0.887695                   0.463867  0.150055  \n",
       "20             0.922852                   0.640137  0.117378  \n",
       "21             0.805664                   0.633301  0.127682  \n",
       "22             0.895508                   0.631348  0.118688  \n",
       "23             0.925293                   0.682617  0.131770  \n",
       "24             0.922363                   0.522461  0.144273  \n",
       "25             0.880859                   0.530273  0.150084  \n",
       "26             0.900879                   0.627930  0.134887  \n",
       "27             0.909180                   0.623535  0.125664  \n",
       "28             0.923828                   0.521973  0.118576  \n",
       "29             0.945801                   0.697754  0.114236  \n",
       "30             0.905273                   0.655273  0.128929  \n",
       "31             0.903320                   0.653320  0.126217  \n",
       "32             0.879883                   0.642578  0.117346  \n",
       "33             0.920898                   0.666016  0.128519  \n",
       "34             0.878418                   0.616211  0.150475  \n",
       "35             0.907715                   0.720703  0.143123  \n",
       "36             0.901855                   0.656738  0.140578  \n",
       "37             0.979492                   0.628174  0.090952  \n",
       "\n",
       "[38 rows x 27 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['correct_product', 'correct_factorization', 'loss']\n",
    "splits = ['test', 'oos']\n",
    "metrics_full = [f'{metric}_{split}' for split in splits for metric in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['correct_product_test',\n",
       " 'correct_factorization_test',\n",
       " 'loss_test',\n",
       " 'correct_product_oos',\n",
       " 'correct_factorization_oos',\n",
       " 'loss_oos']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>train_data</th>\n",
       "      <th>attn_weight_xavier_init_constant</th>\n",
       "      <th>dropout</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>embedding_initialization</th>\n",
       "      <th>extra_positional_encoding_relative_decoder_mha</th>\n",
       "      <th>norm_first</th>\n",
       "      <th>num_decoder_layers</th>\n",
       "      <th>num_encoder_layers</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>num_warmup_steps</th>\n",
       "      <th>nb_epochs</th>\n",
       "      <th>effective_train_batch_size</th>\n",
       "      <th>correct_product_test</th>\n",
       "      <th>correct_factorization_test</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>correct_product_oos</th>\n",
       "      <th>correct_factorization_oos</th>\n",
       "      <th>loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.979356</td>\n",
       "      <td>0.861415</td>\n",
       "      <td>0.047529</td>\n",
       "      <td>0.933594</td>\n",
       "      <td>0.694824</td>\n",
       "      <td>0.119473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.974954</td>\n",
       "      <td>0.857468</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>0.677246</td>\n",
       "      <td>0.124622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.974803</td>\n",
       "      <td>0.857013</td>\n",
       "      <td>0.048752</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.595703</td>\n",
       "      <td>0.158729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.945507</td>\n",
       "      <td>0.561779</td>\n",
       "      <td>0.110729</td>\n",
       "      <td>0.806152</td>\n",
       "      <td>0.370117</td>\n",
       "      <td>0.174067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.962356</td>\n",
       "      <td>0.796752</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>0.770020</td>\n",
       "      <td>0.521973</td>\n",
       "      <td>0.151557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.979053</td>\n",
       "      <td>0.860049</td>\n",
       "      <td>0.047189</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.691406</td>\n",
       "      <td>0.123346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.959168</td>\n",
       "      <td>0.727838</td>\n",
       "      <td>0.070385</td>\n",
       "      <td>0.896973</td>\n",
       "      <td>0.516113</td>\n",
       "      <td>0.166403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.934730</td>\n",
       "      <td>0.658470</td>\n",
       "      <td>0.088125</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.448242</td>\n",
       "      <td>0.166683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.949909</td>\n",
       "      <td>0.659836</td>\n",
       "      <td>0.086440</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.185352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.948543</td>\n",
       "      <td>0.696418</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.896484</td>\n",
       "      <td>0.498535</td>\n",
       "      <td>0.144379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.960990</td>\n",
       "      <td>0.716302</td>\n",
       "      <td>0.073048</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>0.143515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.874772</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.181037</td>\n",
       "      <td>0.643555</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>0.296095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.985580</td>\n",
       "      <td>0.398452</td>\n",
       "      <td>0.150913</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>0.116699</td>\n",
       "      <td>0.535876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.987553</td>\n",
       "      <td>0.906497</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.287109</td>\n",
       "      <td>0.211426</td>\n",
       "      <td>0.512774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>237</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.957498</td>\n",
       "      <td>0.853673</td>\n",
       "      <td>0.047474</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>0.509020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.913783</td>\n",
       "      <td>0.438373</td>\n",
       "      <td>0.124756</td>\n",
       "      <td>0.827637</td>\n",
       "      <td>0.275391</td>\n",
       "      <td>0.163973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.985124</td>\n",
       "      <td>0.848057</td>\n",
       "      <td>0.042097</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>0.222875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>256</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.980419</td>\n",
       "      <td>0.887826</td>\n",
       "      <td>0.045192</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>0.656738</td>\n",
       "      <td>0.161693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>512</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.790861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.798695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.957650</td>\n",
       "      <td>0.668033</td>\n",
       "      <td>0.087711</td>\n",
       "      <td>0.887695</td>\n",
       "      <td>0.463867</td>\n",
       "      <td>0.150055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.966910</td>\n",
       "      <td>0.822860</td>\n",
       "      <td>0.051705</td>\n",
       "      <td>0.922852</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>0.117378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.978597</td>\n",
       "      <td>0.861263</td>\n",
       "      <td>0.040617</td>\n",
       "      <td>0.805664</td>\n",
       "      <td>0.633301</td>\n",
       "      <td>0.127682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.967517</td>\n",
       "      <td>0.835003</td>\n",
       "      <td>0.048632</td>\n",
       "      <td>0.895508</td>\n",
       "      <td>0.631348</td>\n",
       "      <td>0.118688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.980115</td>\n",
       "      <td>0.862174</td>\n",
       "      <td>0.045891</td>\n",
       "      <td>0.925293</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0.131770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.960231</td>\n",
       "      <td>0.716910</td>\n",
       "      <td>0.073398</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>0.522461</td>\n",
       "      <td>0.144273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.959927</td>\n",
       "      <td>0.761081</td>\n",
       "      <td>0.063798</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.530273</td>\n",
       "      <td>0.150084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.964784</td>\n",
       "      <td>0.826351</td>\n",
       "      <td>0.049212</td>\n",
       "      <td>0.900879</td>\n",
       "      <td>0.627930</td>\n",
       "      <td>0.134887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.971160</td>\n",
       "      <td>0.824833</td>\n",
       "      <td>0.050255</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>0.623535</td>\n",
       "      <td>0.125664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24000</td>\n",
       "      <td>200</td>\n",
       "      <td>64</td>\n",
       "      <td>0.968579</td>\n",
       "      <td>0.709624</td>\n",
       "      <td>0.073895</td>\n",
       "      <td>0.923828</td>\n",
       "      <td>0.521973</td>\n",
       "      <td>0.118576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>0.855798</td>\n",
       "      <td>0.046261</td>\n",
       "      <td>0.945801</td>\n",
       "      <td>0.697754</td>\n",
       "      <td>0.114236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.969186</td>\n",
       "      <td>0.850789</td>\n",
       "      <td>0.048823</td>\n",
       "      <td>0.905273</td>\n",
       "      <td>0.655273</td>\n",
       "      <td>0.128929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.976776</td>\n",
       "      <td>0.852307</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.903320</td>\n",
       "      <td>0.653320</td>\n",
       "      <td>0.126217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12000</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>0.970097</td>\n",
       "      <td>0.840164</td>\n",
       "      <td>0.047680</td>\n",
       "      <td>0.879883</td>\n",
       "      <td>0.642578</td>\n",
       "      <td>0.117346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6000</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.854736</td>\n",
       "      <td>0.045719</td>\n",
       "      <td>0.920898</td>\n",
       "      <td>0.666016</td>\n",
       "      <td>0.128519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3000</td>\n",
       "      <td>200</td>\n",
       "      <td>512</td>\n",
       "      <td>0.969945</td>\n",
       "      <td>0.833789</td>\n",
       "      <td>0.052237</td>\n",
       "      <td>0.878418</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.150475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>24000</td>\n",
       "      <td>3200</td>\n",
       "      <td>512</td>\n",
       "      <td>0.987705</td>\n",
       "      <td>0.899666</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>0.907715</td>\n",
       "      <td>0.720703</td>\n",
       "      <td>0.143123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^16.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12000</td>\n",
       "      <td>800</td>\n",
       "      <td>512</td>\n",
       "      <td>0.976624</td>\n",
       "      <td>0.859745</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.901855</td>\n",
       "      <td>0.656738</td>\n",
       "      <td>0.140578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>30</td>\n",
       "      <td>data/train_data_2^20.npy</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>128</td>\n",
       "      <td>xavier</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1200</td>\n",
       "      <td>300</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.984165</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>0.055534</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>0.628174</td>\n",
       "      <td>0.090952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    base                train_data  attn_weight_xavier_init_constant  dropout  \\\n",
       "0     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "1     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "2     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "3     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "4     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "5     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "6     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "7     30  data/train_data_2^16.npy                               1.0     0.05   \n",
       "8     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "9     30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "10    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "11     7  data/train_data_2^16.npy                               0.5     0.05   \n",
       "12     8  data/train_data_2^16.npy                               0.5     0.05   \n",
       "13   210  data/train_data_2^16.npy                               0.5     0.05   \n",
       "14   237  data/train_data_2^16.npy                               0.5     0.05   \n",
       "15     7  data/train_data_2^16.npy                               0.5     0.05   \n",
       "16    90  data/train_data_2^16.npy                               0.5     0.05   \n",
       "17    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "18    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "19    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "20    30  data/train_data_2^16.npy                               0.5     0.10   \n",
       "21    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "22    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "23    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "24    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "25    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "26    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "27    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "28    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "29    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "30    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "31    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "32    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "33    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "34    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "35    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "36    30  data/train_data_2^16.npy                               0.5     0.05   \n",
       "37    30  data/train_data_2^20.npy                               0.5     0.05   \n",
       "\n",
       "    embed_dim embedding_initialization  \\\n",
       "0         128                   normal   \n",
       "1         128                   normal   \n",
       "2         128                   normal   \n",
       "3         128                   normal   \n",
       "4         128                   normal   \n",
       "5         128                   normal   \n",
       "6         128                   normal   \n",
       "7         128                   normal   \n",
       "8         128                   normal   \n",
       "9         128                   normal   \n",
       "10        128                   normal   \n",
       "11        128                   normal   \n",
       "12        128                   normal   \n",
       "13        128                   normal   \n",
       "14        128                   normal   \n",
       "15        128                   normal   \n",
       "16        128                   normal   \n",
       "17        256                   normal   \n",
       "18        512                   normal   \n",
       "19         64                   normal   \n",
       "20        128                   normal   \n",
       "21        128                   normal   \n",
       "22        128                   normal   \n",
       "23        128                   normal   \n",
       "24        128                   normal   \n",
       "25        128                   normal   \n",
       "26        128                   normal   \n",
       "27        128                   normal   \n",
       "28        128                   normal   \n",
       "29        128                   xavier   \n",
       "30        128                   xavier   \n",
       "31        128                   xavier   \n",
       "32        128                   normal   \n",
       "33        128                   normal   \n",
       "34        128                   normal   \n",
       "35        128                   normal   \n",
       "36        128                   normal   \n",
       "37        128                   xavier   \n",
       "\n",
       "    extra_positional_encoding_relative_decoder_mha  norm_first  \\\n",
       "0                                             True       False   \n",
       "1                                             True       False   \n",
       "2                                             True       False   \n",
       "3                                             True       False   \n",
       "4                                             True       False   \n",
       "5                                             True       False   \n",
       "6                                             True       False   \n",
       "7                                             True       False   \n",
       "8                                             True       False   \n",
       "9                                             True       False   \n",
       "10                                            True       False   \n",
       "11                                            True       False   \n",
       "12                                            True       False   \n",
       "13                                            True       False   \n",
       "14                                            True       False   \n",
       "15                                            True       False   \n",
       "16                                            True       False   \n",
       "17                                            True       False   \n",
       "18                                            True       False   \n",
       "19                                            True       False   \n",
       "20                                            True       False   \n",
       "21                                            True        True   \n",
       "22                                           False       False   \n",
       "23                                            True       False   \n",
       "24                                            True       False   \n",
       "25                                            True       False   \n",
       "26                                            True       False   \n",
       "27                                            True       False   \n",
       "28                                            True       False   \n",
       "29                                            True       False   \n",
       "30                                            True       False   \n",
       "31                                            True       False   \n",
       "32                                            True       False   \n",
       "33                                            True       False   \n",
       "34                                            True       False   \n",
       "35                                            True       False   \n",
       "36                                            True       False   \n",
       "37                                            True       False   \n",
       "\n",
       "    num_decoder_layers  num_encoder_layers  ...  weight_decay  \\\n",
       "0                   10                  10  ...          0.10   \n",
       "1                   12                  12  ...          0.10   \n",
       "2                   16                  16  ...          0.10   \n",
       "3                    2                   2  ...          0.10   \n",
       "4                    4                   4  ...          0.10   \n",
       "5                    8                   8  ...          0.10   \n",
       "6                    6                   6  ...          0.00   \n",
       "7                    6                   6  ...          0.00   \n",
       "8                    6                   6  ...          0.00   \n",
       "9                    6                   6  ...          0.00   \n",
       "10                   6                   6  ...          0.00   \n",
       "11                   6                   6  ...          0.00   \n",
       "12                   6                   6  ...          0.00   \n",
       "13                   6                   6  ...          0.10   \n",
       "14                   6                   6  ...          0.10   \n",
       "15                   6                   6  ...          0.10   \n",
       "16                   6                   6  ...          0.10   \n",
       "17                   6                   6  ...          0.10   \n",
       "18                   6                   6  ...          0.10   \n",
       "19                   6                   6  ...          0.10   \n",
       "20                   6                   6  ...          0.10   \n",
       "21                   6                   6  ...          0.10   \n",
       "22                   6                   6  ...          0.10   \n",
       "23                   6                   6  ...          0.10   \n",
       "24                   6                   6  ...          0.00   \n",
       "25                   6                   6  ...          0.01   \n",
       "26                   6                   6  ...          0.05   \n",
       "27                   6                   6  ...          0.10   \n",
       "28                   6                   6  ...          0.25   \n",
       "29                   6                   6  ...          0.10   \n",
       "30                   6                   6  ...          0.10   \n",
       "31                   6                   6  ...          0.10   \n",
       "32                   6                   6  ...          0.10   \n",
       "33                   6                   6  ...          0.10   \n",
       "34                   6                   6  ...          0.10   \n",
       "35                   6                   6  ...          0.10   \n",
       "36                   6                   6  ...          0.10   \n",
       "37                  10                  10  ...          0.10   \n",
       "\n",
       "    num_warmup_steps  nb_epochs  effective_train_batch_size  \\\n",
       "0               6000        200                         256   \n",
       "1               6000        200                         256   \n",
       "2               6000        200                         256   \n",
       "3               6000        200                         256   \n",
       "4               6000        200                         256   \n",
       "5               6000        200                         256   \n",
       "6              24000        200                          64   \n",
       "7              24000        200                          64   \n",
       "8              24000        200                          64   \n",
       "9              24000        200                          64   \n",
       "10             24000        200                          64   \n",
       "11             24000        200                          64   \n",
       "12             24000        200                          64   \n",
       "13             24000        200                          64   \n",
       "14             24000        200                          64   \n",
       "15             24000        200                          64   \n",
       "16             24000        200                          64   \n",
       "17              6000        200                         256   \n",
       "18              6000        200                         256   \n",
       "19              6000        200                         256   \n",
       "20              6000        200                         256   \n",
       "21             10000        200                          64   \n",
       "22             10000        200                          64   \n",
       "23              6000        200                         256   \n",
       "24             24000        200                          64   \n",
       "25             24000        200                          64   \n",
       "26             24000        200                          64   \n",
       "27             24000        200                          64   \n",
       "28             24000        200                          64   \n",
       "29              6000        200                         256   \n",
       "30              6000        200                         256   \n",
       "31              6000        200                         256   \n",
       "32             12000        200                         128   \n",
       "33              6000        200                         256   \n",
       "34              3000        200                         512   \n",
       "35             24000       3200                         512   \n",
       "36             12000        800                         512   \n",
       "37              1200        300                        2048   \n",
       "\n",
       "    correct_product_test  correct_factorization_test loss_test  \\\n",
       "0               0.979356                    0.861415  0.047529   \n",
       "1               0.974954                    0.857468  0.048018   \n",
       "2               0.974803                    0.857013  0.048752   \n",
       "3               0.945507                    0.561779  0.110729   \n",
       "4               0.962356                    0.796752  0.057410   \n",
       "5               0.979053                    0.860049  0.047189   \n",
       "6               0.959168                    0.727838  0.070385   \n",
       "7               0.934730                    0.658470  0.088125   \n",
       "8               0.949909                    0.659836  0.086440   \n",
       "9               0.948543                    0.696418  0.079208   \n",
       "10              0.960990                    0.716302  0.073048   \n",
       "11              0.874772                    0.259259  0.181037   \n",
       "12              0.985580                    0.398452  0.150913   \n",
       "13              0.987553                    0.906497  0.032362   \n",
       "14              0.957498                    0.853673  0.047474   \n",
       "15              0.913783                    0.438373  0.124756   \n",
       "16              0.985124                    0.848057  0.042097   \n",
       "17              0.980419                    0.887826  0.045192   \n",
       "18              0.000152                    0.000152  0.790861   \n",
       "19              0.957650                    0.668033  0.087711   \n",
       "20              0.966910                    0.822860  0.051705   \n",
       "21              0.978597                    0.861263  0.040617   \n",
       "22              0.967517                    0.835003  0.048632   \n",
       "23              0.980115                    0.862174  0.045891   \n",
       "24              0.960231                    0.716910  0.073398   \n",
       "25              0.959927                    0.761081  0.063798   \n",
       "26              0.964784                    0.826351  0.049212   \n",
       "27              0.971160                    0.824833  0.050255   \n",
       "28              0.968579                    0.709624  0.073895   \n",
       "29              0.978901                    0.855798  0.046261   \n",
       "30              0.969186                    0.850789  0.048823   \n",
       "31              0.976776                    0.852307  0.046058   \n",
       "32              0.970097                    0.840164  0.047680   \n",
       "33              0.978142                    0.854736  0.045719   \n",
       "34              0.969945                    0.833789  0.052237   \n",
       "35              0.987705                    0.899666  0.044012   \n",
       "36              0.976624                    0.859745  0.044800   \n",
       "37              0.984165                    0.776742  0.055534   \n",
       "\n",
       "    correct_product_oos  correct_factorization_oos  loss_oos  \n",
       "0              0.933594                   0.694824  0.119473  \n",
       "1              0.912598                   0.677246  0.124622  \n",
       "2              0.757812                   0.595703  0.158729  \n",
       "3              0.806152                   0.370117  0.174067  \n",
       "4              0.770020                   0.521973  0.151557  \n",
       "5              0.943848                   0.691406  0.123346  \n",
       "6              0.896973                   0.516113  0.166403  \n",
       "7              0.859375                   0.448242  0.166683  \n",
       "8              0.812500                   0.414062  0.185352  \n",
       "9              0.896484                   0.498535  0.144379  \n",
       "10             0.917969                   0.523926  0.143515  \n",
       "11             0.643555                   0.177734  0.296095  \n",
       "12             0.394531                   0.116699  0.535876  \n",
       "13             0.287109                   0.211426  0.512774  \n",
       "14             0.164062                   0.106445  0.509020  \n",
       "15             0.827637                   0.275391  0.163973  \n",
       "16             0.587891                   0.341797  0.222875  \n",
       "17             0.869629                   0.656738  0.161693  \n",
       "18             0.000000                   0.000000  0.798695  \n",
       "19             0.887695                   0.463867  0.150055  \n",
       "20             0.922852                   0.640137  0.117378  \n",
       "21             0.805664                   0.633301  0.127682  \n",
       "22             0.895508                   0.631348  0.118688  \n",
       "23             0.925293                   0.682617  0.131770  \n",
       "24             0.922363                   0.522461  0.144273  \n",
       "25             0.880859                   0.530273  0.150084  \n",
       "26             0.900879                   0.627930  0.134887  \n",
       "27             0.909180                   0.623535  0.125664  \n",
       "28             0.923828                   0.521973  0.118576  \n",
       "29             0.945801                   0.697754  0.114236  \n",
       "30             0.905273                   0.655273  0.128929  \n",
       "31             0.903320                   0.653320  0.126217  \n",
       "32             0.879883                   0.642578  0.117346  \n",
       "33             0.920898                   0.666016  0.128519  \n",
       "34             0.878418                   0.616211  0.150475  \n",
       "35             0.907715                   0.720703  0.143123  \n",
       "36             0.901855                   0.656738  0.140578  \n",
       "37             0.979492                   0.628174  0.090952  \n",
       "\n",
       "[38 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correlation_plot(metric_df, x, y):\n",
    "    metric_df.plot.scatter(x=x, y=y)\n",
    "    \n",
    "    x_col = metric_df[x]\n",
    "    y_col = metric_df[y]\n",
    "    \n",
    "    m, b = np.polyfit(x_col, y_col, 1)\n",
    "    ax = plt.gca()\n",
    "    x_vals = np.array(ax.get_xlim())\n",
    "    plt.plot(x_vals, m*x_vals + b, color='black', linestyle='--', alpha=.5)\n",
    "    plt.title(f'Correlation between {x} and {y}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at some correlations\n",
    "#### In general:\n",
    "* Correlation using correct_product is not very strong in many places.\n",
    "    * I think this makes sense because of the issue where when the model is unable to factor the number, it returns the number because it could be prime\n",
    "\n",
    "#### Test metrics vs OoS Metrics:\n",
    "* Test loss is very correlated with Oos. Same for factorization, but not quite as much\n",
    "\n",
    "#### Is loss correlated of correct factorizatoin?\n",
    "* Yes! Loss is very correlated with correct factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAEXCAYAAADhpT7GAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/M0lEQVR4nO3deXhU5dn48e89SUgCARISoEIIYXNBSAJGEBHUCoqiiD+0bohYW1qtrXbTbm9rbfu+Vd/WWl8rpVYtWrVVqoIBka2IiMoqiFZF1gAKhLCEJSSZ+/fHOYOHMNkzZ2aS+3NduTJnmfPcZ+bM3POc85znEVXFGGOMMc0vEO0AjDHGmJbKkqwxxhgTIZZkjTHGmAixJGuMMcZEiCVZY4wxJkIsyRpjjDERYknWGGOMiZCYT7IiMllE3mzC8+eIyM3NGZO73adE5NfNvV3TPETkNBFZIyIHReQ7UY5lqoj8VwS2G5FjuyUQERWRvtGOIxLs2I4vifVZSURuAL4HnA4cBNYAv1HVRie/SBCRe4G+qjoxNE9VL41eROGJyFNAsar+LNqxxJMGvm53A4tUtcDHMsNS1W82JQY3jnvx+dgOV2YTtqVAP1Xd0OTAWiA7tmP/e7ux6qzJisj3gD8A/w10BXKAPwFXNrQwETkpqYebZ1qGKL/fPYH1PpVVIxFJiHYMpvnZsW3Hdr2pao1/QEegDLimlnWScZLwDvfvD0Cyu+wCoBi4B/gMeBq4F3gReAY4AHzNLeevwE5gO/BrIMHdxmTgTU95DwPb3OeuBEa488cAx4AKN+b33Pn/Br7mPg4APwO2ALuA6UBHd1kuoMDNwFZgD/DTWvb7KWAqMA+ndr8Y6OlZfrq7bC/wEfAVd/4UN8ZjbpyzgFuAWZ7nfgK84JneBhTUtl3Pe/G/bvyfu/GlVnsvvu/u+07gllr2rxPwpPuelgIve5Z9HdjgxjAT6OZZpsC33H3YVMMxEAB+BHwKlAD/BDp5tnEe8Bawz933yeFet1piXwhUAUfddU8FxgKr3eNmG3BvtefUu0zgDJzjah/Ol924asfFY8Bs4BAwyp33a3f5LHdbob8gMDmWju06yqzts9oX53Ow3y3jH+78N9zyD7nbujZMeX3c963Efe7fgXTP8s3AD4C17vb/AaR4lv/QjWkH8FW3vL52bNux3dC8VdtxAAjwkBvHAWAdMKDWsurxQasEEmtZ5z7gbaAL0Nl9M3/l+WKvBO53dyoVJ8lWAOPdFy8VeAn4M9DO3c67wDfcbUzmxCQ7EcjEOdX9fZyDO8Vddi/wTLX4vG/WV90XrjeQBvwLeLram/UXN6Z8oBw4o4b9fgonuY509+3hUJzufmzDSZ6JwCD3ze/vee6vPdvqjXNQB4Bu7sFU7FlW6i6ra7sPuQdEJ6A9zkH/P9Xei/uAJOAy4DCQUcP+FeF8kWW465/vzv+yW+Zgd78fAd6o9kU0z40htYZj4E6cYybbnfdn4Dn3+T3d1/V6t9xMvviBccLrVsexe/x99+z/QPd1zMP5ETK+oWW6yzcAPwHauK/HQeA0z/r7geFuWSk1xQ1civMB7xFLx7Zn++HKrO2z+hzwU89+n1ftuAib9NzlfYHR7vHQGScx/8GzfLNbVjecY+tD4Jue76nPgQFuXM/WVh52bNuxXXveqvE4AC7B+ZGQjpNwzwBOqbWsOgK5EfisjnU+BS7zTF8CbPa8+cc48RfnvZx44HZ1X5RUz7zrca45QLUkG6b8UiC/nm/WAuB2z7LTcBJ+oufNyvYsfxe4roZynwKe90yn4fzC7AFcCyyptv6fgV/U9IHCSZ6DgeuAaW7Zp+Mk1JnuOjVu133DDwF9PMuGAZs878URPD+YcH6NnRNm307B+RV6UgLGqcU8UG2/K4BczxfRl6t9AVQ/Bj4ELqpWXuh9+DHwUi2veaO+iMIs/wPwkPu43mUCI3C+IAKeec/h1h7c9afXFTdODWQXnkQUK8d2tc/qM57puj6r03GO3eww26o1yYZZfzyw2jO9GZjomX4AmOo+fgL4bbXXNmx5dmzbse2uU1veqvE4wEnAHwPneF+n2v7quoZQAmSJSKKqVtawTqjmFbLFnReyW1WPVnvONs/jnji/oHaKSGheoNo6x4nID4Bb3TIU6ABk1bEftcWaiPPlEfKZ5/FhnBe4JsdjVNUyEdnrltETGCoi+zzrJuKcTqrJYpwPbeiU2z7gfJxEudhdp7btdgbaAis9r6MA3usmJdXex5r2rwewV1VLwyzrBqwKTbj7XQJ0x/kihJPfu+rHQE/gJREJeuZV4bwPPXA+AM1KRIYCv8Wp7bTB+YX6gru4IWV2A7apqjf2LTj7HxL22PXE0hF4BfiZehoPxtixHU5dn9W7gV8B74pIKfA7VX2iPhsWka44Z4NG4JyFCeB8EXtVjz/0PdMNp3YR4n0dqrNju2at6diuLW/VeByo6kIR+T/gUaCniPwL+IGqHqipoLoaPi3D+eU6vpZ1duAcWCE57rzjMYZ5jnfeNreMLFVNd/86qOqZ1Z8kIiNwPshfwfklmo5z+iL0iQ9XVl2xVuKcXmmMHp7Y0nBOI+3A2afFnv1JV9U0Vb2tljhDSXaE+3gxTpI9ny+SbG3b3YNTUz3Ts6yjqjb0izRUTicRSQ+z7ITXUETa4ZwG2u5Zp/r+VZ/eBlxabT9SVHW7u6xPDXHV9f7W5lmcU+k9VLUjzvXq0HHTkDJ3AD1ExPvZyaH2/T/Ofd6zOLW/aZ75sXZshyuz1s+qqn6mql9X1W7AN4A/NeA2mv92yxuoqh1wTi9K7U85bieezyLOvtfEju2ay2xNx3ZteavW40BV/6iqZwH9cWrtP6ytoFqTrKruB34OPCoi40WkrYgkicilIvKAu9pzwM9EpLOIZLnrP1O//QRV3Qm8DvxORDqISEBE+ojI+WFWb4/z4u4GEkXk5zi/iEI+B3KrHSRezwHfFZFeblL8b5zGGTXV0utymYicJyJtcH7Bv62q24BXgVNF5Cb39UoSkbNF5AxPnL2rbWsxcCHOqbhiYAnOtaZMnEYN1LZd99fnX4CHRKQLgIh0F5FLGrpT7nsyB+dLMsMtZ6S7+DngFhEpEJFknNfwHVXd3IAipgK/EZGebpydReRKd9nfgVEi8hURSRSRTBEpcJeFe93qqz1ODeaoiAwBbvAsa0iZ7+D8Ur7bfV0uAK4Anq9nHL/BuW54Z5j4YunYPqnMuj6rInKNiGS7zy3F+fIMerZV23vXHqfhy34R6U4dX1zV/BOYLCL9RaQtzuWTsOzYtmPbs82a8laNx4H7fTtURJJwLs8d5YtjPKw6b+FR1d/h3CP7M5wXaRtwB/Cyu8qvgRU4rf7W4VSzG9pJwySc0xwf4Hw4X8S5llHdXOA1nHPiW3B20Hv6InSKpEREVnGyJ3BOrb6B0zrwKPDtBsbq9SzOB3ovcBbOr29U9SBwMc711R04pzJCjSPAOeffX0T2icjL7nM+xvmSWeJOHwA2AktVtaqe270Hp4HA2yJyAJiPc/2iMW7CuQ7xH5zrK3e5McwH/guYgVOD6OPG0xAP4/zyfl1EDuI0QBjqbn8rTqOs7+O8rmtwGjNAmNetAW4H7nPL+znOFzMNLVNVj+F88VyKc/bgT8AkVf1PPeO4Hud6TqmIlLl/NxJ7x3ZNZdb2WT0beEdEynDe3ztVdaO77F7gb+7r+JUwZf0Sp03CfpyGSf+qb5CqOgfnOuRCnON/YR1PsWM7TJmt7NiuMW/VcRx0wKnMlLr7UgI8WFtB4l7YNcYYY0wzi/luFY0xxph4ZUnWxCURyfGckqr+V1vDF+MhTh+x4V7Dn0Q7ttbKju3mESvHtp0uNsYYYyLE+g0OIysrS3Nzc6MdhjHGxJWVK1fuUdXO0Y4jlliSDSM3N5cVK1ZEOwxjjIkrIlJbRyCtkl2TNcYYYyLEkqwxxhgTIZZkjTHGmAixJGuMMcZEiCVZY4wxJkIsyRpjTAtRUlbOe9v2UVJWHu1QjMtu4THGmBbglTXbuWfGWpICASqCQR6YkMe4gu51P9FElNVkjTEmzpWUlXPPjLUcrQhysLySoxVB7p6x1mq0McCSrDHGxLni0iMkBU78Ok8KBCguPRKliEyIJVljjIlz2RmpVARPHDu8IhgkOyM1ShGZkLhPsiIyRkQ+EpENIvKjMMsfEpE17t/HIrIvCmEaY0zEZKYl88CEPFKSArRPTiQlKcADE/LITEuOdmitXlw3fBKRBOBRYDRQDCwXkZmq+kFoHVX9rmf9bwODfA/UGGMaqKSsnOLSI2RnpNYrWY4r6M7wvlkNeo6JvLhOssAQYIOqbgQQkeeBK4EPalj/euAXPsVmjDGNEmopnBgQjlUpv7iiPzcO7Vnn8zLTki25xph4T7LdgW2e6WJgaLgVRaQn0AtY6ENcxhjTKN6WwiE/fel9ULjxnLoTrYktcX9NtgGuA15U1apwC0VkioisEJEVu3fv9jk0Y4xxFJceITEgJ83/+Svv2y05cSjek+x2oIdnOtudF851wHM1bUhVp6lqoaoWdu5sYw4bY6IjOyOVY5V60vwqhfU7DkQhItMU8Z5klwP9RKSXiLTBSaQzq68kIqcDGcAyn+MzxpgGyUxL5tbzcsMuW/bpHn+DMU0W10lWVSuBO4C5wIfAP1V1vYjcJyLjPKteBzyvqif/PDTGmBiTndE27Pwnlm62U8ZxJt4bPqGqs4HZ1eb9vNr0vX7GZIwxjVVSVs6visLfINEmwenFyVoQx4+4rskaY0xLU1x6hAQ5ueETWC9O8ciSrDHGxJD3t+/n0LGTb4JITrRenOJR3J8uNsaYlqKmU8WTh/Xk2xf1OynBNrRXqJocOnSIefPm0a9fP84888xGb8eczJKsMcbEiJrukX12+TYG98w4YXzY5hg/NhgMsnLlShYsWEBFRQVdunRp8j6YE1mSNcaYGPH+9v2UlZ98qvhYpTM+7PC+WWSmJZ/QK9RRnJ6hvMvrY8eOHbz66qvs2LGDXr16MXbsWLKyspp1f4wlWWOMiQklZeXc9+r6GpeHxofNTEs+Pn5sKMFWX14fpaWlHDx4kKuvvpozzzwTqaGxlWkaS7LGGBNlJWXlLPrPLgIIEP52fm/L4saMH6uqrFmzhsrKSs4++2z69+9Pv379aNOmTbPthzmZJVljjPFR9cZK3hF3jlQGwz6nesvi0Pixd1e7JltTLfbzzz+nqKiIrVu30qdPHwoLCxERS7A+sCRrjDE+qd5Y6b/G9udXRR+cMOKOV2IAri3M4ZbhufTt2v6EZfUZP7a8vJxFixbx7rvvkpKSwvjx48nPz7dTwz4S62nwZIWFhbpixYpoh2GMaUFKysoZfv/CExJqUgIkBgIc8cxrl5zADy8+jc8PHOWJpZtok5DQ6NbDxcXFPPHEEwwePJiLLrqI1NTIdmQhIitVtTCihcQZ64zCGGMaoaSsnPe27at3X8KhxkpeFVWckGABqoLKeX2zePKtzZRXKgfLKzla4bQurk9Ze/bs4d133wUgOzub73znO1x++eURT7AmPDtdbIwxDdSYe1TDNVaqLnTt9dCxqga3Hj527BhvvPEGy5Yto02bNgwcOJDU1FTS09MbvH+m+ViSNcaYBmjsPaqZacmMy+/GP1cUh13eNimBqTedxchTO1NSVl7v1sOqykcffcScOXPYv38/BQUFjB492mquMcJOFxtjTAOEO+0bqmXWpqSsnJfX7KhxeRDlzG4dgC9aD6ckBWifnEhKUs39Fh86dIgZM2aQnJzMLbfcwvjx42nXrl0j9sxEgtVkjTGmARpzjyo4yblNgnCsMvzyrxRmn5BEa2s9XFlZyfr168nLyyMtLY3JkyfzpS99iYSEhMbvmIkIq8kaY0wDNKSW6ZWdkUplsOa7Of65ovikhk2Zacnk90g/YdsbNmzgT3/6Ey+99BLFxc6p5+7du1uCjVFxX5MVkTHAw0AC8Liq/jbMOl8B7sXpSuU9Vb3B1yCNMS1Kfe5Rrc7bgQRw0r2xdTVs2r9/P3PnzuWDDz4gKyuLSZMm0aNHj6bvjImouE6yIpIAPAqMBoqB5SIyU1U/8KzTD/gxMFxVS0XEhpkwxjRZZlpyg4eXCyXn9TsO8PXpKyj39PBU2ylnVWX69OkcOHCAiy66iGHDhpGYGNdf361GvL9LQ4ANqroRQESeB64EvAMyfh14VFVLAVR1l+9RGmOMKzMtmZGndubBq2vvFrGkrJwV6z9h0Om96dKxLVdccQXp6el2S06cifck2x3Y5pkuBoZWW+dUABFZinNK+V5Vfc2f8IwxJrzaTjk//9bHfP+h6VTs2kxqn0Ie+c41jCvIjV6wptHiPcnWRyLQD7gAyAbeEJGBqrrPu5KITAGmAOTk5PgcojGmNap+yjkYDDJ/8VK+/au/UlFRSXJ2f8js1eCxYk3siPckux3wXvnPdud5FQPvqGoFsElEPsZJusu9K6nqNGAaOH0XRyxiY4ypwSuvvMLcN94huWNnUnIGk5Dq3Dfb0LFiTeyI91t4lgP9RKSXiLQBrgNmVlvnZZxaLCKShXP6eKOPMRpjTI0OHz7M0aNHATj77LO56YZraXfmhccTLNTvPlwTm+I6yapqJXAHMBf4EPinqq4XkftEZJy72lygREQ+ABYBP1TVkuhEbIwxDlVl5cqVPPLIIyxYsABwOvQffvYgHrw6v8H34ZrYZEPdhWFD3RljImnnzp0UFRVRXFxMz549ueyyy+jatesJ61Qf3D0e2FB3J4v3a7LGGBNXVq1axaxZs2jbti1XXXUVeXl5YQdRb8x9uCb2WJI1xpgIU1WOHTtGcnIyvXr1YsiQIVxwwQU2Uk4rYEnWGGMiaNeuXcyePZvExERuvPFGMjIyuPTSS6MdlvFJVJKsiASANFU9EI3yjTEm0o4dO8bixYtZtmwZycnJjBo1KtohmSjwLcmKyLPAN4EqnFtvOojIw6r6oF8xGGOMH3bu3Mlzzz3HgQMHGDRoEKNGjbIxXlspP2uy/VX1gIjcCMwBfgSsBCzJGmNahGAwSCAQICMjg86dO3PNNdfYSDmtnJ/3ySaJSBIwHpjp9sBk9w8ZY+JeRUUFixYt4vHHH6eqqoqUlBRuuukmS7DG15rsn4HNwHs4/Qf3BOyarDEmrn3yySfMnj2b0tJSBg4cSEVFhQ2gbo7zLcmq6h+BP3pmbRGRC/0q3xhjmtORI0d45ZVX+M9//kNWVhY333wzvXr1inZYJsb42fCpI/ALYKQ7azFwH7DfrxiMMaYxwvW+lJycTFlZGaNGjWLYsGFWezVh+Xm6+AngfeAr7vRNwJPA//MxBmOMaZBX1mznHndw9UMlO7iiyz7uv/s2UlJSuPXWW8P21mRMiJ9Jto+qTvBM/1JE1vhYvjGmlQrVRCsqq9hccpiCHun07dq+Xs+7Z8ZaDpeVcWTzaip2b+b5du355o5dnNE7J2yCjcc+h03k+Jlkj4jIear6JoCIDAeO+Fi+MaYVCtVEq4JKRdUXNzRMGpbDfVcOrPW52/YepmLHRxzcsBrVICk5A8nqncexpA5h1/fWeiuCQR6YkMe4gu7Nuj8mvviZZG8D/uZemxVgL3Czj+UbY1qZUE30aEXwpGXTl21lXF43khITaqx1ZmekcqRkBwkdOpPau5CE1PZUSiDs2K7eso7ilHf3jLUM75tlNdpWzM/WxWuAfBHp4E7b7TvGmIgqLj1CUiBwPOlVd91f3iY1KfGEWuehQ4dYuHAh5513HlkZGTzy09v4ySsf0iYh4fh64ZJmuLKSAgGKS49Ykm3Fota6WEQWA/epqrUuNsZERHZGKhXB8AkWoDIIB8srAfjhi2toe2ALK5ctoby8nJycHDIyMphwdi8uOKNbnddZw5VVEQyGrfWa1sPPHp+eAA7itC7+Ck5HFE82daMiMkZEPhKRDSLyozDLJ4vIbhFZ4/59rallGmPiQ2ZaMg9MyCMlKUBSwomNlLyTlQdLKHtvHi++NJOuXbty2223kZ+ff8J28nuk11oj9ZbVPjmRlKRAjbVe03rEdetiEUkAHgVGA8XAchGZqaofVFv1H6p6R1PKMsbED28L33EF3RneN+uE1sW5mW2Z+MS7VLnXait2bUSPlHHDtRMZMfSsRt+W4y3LWhcbiP/WxUOADaq60d3m88CVQPUka4xpJWpq4RtKeIW9MlFVbhuQyB+X7qRtRlfa9B3Mf4+/iZFD+zS5/My0ZEuu5jg/k+w3genutVmAUpreurg7sM0zXQwMDbPeBBEZCXwMfFdVt4VZxxgT5+rTwvfzzz93+hresoV7zx1A3vChVus0EeNn6+L3qKV1sYjcrKp/i0DRs4DnVLVcRL4B/A34cvWVRGQKMAUgJycnAmEYYyKttha+aUnw73//m3feeYeUlBTGjRvHoEGDrMcmE1F+1mSBWm/duRMnATbEdsA7llS2O89bXoln8nHggRrimgZMAygsLLQh+IyJQ7W18H3vvfd4++23GTx4MBdddBFt27aNUpSmNfE9ydaiMT8nlwP9RKQXTnK9DrjhhI2KnKKqO93JccCHTYrSGBOzQi1873avyR4t28f3R+SQmZZM+llnkZ2dTbdu3aIdpmlFYinJNrj2qKqVInIHMBdIAJ5Q1fUich+wQlVnAt8RkXFAJU4vU5ObMWZjTIwZV9CdIT07MmvuQjau/4DyTbtRPYeEhARLsMZ3sZRkG3VhRFVnA7Orzfu55/GPgR83LTRjTLz46KOPmDNnDvv27WPI4AJGjx5t111N1MRSkl0a7QCMMfFt69atPPfcc3Tu3JnJkyeTm5sb7ZBMK+dnt4rJwAQg11uuqt7n/rfOIowxdao+lFxlZSU7duwgJyeHHj16cPXVV3PGGWfYIOomJvhZk30F2A+sBMp9LNcY00JU72jiu0M6cGzzKg4cOMBdd91Fu3btGDBgQLTDNOY4P5NstqqO8bE8Y0wL4u1o4nB5GUc2reKni7fy/SvO4tprr6Vdu3bRDtGYk/iZZN8SkYGqus7HMo0xLUSoo4nDFUc4uLoIDVbRqVcBF189ib69sqIdnjFh+ZlkzwMmi8gmnNPFAqiq5vkYgzEmDpWUlbNt5y6OVQUJJCWT0rOAxIxTaNO+A7md20c7PGNq5GeSvdTHsowxLcTzb33M9x96msrdm0kdMIqkjp1pn3tGrQOoGxMr/Oy7eIuI5AMj3FlL3P6MjTHmJMFgkAVLlvHtXz5ORUUFyd3PQFM7EhB49MZBnNmtoyVYE/P8vIXnTuDrwL/cWc+IyDRVfcSvGIwx8UFVmT59Om+/9x+SO2SSkjOYhLbOAF5tEhLomNrGEqyJC36eLr4VGKqqhwBE5H5gGWBJ1hgDwNGjR0lOTkZEGDhwIH3757Fo5meUV37R62qow39j4kHAx7IEqPJMV9HIrhSNMS2LqrJ69Wr++Mc/sn79egDOOusszhsymAevziclKUD75ERSkgJ2HdbEFT9rsk8C74jIS+70eOCvPpZvjIlBn332GUVFRWzbto2cnBw6d+58wvJxBd0Z3jfrhF6ejIkXfjZ8+r2I/BvnVh6AW1R1tV/lG2Niz5IlS1i0aBEpKSmMHz+e/Pz8sJ35Z6YlW3I1cSniSVZEOqjqARHpBGx2/0LLOqnq3kjHYIyJHaqKqhIIBMjMzDw+iHpqau3XWav3WWxMPPCjJvsscDlOn8XeMWPFne7tQwzGmBiwZ88eioqK6NOnD+eddx79+/enf//+dT6vep/FD0zIY1xBdx8iNqZpIp5kVfVy93+vSJdljIlNx44dY8mSJbz11lskJSUxcODAej/X22fxUYIA3D1jLcP7ZlmN1sQ8P++TXaCqF9U1zxjTsmzatImXX36Z/fv3U1DgDKLekM78Q30WhxIsQFIgQHHpEUuyJub5cU02BWgLZIlIBl/cttMBaPL5HhEZAzwMJACPq+pva1hvAvAicLaqrmhqucaY+klKSiI1NZUJEyaQk5PT4OdnZ6RSEQyeMM/ulTXxwo/7ZL+Bcz32dPd/6O8V4P+asmERSQAexekXuT9wvYicdIFHRNoDdwLvNKU8Y0zdKisrWbx4MXPmzAEgOzubb3zjG41KsOC0LH5gQp7dK2vikh/XZB8GHhaRb0egC8UhwAZV3QggIs8DVwIfVFvvV8D9wA+buXxjjMeGDRuYPXs2e/fuZcCAAQSDQQKBQNjbchrC7pU18crP+2QfEZEBODXOFM/86U3YbHdgm2e6GBjqXUFEBgM9VLVIRGpMsiIyBZgCNPoXtzGt1cGDB5kzZw4ffPABmZmZTJo0id69m/fGAbtX1sQjPxs+/QK4ACfJzsY5xfsm0JQkW1eZAeD3wOS61lXVacA0gMLCQq1jdWOMR1VVFZs3b+aiiy5i2LBhJCb62ZmcMbHLz76LrwYuAj5T1VuAfKBjE7e5Hejhmc5254W0BwYA/xaRzcA5wEwRKWxiuca0eps3b6aoqAhVJT09ne9+97uMGDHCEqwxHn5+Go6oalBEKkWkA7CLExNkYywH+olIL5zkeh1wQ2ihqu4HskLTbreOP7DWxcY0XllZGa+//jpr164lPT2dQ4cOkZaWRlJSUrRDMybm+JlkV4hIOvAXnNbFZThD3TWaqlaKyB3AXJxbeJ5Q1fUich+wQlVnNjFmY4wrGAyyfPlyXp3zOnvLjjL6yyMZO/rLllyNqYWfDZ9udx9OFZHXgA6qurYZtjsb5xqvd97Pa1j3gqaWZ0xrVVFRwdR/FPHap4dJP3UoC5YFCXTbZd0bGlML367JisgCEbkMQFU3q+paEZnmV/nGmIY7fPgwCxcupKqqirIKeDMxnzanX8CRhLYcrQhy94y1lJSVRztMY2KWn6eLewH3iMjZqvpLd541QDImBoUGUZ83bx7l5eX06tWLA4kZpKSmUVFeeXw9697QmNr5mWT34bQu/qOIzAIm+li2Maaedu7cSVFREcXFxfTs2ZOxY8fSpUsXSsrKrXtDYxrIz1t4RFUr3WuzM3Duke3iY/nGmDqoKrNmzaK0tJSrrrqKyZMn06WL8zG17g2NaTg/a7JTQw9U9SkRWQd8y8fyjTFhqCrvv/8+ffv2Pd6Rf9u2bcMOom7dGxrTMH6MwtNBVQ8AL4hIJ8+iTcAPIl2+MaZmu3fvpqio6HhvTSNGjCAzM7PW51j3hpFTUlZuP2BaGD9qss8Cl+PcG6t8MdQd7nTzdnBqjKnTsWPHWLx4McuWLSM5OZkrrriCwYMHRzusVu2VNdu5Z8ZakgIBKoJBHpiQZ7dHtQB+jMJzuThDcJyvqlsjXZ4xpm6vvfYaq1atYtCgQYwaNapBg6ib5ldSVs49M9ZytCJ4fHD6u2esZXjfLKvRxjlfrsmqqopIETDQj/KMMScrKSkhEAiQkZHByJEjGTRoED16NLVnU9McikuPkBQIHE+wYLdHtRR+ti5eJSJn+1ieMQanp6ZFixbxpz/9iXnz5gGQnp5uCTaGZGek2u1RLZSfrYuHAjeKyBbgEM61WVXVPB9jMKZV+fjjj5kzZw6lpaUMHDiQiy++ONohmTBCt0fdXe2arNVi45+fSfYSH8syptVbtWoVM2fOJCsri5tvvplevXpFOyRTC7s9qmXyc4CALSKSD4xwZy1R1ff8Kt+Y1qCqqoqDBw+Snp7OmWeeSXl5OUOGDCEhISHaoZl6sNujWh4/Bwi4E/g7Ti9PXYBnROTbfpVvTEu3adMmHnvsMZ599lmCwSDJyckMGzbMEqwxUeTn6eJbgaGqeghARO7HGU/2ER9jMKbFOXjwIK+//jrr1q0jIyODSy65hEDAzzaNxpia+JlkBajyTFdxYscUxpgG+uyzz3jyySepqqriggsuYPjw4TaIujExxM8k+yTwjoi85E6PB55o6kZFZAzwMJAAPK6qv622/Js4fSRXAWXAFFX9oKnlGhNNR48eJSUlhS5dulBQUMDQoUPp1KlT3U80xvhKVNW/wkQGA+e5k0tUdXUTt5cAfAyMBoqB5cD13iTq6TsZERkH3K6qY2rbbmFhoa5YsaIpoRkTEYcOHWL+/Pl88skn3HHHHaSkpEQ7JGOOE5GVqmrjhHv4VpMVkadV9SZgVZh5jTUE2KCqG93tPQ9cCRxPsqEE62qH01+yMXFFVVm5ciULFiygvLycYcOG2XVXY+KAn6eLz/ROuLXQs5q4ze7ANs90MU6nFycQkW8B3wPaAF8OtyERmQJMAcjJyWliWMY0n/LycqZPn8727dvJzc1l7NixdO7cOdphGWPqwY+h7n4M/ARIFZFQrVKAY8C0SJcPoKqPAo+KyA3Az4Cbw6wzLRRPYWGh1XZN1AWDQQKBAG3atKFr164MHTqUgQMH4oy3YYyJBxE/36Sq/6Oq7YEHVbWD+9deVTNV9cdN3Px2wNsBa7Y7rybP4zS4MiZmqSpr1qzh4YcfZu/evYgI48aNIy8vzxKsMXHGz4s674pIx9CEiKSLyPgmbnM50E9EeolIG+A6YKZ3BRHp55kcC3zSxDKNiZjPP/+cJ598kpdffhlJSmHttlJKysqjHZYxppH8vCb7C1UN3b6Dqu4TkV8ALzd2g6paKSJ3AHNxbuF5QlXXi8h9wApVnQncISKjgAqglDCnio2JNlVl/vz5xwdR73DaOTy2Pkibf22gIvixDeBtTJzyM8mGqzU3uXxVnQ3Mrjbv557Hdza1DGMiTUSorKykoKCAQeeMYPQjb1NeqZRXVgI2gLcx8crP08UrROT3ItLH/fs9sNLH8o2JKXv27OHpp59m69atAIwZM4Zx48axt1xIqnZ7TmgAb2NMfPGzJvtt4L+Af7jT83B6YjKmVamoqGDJkiUsXbqUpKQkDh48CHC8UZMN4G1My+HnUHeHgB/5VZ4xseiTTz6hqKiIffv2kZ+fz+jRo0lLSzthHRvA25iWw88enzoDd+N0SnG8LzhVDds5hDEt0Z49e0hKSmLy5Mnk5ubWuJ4N4G1My+Dn6eK/45wqvhz4Jk4r390+lm+M7yorK3nrrbfo1KkTAwYMYOjQofUeRN0G8DYm/vnZ8ClTVf8KVKjqYlX9KjV0cWhMS/Dpp5/y2GOPsXDhQrZs2QJAIBCwQdSNaUX8rMlWuP93ishYYAdgY3OZFufAgQPMnTuX9evX06lTJyZOnEjfvn2jHZYxJgr8TLK/dnt8+j7wCNAB+K6P5Rvji+3bt/PRRx9x4YUXMnz4cBIT/fyYGWNiiR8DBNyvqvcAqaq6H9gPXBjpco3x05YtW9i7dy+DBg3i9NNP584776R9+/bRDssYE2V+XJO9TJwbAJs6GIAxMefQoUO8/PLLPPnkkyxdupRgMIiIWII1xgD+nC5+DafP4DTPUHfgDHenqtrBhxiMaVbBYPD4IOoVFRWMGDGCESNG2EDqxpgTRDzJquoPgR+KyCuqemWkyzPGD7t372b27NnHB1HPysqKdkjGmBjkZ49PtSZYEVmmqsP8iseYhjpy5Agff/wx+fn5dO3ala9//euccsopNsarMaZGsdTsMaXuVYzxX2gQ9Xnz5nH06FFyc3Pp2LEj3bp1i3ZoxoRVUlZuvYXFiFhKshrtAIyp7rPPPqOoqIht27bRo0cPLr/8cjp27BjtsIyp0StrtnNPtX6vbSzi6ImlJGtMTDl27BhPPfUUgUCAK6+8koKCAjs1bGJaSVk598xYy9GKIEdxRnKysYijK5aSbKO+vURkDPAwkAA8rqq/rbb8e8DXgEqcvpK/qqpbmhiraaFUlY0bN9K7d2/atGnDNddcQ7du3UhNtWHmTOwrLj1CUiBwPMHCF2MRW5KNDt/uNxCR++uYd1MjtpkAPApcCvQHrheR/tVWWw0Uqmoe8CLwQEPLMa3D7t27mT59Ok8//TQff/wxAH369LEEa+KGjUUce/y8qW90mHmXhh6o6vuN2OYQYIOqblTVY8DzwAmtmFV1kaoediffBrIbUY5pwY4dO8aCBQuYOnUqO3fuZOzYsfTr1y/aYRnTYKGxiFOSArRPTiQlKWBjEUeZH90q3gbcDvQRkbWeRe2Bt5q4+e7ANs90MTC0lvVvBebUEOcUYApATk5OE8My8eSZZ55h69atFBQUMHr0aNq1axftkIxpNBuLOLb4cU32WZzE9j/AjzzzD6rqXh/KB0BEJgKFwPnhlqvqNGAaQGFhobV0buFKS0tp3749iYmJnH/++SQlJdmPK9Ni2FjEscOPHp/2A/tF5GFgr6oeBBCRDiIyVFXfacLmtwM9PNPZ7rwTiMgo4KfA+apa3oTyTJyrrKxk6dKlLFmyhPPPP58RI0bQp0+faIdljGmh/Gxd/Bgw2DNdFmZeQy0H+olIL5zkeh1wg3cFERkE/BkYo6q7mlCWiVH1vfF+w4YNzJ49m7179zJgwADy8/N9jNIY0xr5mWRFVY+fhlXVoIg0qXxVrRSRO4C5OLfwPKGq60XkPmCFqs4EHgTSgBfcexy3quq4ppRrYkd9b7xftGgRixcvJjMzk0mTJtG7d+8oRGuMaW38TLIbReQ7OLVXcBpDbWzqRlV1NjC72ryfex6PamoZJjbVdeN9VVUVlZWVJCcnc+qpp5KYmMiwYcNsEHVjjG/8vIXnm8C5OKd1Q62Ap/hYvmlhQjfee4VuvN+8eTNTp05l7ty5AHTv3p0RI0ZYgjXG+MrPUXh24VwzNaZZhLvxvvzoIda8MZdNn3xIeno6p512WpSiM8YYf3t8OlVEFojI++50noj8zK/yTctT/cb7wMGdnHN4OVs3fszIkSP51re+ZUnWGBNVfp47+wvwQ5yWvqjqWhF5Fvi1jzGYFmZcQXfO6ZXBzgPH6BAYxDtLFjJ69GgyMzOjHZoxxviaZNuq6rvVRjGp9LF808IcPnyY+fPns3//fiZOnIiI0Os6uyJhjIkdfibZPSLSB3fcWBG5GtjpY/mmhVBVVq9ezbx58ygvL+ecc84hGAySkJAQ7dCMMeYEfibZb+F0W3i6iGwHNgE3+li+aQH27dvHiy++SHFxMT179mTs2LF06dIl2mEZY0xYviRZd0i621V1lIi0AwKh7hWNaYjU1FSqqqq46qqryMvLs0HUjTExzZckq6pVInKe+/iQH2WalkFVWbduHatWreKmm24iOTmZKVOmWHI1xsQFP08XrxaRmcALwPFEq6r/8jEGE0d2795NUVERmzdvpnv37hw6dIgOHTpYgjXGxA0/k2wKUAJ82TNPAUuy5gSVlZUsWrSIZcuWkZyczBVXXMHgwYMtuRpj4o6f12RLVPUHfpRn4lsgEGDTpk3k5+czatQoG0TdGBO3/LwmO9yPskx82rt3LwsXLmTs2LGkpqby1a9+tcX1M1zfIfmMMS2Hn99ia+yarKmuoqKCN998k6VLl5KQkMDOnTvp3bt3i0uw9R2SzxjTstg1WRM1n3zyCbNnz6a0tJSBAwdy8cUX0759+2iH1ezqGpLPmOrsrEfL4ecoPLf4VZaJDytXriQhIYGbb76ZXr16RTuciAkNyRdKsPDFkHz2BWqqs7MeLYufo/Bki8hLIrLL/ZshItnNsN0xIvKRiGwQkR+FWT5SRFaJSKXblaOJkqqqKt58801KSkoAGDduHLfddluLTrAQfki+imCQ7IzUKEVkYpX3rMfB8kqOVgS5e8ZaSsrKox2aaSQ/B21/EpgJdHP/ZrnzGs1ttfwocCnQH7heRPpXW20rMBl4tillmabZtGkTjz32GPPnz2f9+vUAtG3btlX0N1x9SL6UpAAPTMizWqw5Seish1forIeJT35ek+2sqt6k+pSI3NXEbQ4BNqjqRgAReR64EvggtIKqbnaXBcNtwETWwYMHef3111m3bh0ZGRnceOON9OvXL9ph+W5cQXeG982y62ymVnbWo+XxsyZbIiITRSTB/ZuI0xCqKboD2zzTxe68BhORKSKyQkRW7N69u4lhmZC3336bDz/8kAsuuIDbb7+9VSbYkMy0ZPJ7pFuCNTWysx4tj5812a8CjwAP4bQqfgvnNG5MUNVpOKMEUVhYqFEOJ65t27YNESE7O5uRI0cyePBgG0TdmHqysx4ti59J9j7gZlUtBRCRTsD/4iTfxtoO9PBMZ7vzTBQcOnSI+fPns3r1avr06XO8Q//kZPuSMKYhMtOSLbm2EH4m2bxQggVQ1b0iMqiJ21wO9BORXjjJ9TrghiZu0zSQqrJy5UoWLFhAeXk55513HiNHjox2WMYYE3V+JtmAiGRUq8k2qXxVrRSRO4C5QALwhKquF5H7gBWqOlNEzgZeAjKAK0Tkl6p6ZtN2xXitW7eOV199ldzcXMaOHUvnzp2jHZIxxsQEP5Ps74BlIvKCO30N8JumblRVZwOzq837uefxcpzTyKYZHTlyhD179tCjRw8GDBhAmzZtOO2002ykHGOM8fCzx6fpIrKCL7pV/H+q+kFtzzGxR1VZu3Ytr7/+OiLCXXfdRWJiIqeffnq0QzPGmJjjay/sblK1xBqndu3aRVFREVu2bCE7O5uxY8e2uI78jTGmOdk3pKmXPXv2MHXqVFJSUhg3bhyDBg2yU8PGGFMHS7KmRqrKnj176Ny5M1lZWYwZM4YBAwbQtm3baIdmjDFxwc8en0wcKSkp4ZlnnuHPf/4zpaXOnVdDhgyxBGuMMQ1gNVlzgoqKCpYsWcLSpUtJTEzk4osvpmPHjtEOyxhj4pIlWXNcRUUFjz32GHv37iUvL4+LL76YtLS0aIdljDFxy5Ks4fDhw7Rt25akpCQKCwvp1q0bubm50Q7LGGPinl2TbcUqKyt54403eOihh9iyZQsA5557riVYY4xpJlaTbaU+/fRTZs+eTUlJCf379ycjIyPaIRljTItjSbYVmjlzJqtWraJTp05MnDiRvn37RjskY4xpkSzJthJVVVUEAgFEhFNOOYULL7yQ4cOHW49NxhgTQfYN2wps2bKFoqIihg8fTn5+PmeffXa0QzLGmFbBkmwLdujQIebNm8eaNWvo2LGjdSRhjDE+syTbQq1bt46ioiIqKioYMWIEI0aMoE2bNtEOyxhjWhVLsi2MqiIiJCUlccoppzB27FiysrKiHZYxxrRKcX+frIiMEZGPRGSDiPwozPJkEfmHu/wdEcmNQpi1Kikr571t+ygpK2/0No4cOcKrr77KkiVLADjttNOYNGmSJVhjjImiuK7JikgC8CgwGigGlovIzGqDwd8KlKpqXxG5DrgfuNb/aMN7Zc127pmxlqRAgIpgkAcm5DGuoHu9n6+qrFmzhnnz5nH06FHOPfdcABuGzhhjYkBcJ1lgCLBBVTcCiMjzwJWcODD8lcC97uMXgf8TEVFV9TPQcErKyrlnxlqOVgQ5ShCAu2esZXjfLDLTkut8/u7du5k1axZbt24lJyeHyy67jC996UuRDtsYY0w9xXuS7Q5s80wXA0NrWkdVK0VkP5AJ7PGuJCJTgCkAOTk5kYr3BMWlR0gKBI4nWICkQIDi0iP1SrKVlZXs3buX8ePHk5+fb7VXY4yJMXF/Tba5qOo0VS1U1cLOnTv7UmZ2RioVweAJ8yqCQbIzUsOur6qsW7eOefPmAXDKKadw1113UVBQYAnWGGNiULwn2e1AD890tjsv7Doikgh0BEp8ia4OmWnJPDAhj5SkAO2TE0lJCvDAhLywtdjdu3czffp0ZsyYwaZNm6ioqACwHpuMMSaGxfs39HKgn4j0wkmm1wE3VFtnJnAzsAy4GlgYC9djQ8YVdGd43yyKS4+QnZF6UoI9duwYb7zxBsuWLSMpKYmxY8dy1llnEQjE++8jY4xp+eI6ybrXWO8A5gIJwBOqul5E7gNWqOpM4K/A0yKyAdiLk4hjSmZaco3XYI8ePcry5csZOHAgo0ePpl27dj5HZ4wxprEkhip1MaOwsFBXrFgRtfJLS0tZvXo1F154ISJCWVkZaWlpUYvHGGPqQ0RWqmphtOOIJXFdk21pKisrWbp0KUuWLCEQCJCXl0dWVpYlWGOMiVOWZGPEhg0bmD17Nnv37mXAgAFcfPHFdOjQIdphGWOMaQJLsjGgsrKSWbNmkZSUxKRJk+jdu3e0QzLGGNMMLMlGSVVVFatWrWLQoEEkJiYyceJEMjIy7JYcY4xpQewbPQo2b95MUVERu3fvJjU1lQEDBuBXBxjGGGP8Y0nWR2VlZbz++uusXbuW9PR0rr/+ek477bRoh2WMMSZCLMn66F//+hdbtmxh5MiRjBgxgqSkpGiHZIwxJoIsyUZYcXExGRkZtGvXjjFjxpCQkEBmZma0wzLGGOMDS7IRcvjwYebPn8+qVasYNmwYl1xyCV26dIl2WMYYY3xkSbaZqSqrVq1i/vz5lJeXc+6553L++edHOyxjjDFRYEm2mS1cuJAlS5bQs2dPLrvsMrp27RrtkIwxxkSJJdlmVlhYSFZWFnl5eTbGqzHGtHKWZJtZx44dyc/Pj3YYxhhjYoANSmqMMcZEiCVZY4wxJkIsyRpjjDERErdJVkQ6icg8EfnE/Z9Rw3qvicg+EXnV7xiNMca0bnGbZIEfAQtUtR+wwJ0O50HgJt+iMsYYY1zxnGSvBP7mPv4bMD7cSqq6ADjoU0zGGGPMcfGcZLuq6k738WdAk3p9EJEpIrJCRFbs3r276dEZY4xp9WL6PlkRmQ98Kcyin3onVFVFRJtSlqpOA6YBFBYWNmlbxhhjDMR4klXVUTUtE5HPReQUVd0pIqcAu5qr3JUrV+4RkS3Ntb16ygL2+FxmtLXGfYbWud+2z62DDZBdTUwn2TrMBG4Gfuv+f6W5NqyqnZtrW/UlIitUtdDvcqOpNe4ztM79tn1uHURkRbRjiDXxfE32t8BoEfkEGOVOIyKFIvJ4aCURWQK8AFwkIsUicklUojXGGNPqxG1NVlVLgIvCzF8BfM0zPcLPuIwxxpiQeK7JtjTToh1AFLTGfYbWud+2z61Da9znWomqNaQ1xhhjIsFqssYYY0yEWJI1xhhjIsSSrM9EZIyIfCQiG0TkpP6WRSRZRP7hLn9HRHKjEGazqsc+f09EPhCRtSKyQER6RiPO5lTXPnvWmyAiKiJxf6tHffZZRL7ivtfrReRZv2NsbvU4tnNEZJGIrHaP78uiEWdzEpEnRGSXiLxfw3IRkT+6r8laERnsd4wxRVXtz6c/IAH4FOgNtAHeA/pXW+d2YKr7+DrgH9GO24d9vhBo6z6+rTXss7tee+AN4G2gMNpx+/A+9wNWAxnudJdox+3DPk8DbnMf9wc2RzvuZtjvkcBg4P0all8GzAEEOAd4J9oxR/PParL+GgJsUNWNqnoMeB5noAMv78AHL+Lc3ys+xtjc6txnVV2kqofdybeBbJ9jbG71eZ8BfgXcDxz1M7gIqc8+fx14VFVLAVS12Xppi5L67LMCHdzHHYEdPsYXEar6BrC3llWuBKar420g3e2Vr1WyJOuv7sA2z3SxOy/sOqpaCewHMn2JLjLqs89et+L8Co5nde6zewqth6oW+RlYBNXnfT4VOFVElorI2yIyxrfoIqM++3wvMFFEioHZwLf9CS2qGvqZb9HitjMK0/KIyESgEDg/2rFEkogEgN8Dk6Mcit8ScU4ZX4BztuINERmoqvuiGVSEXQ88paq/E5FhwNMiMkBVg9EOzPjDarL+2g708Exnu/PCriMiiTinmEp8iS4y6rPPiMgonNGVxqlquU+xRUpd+9weGAD8W0Q241y3mhnnjZ/q8z4XAzNVtUJVNwEf4yTdeFWffb4V+CeAqi4DUnAGDmjJ6vWZby0syfprOdBPRHqJSBuchk0zq60TGvgA4GpgobqtCeJUnfssIoOAP+Mk2Hi/Tgd17LOq7lfVLFXNVdVcnOvQ49TpEjRe1efYfhmnFouIZOGcPt7oY4zNrT77vBW3+1cROQMnybb0AatnApPcVsbnAPv1i7G/Wx07XewjVa0UkTuAuTgtE59Q1fUich+wQlVnAn/FOaW0AadxwXXRi7jp6rnPDwJpwAtuG6+tqjouakE3UT33uUWp5z7PBS4WkQ+AKuCH6vRBHpfquc/fB/4iIt/FaQQ1Oc5/NCMiz+H8WMpyrzX/AkgCUNWpONeeLwM2AIeBW6ITaWywbhWNMcaYCLHTxcYYY0yEWJI1xhhjIsSSrDHGGBMhlmSNMcaYCLEka4wxxkSIJVljjDEmQizJGtMAIpIuIrfXY70H3eHcHmxEGT9pZGyzRSS9Ec+7S0TaNnU7tWx/soh0a+RzLxCRc5srFmP8ZvfJmlZFRBLdgRfCTtfj+bnAq6o6oI719gOdVLWqETGWqWpaA9YXnM9yo/rDdbt2LFTVPY15fj22/2/gB43p0UpE7gXKVPV/mzsuY/xgNVkTt0Rkkjso9Hsi8rSI5IrIQs/g7znuek+JyFQReQd4IMx0HxF5TURWisgSETndfV5XEXnJ3f57bo3qt0AfEVlTUy1VRGbi9GC1UkSuFZErROQdcQbuni8iXd310kTkSRFZ58Y8QUR+C6S62/+7u973ROR99+8ud16uOIOFTwfeB3qIyGYRyRKRb7rPXyMim0Rkkfucx0RkhVvD/qU77ztAN2CRZ73NbreHtZX9oYj8xd3W6yKSWsNrcTXOoA9/d+NJFZGzRGSx+3rPFXcYNBH5jjgDuq8VkefdHzTfBL7rPndE444UY6Io2gPa2p/9NeYPOBOng/ksd7oTMAu42Z3+KvCy+/gp4FUgoYbpBUA/9/FQnP6iAf4B3OU+TsAZrCGXGgarrhZfmedxBl+cNfoa8Dv38f3AH7zrhXnuWcA6oB1O4l4PDHLjCALneNbdHHo93OkkYAlwReg18uzLv4G8Gp63GacT+9rKrgQK3PX/CUys5bX4N+6g9G5MbwGd3elrcbojBGes1WT3cbr7/16cWnDUjzn7s7/G/FnfxSZefRl4Qd1TnKq6V5yhxP6fu/xp4AHP+i/oiaduX1DVKhFJA87li36TAZI9ZUxyt18F7BeRjEbEmg38w62xtQE2ufNH4embWt3BzKs5D3hJVQ8BiMi/gBE4nbBvUWdQ7Jo8jPODYZY7/RURmYLTZ/kpQH9gbS3Pr63sTaq6xl1vJU7irY/TcEYgmue+3glAqPP4tTg13pdxBhMwJu5ZkjWtxaEapgPAPlUtiGDZjwC/V9WZInIBTu2sOVTfp+NEZDLQE7jDne4F/AA4W1VLReQpnBFhGss7HGEVEPZ0cbjQgPWqOizMsrHASOAK4KciMrAJ8RkTE+yarIlXC4FrRCQTQEQ64ZyGDNUMb8Q5VVorVT0AbBKRa9ztiIjku4sXALe58xNEpCNwEGc82IboyBfjad7smT8P+FZowlNLrhCRJPfxEmC8iLQVkXbAVXXtl4ichZNQJ+oXjaE64CTl/e414Us9T6lpnxpcdg282/8I6OyedUBEkkTkTHEGsu+hqouAe3Bes7RaYjMmLliSNXFJVdcDvwEWi8h7wO+BbwO3iMha4Cbgznpu7kbgVnc764Er3fl3AheKyDqcU6L91RmabanbEKi+t+fci3M6eiXgbcH7ayDD3dZ7wIXu/GnAWhH5u6quwrmG/C7wDvC4qq6uo7w7cK5RL3IbDD2uqu8Bq4H/AM8CSz3rTwNeCzV8Cmlk2eE8BUwVkTU4p4evBu5393kNzun6BOAZ97VeDfxRVffhXGe/yho+mXhlt/AYY4wxEWI1WWOMMSZCrOGTMY3kNsx5utrsclUdGo14ok1EHgWGV5v9sKo+GY14jIkFdrrYGGOMiRA7XWyMMcZEiCVZY4wxJkIsyRpjjDERYknWGGOMiZD/D8+G6F6ltfODAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in metrics:\n",
    "    make_correlation_plot(metric_df, x=m + f'_{splits[0]}', y=m + f'_{splits[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in metrics:\n",
    "    if m == 'loss' : continue\n",
    "    for s in splits:\n",
    "        make_correlation_plot(metric_df, x=f'loss_{s}', y = f'{m}_{s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_cols = [c for c in metric_df.columns if not c in metrics_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base',\n",
       " 'train_data',\n",
       " 'attn_weight_xavier_init_constant',\n",
       " 'dropout',\n",
       " 'embed_dim',\n",
       " 'embedding_initialization',\n",
       " 'extra_positional_encoding_relative_decoder_mha',\n",
       " 'norm_first',\n",
       " 'num_decoder_layers',\n",
       " 'num_encoder_layers',\n",
       " 'positional_encoding_query_key_only',\n",
       " 'relative_positional_encoding',\n",
       " 'repeat_positional_encoding',\n",
       " 'scale_embeddings',\n",
       " 'scale_embeddings_at_init',\n",
       " 'shared_embeddings',\n",
       " 'optimizer',\n",
       " 'weight_decay',\n",
       " 'num_warmup_steps',\n",
       " 'nb_epochs',\n",
       " 'effective_train_batch_size']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_lower_is_better = {'loss'}\n",
    "\n",
    "def style_col_axis_1(col, n_highlight=3, col_id_name=\"id\"):\n",
    "#     if col.name==col_id_name:\n",
    "#         return [f'background-color: {col[i]}' for i in range(len(col))]\n",
    "    if len(set(col.name.split('_')).intersection(metrics_lower_is_better)):\n",
    "        top_indicies = np.argsort(col.values)[:n_highlight]\n",
    "    else:\n",
    "        top_indicies = np.argsort(col.values)[::-1][:n_highlight]\n",
    "    alphas = np.zeros(len(col))\n",
    "    for i in range(len(top_indicies)):\n",
    "        alphas[top_indicies[i]] = 1 - i/n_highlight\n",
    "    return np.array([f'background-color: rgba(0,169,0,{alphas[i]})' for i in range(len(col))])\n",
    "\n",
    "def style_df(df, ablated_hparams = None, n_highlight=3, col_id_name=\"color\"):\n",
    "    if ablated_hparams is None:\n",
    "        ablated_hparams = []\n",
    "    to_return = np.zeros_like(df.values, dtype=np.object)\n",
    "    df_cols = df.columns\n",
    "#     display(df)\n",
    "    for i in range(df.shape[1]):\n",
    "        this_col = df_cols[i]\n",
    "        if this_col in ablated_hparams: continue\n",
    "        if this_col in hyperparam_cols:\n",
    "            to_return[:,i] = np.array([f'background-color: {df[col_id_name].iloc[j]}' for j in range(df.shape[0])])\n",
    "#             print(to_return)\n",
    "        else:\n",
    "            to_return[:,i] = style_col_axis_1(df.iloc[:,i], n_highlight, col_id_name)\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ef068_row0_col21, #T_ef068_row0_col22, #T_ef068_row0_col23, #T_ef068_row0_col24, #T_ef068_row0_col25, #T_ef068_row0_col26, #T_ef068_row1_col21, #T_ef068_row1_col22, #T_ef068_row1_col23, #T_ef068_row1_col24, #T_ef068_row1_col25, #T_ef068_row1_col26, #T_ef068_row2_col22, #T_ef068_row2_col23, #T_ef068_row2_col24, #T_ef068_row2_col25, #T_ef068_row2_col26, #T_ef068_row3_col21, #T_ef068_row3_col22, #T_ef068_row3_col23, #T_ef068_row3_col24, #T_ef068_row3_col25, #T_ef068_row3_col26, #T_ef068_row4_col21, #T_ef068_row4_col22, #T_ef068_row4_col23, #T_ef068_row4_col24, #T_ef068_row4_col25, #T_ef068_row4_col26, #T_ef068_row5_col21, #T_ef068_row5_col22, #T_ef068_row5_col23, #T_ef068_row5_col24, #T_ef068_row5_col25, #T_ef068_row5_col26, #T_ef068_row6_col21, #T_ef068_row6_col22, #T_ef068_row6_col23, #T_ef068_row6_col24, #T_ef068_row6_col25, #T_ef068_row6_col26, #T_ef068_row7_col21, #T_ef068_row7_col22, #T_ef068_row7_col23, #T_ef068_row7_col24, #T_ef068_row7_col25, #T_ef068_row7_col26, #T_ef068_row8_col21, #T_ef068_row8_col22, #T_ef068_row8_col23, #T_ef068_row8_col24, #T_ef068_row8_col25, #T_ef068_row8_col26, #T_ef068_row9_col21, #T_ef068_row9_col22, #T_ef068_row9_col23, #T_ef068_row9_col24, #T_ef068_row9_col25, #T_ef068_row9_col26, #T_ef068_row10_col21, #T_ef068_row10_col22, #T_ef068_row10_col23, #T_ef068_row10_col24, #T_ef068_row10_col25, #T_ef068_row10_col26, #T_ef068_row11_col21, #T_ef068_row11_col22, #T_ef068_row11_col23, #T_ef068_row11_col24, #T_ef068_row11_col25, #T_ef068_row11_col26, #T_ef068_row12_col21, #T_ef068_row12_col22, #T_ef068_row12_col23, #T_ef068_row12_col24, #T_ef068_row12_col25, #T_ef068_row12_col26, #T_ef068_row13_col21, #T_ef068_row13_col22, #T_ef068_row13_col23, #T_ef068_row13_col24, #T_ef068_row13_col25, #T_ef068_row13_col26, #T_ef068_row14_col21, #T_ef068_row14_col22, #T_ef068_row14_col23, #T_ef068_row14_col24, #T_ef068_row14_col25, #T_ef068_row15_col21, #T_ef068_row15_col22, #T_ef068_row15_col23, #T_ef068_row15_col24, #T_ef068_row15_col25, #T_ef068_row15_col26, #T_ef068_row16_col21, #T_ef068_row16_col22, #T_ef068_row16_col23, #T_ef068_row16_col24, #T_ef068_row16_col25, #T_ef068_row16_col26, #T_ef068_row17_col23, #T_ef068_row17_col24, #T_ef068_row17_col26, #T_ef068_row18_col21, #T_ef068_row18_col22, #T_ef068_row18_col23, #T_ef068_row18_col24, #T_ef068_row18_col25, #T_ef068_row18_col26, #T_ef068_row19_col21, #T_ef068_row19_col22, #T_ef068_row19_col23, #T_ef068_row19_col24, #T_ef068_row19_col25, #T_ef068_row19_col26, #T_ef068_row20_col21, #T_ef068_row20_col22, #T_ef068_row20_col23, #T_ef068_row20_col24, #T_ef068_row20_col25, #T_ef068_row20_col26, #T_ef068_row21_col21, #T_ef068_row21_col22, #T_ef068_row21_col23, #T_ef068_row21_col24, #T_ef068_row21_col25, #T_ef068_row21_col26, #T_ef068_row22_col21, #T_ef068_row22_col22, #T_ef068_row22_col23, #T_ef068_row22_col25, #T_ef068_row22_col26, #T_ef068_row23_col21, #T_ef068_row23_col22, #T_ef068_row23_col23, #T_ef068_row23_col24, #T_ef068_row23_col26, #T_ef068_row24_col21, #T_ef068_row24_col22, #T_ef068_row24_col23, #T_ef068_row24_col24, #T_ef068_row24_col25, #T_ef068_row24_col26, #T_ef068_row25_col21, #T_ef068_row25_col22, #T_ef068_row25_col23, #T_ef068_row25_col24, #T_ef068_row25_col25, #T_ef068_row25_col26, #T_ef068_row26_col21, #T_ef068_row26_col22, #T_ef068_row26_col24, #T_ef068_row26_col25, #T_ef068_row26_col26, #T_ef068_row27_col21, #T_ef068_row27_col22, #T_ef068_row27_col23, #T_ef068_row28_col21, #T_ef068_row28_col22, #T_ef068_row28_col23, #T_ef068_row28_col24, #T_ef068_row28_col25, #T_ef068_row28_col26, #T_ef068_row29_col21, #T_ef068_row29_col22, #T_ef068_row29_col23, #T_ef068_row29_col24, #T_ef068_row29_col25, #T_ef068_row29_col26, #T_ef068_row30_col21, #T_ef068_row30_col23, #T_ef068_row30_col24, #T_ef068_row30_col25, #T_ef068_row30_col26, #T_ef068_row31_col21, #T_ef068_row31_col22, #T_ef068_row31_col23, #T_ef068_row31_col24, #T_ef068_row31_col25, #T_ef068_row31_col26, #T_ef068_row32_col21, #T_ef068_row32_col22, #T_ef068_row32_col23, #T_ef068_row32_col24, #T_ef068_row32_col25, #T_ef068_row32_col26, #T_ef068_row33_col21, #T_ef068_row33_col22, #T_ef068_row33_col23, #T_ef068_row33_col24, #T_ef068_row33_col25, #T_ef068_row33_col26, #T_ef068_row34_col21, #T_ef068_row34_col22, #T_ef068_row34_col23, #T_ef068_row34_col25, #T_ef068_row35_col21, #T_ef068_row35_col22, #T_ef068_row35_col24, #T_ef068_row35_col25, #T_ef068_row35_col26, #T_ef068_row36_col24, #T_ef068_row36_col25, #T_ef068_row36_col26, #T_ef068_row37_col21, #T_ef068_row37_col22, #T_ef068_row37_col23, #T_ef068_row37_col24, #T_ef068_row37_col25, #T_ef068_row37_col26 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "#T_ef068_row2_col21, #T_ef068_row14_col26, #T_ef068_row22_col24, #T_ef068_row23_col25, #T_ef068_row30_col22, #T_ef068_row35_col23 {\n",
       "  background-color: rgba(0,169,0,0.33333333333333337);\n",
       "}\n",
       "#T_ef068_row17_col21, #T_ef068_row17_col25, #T_ef068_row34_col24, #T_ef068_row34_col26, #T_ef068_row36_col22, #T_ef068_row36_col23 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "#T_ef068_row17_col22, #T_ef068_row26_col23, #T_ef068_row27_col24, #T_ef068_row27_col25, #T_ef068_row27_col26, #T_ef068_row36_col21 {\n",
       "  background-color: rgba(0,169,0,0.6666666666666667);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ef068_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >base</th>\n",
       "      <th class=\"col_heading level0 col1\" >train_data</th>\n",
       "      <th class=\"col_heading level0 col2\" >attn_weight_xavier_init_constant</th>\n",
       "      <th class=\"col_heading level0 col3\" >dropout</th>\n",
       "      <th class=\"col_heading level0 col4\" >embed_dim</th>\n",
       "      <th class=\"col_heading level0 col5\" >embedding_initialization</th>\n",
       "      <th class=\"col_heading level0 col6\" >extra_positional_encoding_relative_decoder_mha</th>\n",
       "      <th class=\"col_heading level0 col7\" >norm_first</th>\n",
       "      <th class=\"col_heading level0 col8\" >num_decoder_layers</th>\n",
       "      <th class=\"col_heading level0 col9\" >num_encoder_layers</th>\n",
       "      <th class=\"col_heading level0 col10\" >positional_encoding_query_key_only</th>\n",
       "      <th class=\"col_heading level0 col11\" >relative_positional_encoding</th>\n",
       "      <th class=\"col_heading level0 col12\" >repeat_positional_encoding</th>\n",
       "      <th class=\"col_heading level0 col13\" >scale_embeddings</th>\n",
       "      <th class=\"col_heading level0 col14\" >scale_embeddings_at_init</th>\n",
       "      <th class=\"col_heading level0 col15\" >shared_embeddings</th>\n",
       "      <th class=\"col_heading level0 col16\" >optimizer</th>\n",
       "      <th class=\"col_heading level0 col17\" >weight_decay</th>\n",
       "      <th class=\"col_heading level0 col18\" >num_warmup_steps</th>\n",
       "      <th class=\"col_heading level0 col19\" >nb_epochs</th>\n",
       "      <th class=\"col_heading level0 col20\" >effective_train_batch_size</th>\n",
       "      <th class=\"col_heading level0 col21\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col22\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col23\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col24\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col25\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col26\" >loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row0\" class=\"row_heading level0 row0\" >15</th>\n",
       "      <td id=\"T_ef068_row0_col0\" class=\"data row0 col0\" >7</td>\n",
       "      <td id=\"T_ef068_row0_col1\" class=\"data row0 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row0_col2\" class=\"data row0 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row0_col3\" class=\"data row0 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row0_col4\" class=\"data row0 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row0_col5\" class=\"data row0 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row0_col6\" class=\"data row0 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row0_col7\" class=\"data row0 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row0_col8\" class=\"data row0 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row0_col9\" class=\"data row0 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row0_col10\" class=\"data row0 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row0_col11\" class=\"data row0 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row0_col12\" class=\"data row0 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row0_col13\" class=\"data row0 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row0_col14\" class=\"data row0 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row0_col15\" class=\"data row0 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row0_col16\" class=\"data row0 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row0_col17\" class=\"data row0 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row0_col18\" class=\"data row0 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row0_col19\" class=\"data row0 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row0_col20\" class=\"data row0 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row0_col21\" class=\"data row0 col21\" >0.913783</td>\n",
       "      <td id=\"T_ef068_row0_col22\" class=\"data row0 col22\" >0.438373</td>\n",
       "      <td id=\"T_ef068_row0_col23\" class=\"data row0 col23\" >0.124756</td>\n",
       "      <td id=\"T_ef068_row0_col24\" class=\"data row0 col24\" >0.827637</td>\n",
       "      <td id=\"T_ef068_row0_col25\" class=\"data row0 col25\" >0.275391</td>\n",
       "      <td id=\"T_ef068_row0_col26\" class=\"data row0 col26\" >0.163973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row1\" class=\"row_heading level0 row1\" >11</th>\n",
       "      <td id=\"T_ef068_row1_col0\" class=\"data row1 col0\" >7</td>\n",
       "      <td id=\"T_ef068_row1_col1\" class=\"data row1 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row1_col2\" class=\"data row1 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row1_col3\" class=\"data row1 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row1_col4\" class=\"data row1 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row1_col5\" class=\"data row1 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row1_col6\" class=\"data row1 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row1_col7\" class=\"data row1 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row1_col8\" class=\"data row1 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row1_col9\" class=\"data row1 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row1_col10\" class=\"data row1 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row1_col11\" class=\"data row1 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row1_col12\" class=\"data row1 col12\" >True</td>\n",
       "      <td id=\"T_ef068_row1_col13\" class=\"data row1 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row1_col14\" class=\"data row1 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row1_col15\" class=\"data row1 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row1_col16\" class=\"data row1 col16\" >adam</td>\n",
       "      <td id=\"T_ef068_row1_col17\" class=\"data row1 col17\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row1_col18\" class=\"data row1 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row1_col19\" class=\"data row1 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row1_col20\" class=\"data row1 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row1_col21\" class=\"data row1 col21\" >0.874772</td>\n",
       "      <td id=\"T_ef068_row1_col22\" class=\"data row1 col22\" >0.259259</td>\n",
       "      <td id=\"T_ef068_row1_col23\" class=\"data row1 col23\" >0.181037</td>\n",
       "      <td id=\"T_ef068_row1_col24\" class=\"data row1 col24\" >0.643555</td>\n",
       "      <td id=\"T_ef068_row1_col25\" class=\"data row1 col25\" >0.177734</td>\n",
       "      <td id=\"T_ef068_row1_col26\" class=\"data row1 col26\" >0.296095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row2\" class=\"row_heading level0 row2\" >12</th>\n",
       "      <td id=\"T_ef068_row2_col0\" class=\"data row2 col0\" >8</td>\n",
       "      <td id=\"T_ef068_row2_col1\" class=\"data row2 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row2_col2\" class=\"data row2 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row2_col3\" class=\"data row2 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row2_col4\" class=\"data row2 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row2_col5\" class=\"data row2 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row2_col6\" class=\"data row2 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row2_col7\" class=\"data row2 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row2_col8\" class=\"data row2 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row2_col9\" class=\"data row2 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row2_col10\" class=\"data row2 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row2_col11\" class=\"data row2 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row2_col12\" class=\"data row2 col12\" >True</td>\n",
       "      <td id=\"T_ef068_row2_col13\" class=\"data row2 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row2_col14\" class=\"data row2 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row2_col15\" class=\"data row2 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row2_col16\" class=\"data row2 col16\" >adam</td>\n",
       "      <td id=\"T_ef068_row2_col17\" class=\"data row2 col17\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row2_col18\" class=\"data row2 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row2_col19\" class=\"data row2 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row2_col20\" class=\"data row2 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row2_col21\" class=\"data row2 col21\" >0.985580</td>\n",
       "      <td id=\"T_ef068_row2_col22\" class=\"data row2 col22\" >0.398452</td>\n",
       "      <td id=\"T_ef068_row2_col23\" class=\"data row2 col23\" >0.150913</td>\n",
       "      <td id=\"T_ef068_row2_col24\" class=\"data row2 col24\" >0.394531</td>\n",
       "      <td id=\"T_ef068_row2_col25\" class=\"data row2 col25\" >0.116699</td>\n",
       "      <td id=\"T_ef068_row2_col26\" class=\"data row2 col26\" >0.535876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row3\" class=\"row_heading level0 row3\" >19</th>\n",
       "      <td id=\"T_ef068_row3_col0\" class=\"data row3 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row3_col1\" class=\"data row3 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row3_col2\" class=\"data row3 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row3_col3\" class=\"data row3 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row3_col4\" class=\"data row3 col4\" >64</td>\n",
       "      <td id=\"T_ef068_row3_col5\" class=\"data row3 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row3_col6\" class=\"data row3 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row3_col7\" class=\"data row3 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row3_col8\" class=\"data row3 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row3_col9\" class=\"data row3 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row3_col10\" class=\"data row3 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row3_col11\" class=\"data row3 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row3_col12\" class=\"data row3 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row3_col13\" class=\"data row3 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row3_col14\" class=\"data row3 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row3_col15\" class=\"data row3 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row3_col16\" class=\"data row3 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row3_col17\" class=\"data row3 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row3_col18\" class=\"data row3 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row3_col19\" class=\"data row3 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row3_col20\" class=\"data row3 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row3_col21\" class=\"data row3 col21\" >0.957650</td>\n",
       "      <td id=\"T_ef068_row3_col22\" class=\"data row3 col22\" >0.668033</td>\n",
       "      <td id=\"T_ef068_row3_col23\" class=\"data row3 col23\" >0.087711</td>\n",
       "      <td id=\"T_ef068_row3_col24\" class=\"data row3 col24\" >0.887695</td>\n",
       "      <td id=\"T_ef068_row3_col25\" class=\"data row3 col25\" >0.463867</td>\n",
       "      <td id=\"T_ef068_row3_col26\" class=\"data row3 col26\" >0.150055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row4\" class=\"row_heading level0 row4\" >22</th>\n",
       "      <td id=\"T_ef068_row4_col0\" class=\"data row4 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row4_col1\" class=\"data row4 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row4_col2\" class=\"data row4 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row4_col3\" class=\"data row4 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row4_col4\" class=\"data row4 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row4_col5\" class=\"data row4 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row4_col6\" class=\"data row4 col6\" >False</td>\n",
       "      <td id=\"T_ef068_row4_col7\" class=\"data row4 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row4_col8\" class=\"data row4 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row4_col9\" class=\"data row4 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row4_col10\" class=\"data row4 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row4_col11\" class=\"data row4 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row4_col12\" class=\"data row4 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row4_col13\" class=\"data row4 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row4_col14\" class=\"data row4 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row4_col15\" class=\"data row4 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row4_col16\" class=\"data row4 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row4_col17\" class=\"data row4 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row4_col18\" class=\"data row4 col18\" >10000</td>\n",
       "      <td id=\"T_ef068_row4_col19\" class=\"data row4 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row4_col20\" class=\"data row4 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row4_col21\" class=\"data row4 col21\" >0.967517</td>\n",
       "      <td id=\"T_ef068_row4_col22\" class=\"data row4 col22\" >0.835003</td>\n",
       "      <td id=\"T_ef068_row4_col23\" class=\"data row4 col23\" >0.048632</td>\n",
       "      <td id=\"T_ef068_row4_col24\" class=\"data row4 col24\" >0.895508</td>\n",
       "      <td id=\"T_ef068_row4_col25\" class=\"data row4 col25\" >0.631348</td>\n",
       "      <td id=\"T_ef068_row4_col26\" class=\"data row4 col26\" >0.118688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row5\" class=\"row_heading level0 row5\" >3</th>\n",
       "      <td id=\"T_ef068_row5_col0\" class=\"data row5 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row5_col1\" class=\"data row5 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row5_col2\" class=\"data row5 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row5_col3\" class=\"data row5 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row5_col4\" class=\"data row5 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row5_col5\" class=\"data row5 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row5_col6\" class=\"data row5 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row5_col7\" class=\"data row5 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row5_col8\" class=\"data row5 col8\" >2</td>\n",
       "      <td id=\"T_ef068_row5_col9\" class=\"data row5 col9\" >2</td>\n",
       "      <td id=\"T_ef068_row5_col10\" class=\"data row5 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row5_col11\" class=\"data row5 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row5_col12\" class=\"data row5 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row5_col13\" class=\"data row5 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row5_col14\" class=\"data row5 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row5_col15\" class=\"data row5 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row5_col16\" class=\"data row5 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row5_col17\" class=\"data row5 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row5_col18\" class=\"data row5 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row5_col19\" class=\"data row5 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row5_col20\" class=\"data row5 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row5_col21\" class=\"data row5 col21\" >0.945507</td>\n",
       "      <td id=\"T_ef068_row5_col22\" class=\"data row5 col22\" >0.561779</td>\n",
       "      <td id=\"T_ef068_row5_col23\" class=\"data row5 col23\" >0.110729</td>\n",
       "      <td id=\"T_ef068_row5_col24\" class=\"data row5 col24\" >0.806152</td>\n",
       "      <td id=\"T_ef068_row5_col25\" class=\"data row5 col25\" >0.370117</td>\n",
       "      <td id=\"T_ef068_row5_col26\" class=\"data row5 col26\" >0.174067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row6\" class=\"row_heading level0 row6\" >4</th>\n",
       "      <td id=\"T_ef068_row6_col0\" class=\"data row6 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row6_col1\" class=\"data row6 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row6_col2\" class=\"data row6 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row6_col3\" class=\"data row6 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row6_col4\" class=\"data row6 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row6_col5\" class=\"data row6 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row6_col6\" class=\"data row6 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row6_col7\" class=\"data row6 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row6_col8\" class=\"data row6 col8\" >4</td>\n",
       "      <td id=\"T_ef068_row6_col9\" class=\"data row6 col9\" >4</td>\n",
       "      <td id=\"T_ef068_row6_col10\" class=\"data row6 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row6_col11\" class=\"data row6 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row6_col12\" class=\"data row6 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row6_col13\" class=\"data row6 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row6_col14\" class=\"data row6 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row6_col15\" class=\"data row6 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row6_col16\" class=\"data row6 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row6_col17\" class=\"data row6 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row6_col18\" class=\"data row6 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row6_col19\" class=\"data row6 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row6_col20\" class=\"data row6 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row6_col21\" class=\"data row6 col21\" >0.962356</td>\n",
       "      <td id=\"T_ef068_row6_col22\" class=\"data row6 col22\" >0.796752</td>\n",
       "      <td id=\"T_ef068_row6_col23\" class=\"data row6 col23\" >0.057410</td>\n",
       "      <td id=\"T_ef068_row6_col24\" class=\"data row6 col24\" >0.770020</td>\n",
       "      <td id=\"T_ef068_row6_col25\" class=\"data row6 col25\" >0.521973</td>\n",
       "      <td id=\"T_ef068_row6_col26\" class=\"data row6 col26\" >0.151557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_ef068_row7_col0\" class=\"data row7 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row7_col1\" class=\"data row7 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row7_col2\" class=\"data row7 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row7_col3\" class=\"data row7 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row7_col4\" class=\"data row7 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row7_col5\" class=\"data row7 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row7_col6\" class=\"data row7 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row7_col7\" class=\"data row7 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row7_col8\" class=\"data row7 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row7_col9\" class=\"data row7 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row7_col10\" class=\"data row7 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row7_col11\" class=\"data row7 col11\" >False</td>\n",
       "      <td id=\"T_ef068_row7_col12\" class=\"data row7 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row7_col13\" class=\"data row7 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row7_col14\" class=\"data row7 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row7_col15\" class=\"data row7 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row7_col16\" class=\"data row7 col16\" >adam</td>\n",
       "      <td id=\"T_ef068_row7_col17\" class=\"data row7 col17\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row7_col18\" class=\"data row7 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row7_col19\" class=\"data row7 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row7_col20\" class=\"data row7 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row7_col21\" class=\"data row7 col21\" >0.949909</td>\n",
       "      <td id=\"T_ef068_row7_col22\" class=\"data row7 col22\" >0.659836</td>\n",
       "      <td id=\"T_ef068_row7_col23\" class=\"data row7 col23\" >0.086440</td>\n",
       "      <td id=\"T_ef068_row7_col24\" class=\"data row7 col24\" >0.812500</td>\n",
       "      <td id=\"T_ef068_row7_col25\" class=\"data row7 col25\" >0.414062</td>\n",
       "      <td id=\"T_ef068_row7_col26\" class=\"data row7 col26\" >0.185352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_ef068_row8_col0\" class=\"data row8 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row8_col1\" class=\"data row8 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row8_col2\" class=\"data row8 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row8_col3\" class=\"data row8 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row8_col4\" class=\"data row8 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row8_col5\" class=\"data row8 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row8_col6\" class=\"data row8 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row8_col7\" class=\"data row8 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row8_col8\" class=\"data row8 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row8_col9\" class=\"data row8 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row8_col10\" class=\"data row8 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row8_col11\" class=\"data row8 col11\" >False</td>\n",
       "      <td id=\"T_ef068_row8_col12\" class=\"data row8 col12\" >True</td>\n",
       "      <td id=\"T_ef068_row8_col13\" class=\"data row8 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row8_col14\" class=\"data row8 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row8_col15\" class=\"data row8 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row8_col16\" class=\"data row8 col16\" >adam</td>\n",
       "      <td id=\"T_ef068_row8_col17\" class=\"data row8 col17\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row8_col18\" class=\"data row8 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row8_col19\" class=\"data row8 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row8_col20\" class=\"data row8 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row8_col21\" class=\"data row8 col21\" >0.948543</td>\n",
       "      <td id=\"T_ef068_row8_col22\" class=\"data row8 col22\" >0.696418</td>\n",
       "      <td id=\"T_ef068_row8_col23\" class=\"data row8 col23\" >0.079208</td>\n",
       "      <td id=\"T_ef068_row8_col24\" class=\"data row8 col24\" >0.896484</td>\n",
       "      <td id=\"T_ef068_row8_col25\" class=\"data row8 col25\" >0.498535</td>\n",
       "      <td id=\"T_ef068_row8_col26\" class=\"data row8 col26\" >0.144379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row9\" class=\"row_heading level0 row9\" >23</th>\n",
       "      <td id=\"T_ef068_row9_col0\" class=\"data row9 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row9_col1\" class=\"data row9 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row9_col2\" class=\"data row9 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row9_col3\" class=\"data row9 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row9_col4\" class=\"data row9 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row9_col5\" class=\"data row9 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row9_col6\" class=\"data row9 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row9_col7\" class=\"data row9 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row9_col8\" class=\"data row9 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row9_col9\" class=\"data row9 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row9_col10\" class=\"data row9 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row9_col11\" class=\"data row9 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row9_col12\" class=\"data row9 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row9_col13\" class=\"data row9 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row9_col14\" class=\"data row9 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row9_col15\" class=\"data row9 col15\" >False</td>\n",
       "      <td id=\"T_ef068_row9_col16\" class=\"data row9 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row9_col17\" class=\"data row9 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row9_col18\" class=\"data row9 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row9_col19\" class=\"data row9 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row9_col20\" class=\"data row9 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row9_col21\" class=\"data row9 col21\" >0.980115</td>\n",
       "      <td id=\"T_ef068_row9_col22\" class=\"data row9 col22\" >0.862174</td>\n",
       "      <td id=\"T_ef068_row9_col23\" class=\"data row9 col23\" >0.045891</td>\n",
       "      <td id=\"T_ef068_row9_col24\" class=\"data row9 col24\" >0.925293</td>\n",
       "      <td id=\"T_ef068_row9_col25\" class=\"data row9 col25\" >0.682617</td>\n",
       "      <td id=\"T_ef068_row9_col26\" class=\"data row9 col26\" >0.131770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row10\" class=\"row_heading level0 row10\" >25</th>\n",
       "      <td id=\"T_ef068_row10_col0\" class=\"data row10 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row10_col1\" class=\"data row10 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row10_col2\" class=\"data row10 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row10_col3\" class=\"data row10 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row10_col4\" class=\"data row10 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row10_col5\" class=\"data row10 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row10_col6\" class=\"data row10 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row10_col7\" class=\"data row10 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row10_col8\" class=\"data row10 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row10_col9\" class=\"data row10 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row10_col10\" class=\"data row10 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row10_col11\" class=\"data row10 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row10_col12\" class=\"data row10 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row10_col13\" class=\"data row10 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row10_col14\" class=\"data row10 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row10_col15\" class=\"data row10 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row10_col16\" class=\"data row10 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row10_col17\" class=\"data row10 col17\" >0.010000</td>\n",
       "      <td id=\"T_ef068_row10_col18\" class=\"data row10 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row10_col19\" class=\"data row10 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row10_col20\" class=\"data row10 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row10_col21\" class=\"data row10 col21\" >0.959927</td>\n",
       "      <td id=\"T_ef068_row10_col22\" class=\"data row10 col22\" >0.761081</td>\n",
       "      <td id=\"T_ef068_row10_col23\" class=\"data row10 col23\" >0.063798</td>\n",
       "      <td id=\"T_ef068_row10_col24\" class=\"data row10 col24\" >0.880859</td>\n",
       "      <td id=\"T_ef068_row10_col25\" class=\"data row10 col25\" >0.530273</td>\n",
       "      <td id=\"T_ef068_row10_col26\" class=\"data row10 col26\" >0.150084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row11\" class=\"row_heading level0 row11\" >26</th>\n",
       "      <td id=\"T_ef068_row11_col0\" class=\"data row11 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row11_col1\" class=\"data row11 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row11_col2\" class=\"data row11 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row11_col3\" class=\"data row11 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row11_col4\" class=\"data row11 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row11_col5\" class=\"data row11 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row11_col6\" class=\"data row11 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row11_col7\" class=\"data row11 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row11_col8\" class=\"data row11 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row11_col9\" class=\"data row11 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row11_col10\" class=\"data row11 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row11_col11\" class=\"data row11 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row11_col12\" class=\"data row11 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row11_col13\" class=\"data row11 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row11_col14\" class=\"data row11 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row11_col15\" class=\"data row11 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row11_col16\" class=\"data row11 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row11_col17\" class=\"data row11 col17\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row11_col18\" class=\"data row11 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row11_col19\" class=\"data row11 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row11_col20\" class=\"data row11 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row11_col21\" class=\"data row11 col21\" >0.964784</td>\n",
       "      <td id=\"T_ef068_row11_col22\" class=\"data row11 col22\" >0.826351</td>\n",
       "      <td id=\"T_ef068_row11_col23\" class=\"data row11 col23\" >0.049212</td>\n",
       "      <td id=\"T_ef068_row11_col24\" class=\"data row11 col24\" >0.900879</td>\n",
       "      <td id=\"T_ef068_row11_col25\" class=\"data row11 col25\" >0.627930</td>\n",
       "      <td id=\"T_ef068_row11_col26\" class=\"data row11 col26\" >0.134887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row12\" class=\"row_heading level0 row12\" >34</th>\n",
       "      <td id=\"T_ef068_row12_col0\" class=\"data row12 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row12_col1\" class=\"data row12 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row12_col2\" class=\"data row12 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row12_col3\" class=\"data row12 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row12_col4\" class=\"data row12 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row12_col5\" class=\"data row12 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row12_col6\" class=\"data row12 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row12_col7\" class=\"data row12 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row12_col8\" class=\"data row12 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row12_col9\" class=\"data row12 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row12_col10\" class=\"data row12 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row12_col11\" class=\"data row12 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row12_col12\" class=\"data row12 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row12_col13\" class=\"data row12 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row12_col14\" class=\"data row12 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row12_col15\" class=\"data row12 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row12_col16\" class=\"data row12 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row12_col17\" class=\"data row12 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row12_col18\" class=\"data row12 col18\" >3000</td>\n",
       "      <td id=\"T_ef068_row12_col19\" class=\"data row12 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row12_col20\" class=\"data row12 col20\" >512</td>\n",
       "      <td id=\"T_ef068_row12_col21\" class=\"data row12 col21\" >0.969945</td>\n",
       "      <td id=\"T_ef068_row12_col22\" class=\"data row12 col22\" >0.833789</td>\n",
       "      <td id=\"T_ef068_row12_col23\" class=\"data row12 col23\" >0.052237</td>\n",
       "      <td id=\"T_ef068_row12_col24\" class=\"data row12 col24\" >0.878418</td>\n",
       "      <td id=\"T_ef068_row12_col25\" class=\"data row12 col25\" >0.616211</td>\n",
       "      <td id=\"T_ef068_row12_col26\" class=\"data row12 col26\" >0.150475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row13\" class=\"row_heading level0 row13\" >33</th>\n",
       "      <td id=\"T_ef068_row13_col0\" class=\"data row13 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row13_col1\" class=\"data row13 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row13_col2\" class=\"data row13 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row13_col3\" class=\"data row13 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row13_col4\" class=\"data row13 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row13_col5\" class=\"data row13 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row13_col6\" class=\"data row13 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row13_col7\" class=\"data row13 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row13_col8\" class=\"data row13 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row13_col9\" class=\"data row13 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row13_col10\" class=\"data row13 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row13_col11\" class=\"data row13 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row13_col12\" class=\"data row13 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row13_col13\" class=\"data row13 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row13_col14\" class=\"data row13 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row13_col15\" class=\"data row13 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row13_col16\" class=\"data row13 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row13_col17\" class=\"data row13 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row13_col18\" class=\"data row13 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row13_col19\" class=\"data row13 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row13_col20\" class=\"data row13 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row13_col21\" class=\"data row13 col21\" >0.978142</td>\n",
       "      <td id=\"T_ef068_row13_col22\" class=\"data row13 col22\" >0.854736</td>\n",
       "      <td id=\"T_ef068_row13_col23\" class=\"data row13 col23\" >0.045719</td>\n",
       "      <td id=\"T_ef068_row13_col24\" class=\"data row13 col24\" >0.920898</td>\n",
       "      <td id=\"T_ef068_row13_col25\" class=\"data row13 col25\" >0.666016</td>\n",
       "      <td id=\"T_ef068_row13_col26\" class=\"data row13 col26\" >0.128519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row14\" class=\"row_heading level0 row14\" >32</th>\n",
       "      <td id=\"T_ef068_row14_col0\" class=\"data row14 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row14_col1\" class=\"data row14 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row14_col2\" class=\"data row14 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row14_col3\" class=\"data row14 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row14_col4\" class=\"data row14 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row14_col5\" class=\"data row14 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row14_col6\" class=\"data row14 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row14_col7\" class=\"data row14 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row14_col8\" class=\"data row14 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row14_col9\" class=\"data row14 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row14_col10\" class=\"data row14 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row14_col11\" class=\"data row14 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row14_col12\" class=\"data row14 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row14_col13\" class=\"data row14 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row14_col14\" class=\"data row14 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row14_col15\" class=\"data row14 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row14_col16\" class=\"data row14 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row14_col17\" class=\"data row14 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row14_col18\" class=\"data row14 col18\" >12000</td>\n",
       "      <td id=\"T_ef068_row14_col19\" class=\"data row14 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row14_col20\" class=\"data row14 col20\" >128</td>\n",
       "      <td id=\"T_ef068_row14_col21\" class=\"data row14 col21\" >0.970097</td>\n",
       "      <td id=\"T_ef068_row14_col22\" class=\"data row14 col22\" >0.840164</td>\n",
       "      <td id=\"T_ef068_row14_col23\" class=\"data row14 col23\" >0.047680</td>\n",
       "      <td id=\"T_ef068_row14_col24\" class=\"data row14 col24\" >0.879883</td>\n",
       "      <td id=\"T_ef068_row14_col25\" class=\"data row14 col25\" >0.642578</td>\n",
       "      <td id=\"T_ef068_row14_col26\" class=\"data row14 col26\" >0.117346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row15\" class=\"row_heading level0 row15\" >36</th>\n",
       "      <td id=\"T_ef068_row15_col0\" class=\"data row15 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row15_col1\" class=\"data row15 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row15_col2\" class=\"data row15 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row15_col3\" class=\"data row15 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row15_col4\" class=\"data row15 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row15_col5\" class=\"data row15 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row15_col6\" class=\"data row15 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row15_col7\" class=\"data row15 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row15_col8\" class=\"data row15 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row15_col9\" class=\"data row15 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row15_col10\" class=\"data row15 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row15_col11\" class=\"data row15 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row15_col12\" class=\"data row15 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row15_col13\" class=\"data row15 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row15_col14\" class=\"data row15 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row15_col15\" class=\"data row15 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row15_col16\" class=\"data row15 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row15_col17\" class=\"data row15 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row15_col18\" class=\"data row15 col18\" >12000</td>\n",
       "      <td id=\"T_ef068_row15_col19\" class=\"data row15 col19\" >800</td>\n",
       "      <td id=\"T_ef068_row15_col20\" class=\"data row15 col20\" >512</td>\n",
       "      <td id=\"T_ef068_row15_col21\" class=\"data row15 col21\" >0.976624</td>\n",
       "      <td id=\"T_ef068_row15_col22\" class=\"data row15 col22\" >0.859745</td>\n",
       "      <td id=\"T_ef068_row15_col23\" class=\"data row15 col23\" >0.044800</td>\n",
       "      <td id=\"T_ef068_row15_col24\" class=\"data row15 col24\" >0.901855</td>\n",
       "      <td id=\"T_ef068_row15_col25\" class=\"data row15 col25\" >0.656738</td>\n",
       "      <td id=\"T_ef068_row15_col26\" class=\"data row15 col26\" >0.140578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row16\" class=\"row_heading level0 row16\" >27</th>\n",
       "      <td id=\"T_ef068_row16_col0\" class=\"data row16 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row16_col1\" class=\"data row16 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row16_col2\" class=\"data row16 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row16_col3\" class=\"data row16 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row16_col4\" class=\"data row16 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row16_col5\" class=\"data row16 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row16_col6\" class=\"data row16 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row16_col7\" class=\"data row16 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row16_col8\" class=\"data row16 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row16_col9\" class=\"data row16 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row16_col10\" class=\"data row16 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row16_col11\" class=\"data row16 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row16_col12\" class=\"data row16 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row16_col13\" class=\"data row16 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row16_col14\" class=\"data row16 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row16_col15\" class=\"data row16 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row16_col16\" class=\"data row16 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row16_col17\" class=\"data row16 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row16_col18\" class=\"data row16 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row16_col19\" class=\"data row16 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row16_col20\" class=\"data row16 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row16_col21\" class=\"data row16 col21\" >0.971160</td>\n",
       "      <td id=\"T_ef068_row16_col22\" class=\"data row16 col22\" >0.824833</td>\n",
       "      <td id=\"T_ef068_row16_col23\" class=\"data row16 col23\" >0.050255</td>\n",
       "      <td id=\"T_ef068_row16_col24\" class=\"data row16 col24\" >0.909180</td>\n",
       "      <td id=\"T_ef068_row16_col25\" class=\"data row16 col25\" >0.623535</td>\n",
       "      <td id=\"T_ef068_row16_col26\" class=\"data row16 col26\" >0.125664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row17\" class=\"row_heading level0 row17\" >35</th>\n",
       "      <td id=\"T_ef068_row17_col0\" class=\"data row17 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row17_col1\" class=\"data row17 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row17_col2\" class=\"data row17 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row17_col3\" class=\"data row17 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row17_col4\" class=\"data row17 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row17_col5\" class=\"data row17 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row17_col6\" class=\"data row17 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row17_col7\" class=\"data row17 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row17_col8\" class=\"data row17 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row17_col9\" class=\"data row17 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row17_col10\" class=\"data row17 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row17_col11\" class=\"data row17 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row17_col12\" class=\"data row17 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row17_col13\" class=\"data row17 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row17_col14\" class=\"data row17 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row17_col15\" class=\"data row17 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row17_col16\" class=\"data row17 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row17_col17\" class=\"data row17 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row17_col18\" class=\"data row17 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row17_col19\" class=\"data row17 col19\" >3200</td>\n",
       "      <td id=\"T_ef068_row17_col20\" class=\"data row17 col20\" >512</td>\n",
       "      <td id=\"T_ef068_row17_col21\" class=\"data row17 col21\" >0.987705</td>\n",
       "      <td id=\"T_ef068_row17_col22\" class=\"data row17 col22\" >0.899666</td>\n",
       "      <td id=\"T_ef068_row17_col23\" class=\"data row17 col23\" >0.044012</td>\n",
       "      <td id=\"T_ef068_row17_col24\" class=\"data row17 col24\" >0.907715</td>\n",
       "      <td id=\"T_ef068_row17_col25\" class=\"data row17 col25\" >0.720703</td>\n",
       "      <td id=\"T_ef068_row17_col26\" class=\"data row17 col26\" >0.143123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row18\" class=\"row_heading level0 row18\" >28</th>\n",
       "      <td id=\"T_ef068_row18_col0\" class=\"data row18 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row18_col1\" class=\"data row18 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row18_col2\" class=\"data row18 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row18_col3\" class=\"data row18 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row18_col4\" class=\"data row18 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row18_col5\" class=\"data row18 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row18_col6\" class=\"data row18 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row18_col7\" class=\"data row18 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row18_col8\" class=\"data row18 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row18_col9\" class=\"data row18 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row18_col10\" class=\"data row18 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row18_col11\" class=\"data row18 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row18_col12\" class=\"data row18 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row18_col13\" class=\"data row18 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row18_col14\" class=\"data row18 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row18_col15\" class=\"data row18 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row18_col16\" class=\"data row18 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row18_col17\" class=\"data row18 col17\" >0.250000</td>\n",
       "      <td id=\"T_ef068_row18_col18\" class=\"data row18 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row18_col19\" class=\"data row18 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row18_col20\" class=\"data row18 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row18_col21\" class=\"data row18 col21\" >0.968579</td>\n",
       "      <td id=\"T_ef068_row18_col22\" class=\"data row18 col22\" >0.709624</td>\n",
       "      <td id=\"T_ef068_row18_col23\" class=\"data row18 col23\" >0.073895</td>\n",
       "      <td id=\"T_ef068_row18_col24\" class=\"data row18 col24\" >0.923828</td>\n",
       "      <td id=\"T_ef068_row18_col25\" class=\"data row18 col25\" >0.521973</td>\n",
       "      <td id=\"T_ef068_row18_col26\" class=\"data row18 col26\" >0.118576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row19\" class=\"row_heading level0 row19\" >6</th>\n",
       "      <td id=\"T_ef068_row19_col0\" class=\"data row19 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row19_col1\" class=\"data row19 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row19_col2\" class=\"data row19 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row19_col3\" class=\"data row19 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row19_col4\" class=\"data row19 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row19_col5\" class=\"data row19 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row19_col6\" class=\"data row19 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row19_col7\" class=\"data row19 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row19_col8\" class=\"data row19 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row19_col9\" class=\"data row19 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row19_col10\" class=\"data row19 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row19_col11\" class=\"data row19 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row19_col12\" class=\"data row19 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row19_col13\" class=\"data row19 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row19_col14\" class=\"data row19 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row19_col15\" class=\"data row19 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row19_col16\" class=\"data row19 col16\" >adam</td>\n",
       "      <td id=\"T_ef068_row19_col17\" class=\"data row19 col17\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row19_col18\" class=\"data row19 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row19_col19\" class=\"data row19 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row19_col20\" class=\"data row19 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row19_col21\" class=\"data row19 col21\" >0.959168</td>\n",
       "      <td id=\"T_ef068_row19_col22\" class=\"data row19 col22\" >0.727838</td>\n",
       "      <td id=\"T_ef068_row19_col23\" class=\"data row19 col23\" >0.070385</td>\n",
       "      <td id=\"T_ef068_row19_col24\" class=\"data row19 col24\" >0.896973</td>\n",
       "      <td id=\"T_ef068_row19_col25\" class=\"data row19 col25\" >0.516113</td>\n",
       "      <td id=\"T_ef068_row19_col26\" class=\"data row19 col26\" >0.166403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row20\" class=\"row_heading level0 row20\" >24</th>\n",
       "      <td id=\"T_ef068_row20_col0\" class=\"data row20 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row20_col1\" class=\"data row20 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row20_col2\" class=\"data row20 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row20_col3\" class=\"data row20 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row20_col4\" class=\"data row20 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row20_col5\" class=\"data row20 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row20_col6\" class=\"data row20 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row20_col7\" class=\"data row20 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row20_col8\" class=\"data row20 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row20_col9\" class=\"data row20 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row20_col10\" class=\"data row20 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row20_col11\" class=\"data row20 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row20_col12\" class=\"data row20 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row20_col13\" class=\"data row20 col13\" >True</td>\n",
       "      <td id=\"T_ef068_row20_col14\" class=\"data row20 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row20_col15\" class=\"data row20 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row20_col16\" class=\"data row20 col16\" >adam</td>\n",
       "      <td id=\"T_ef068_row20_col17\" class=\"data row20 col17\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row20_col18\" class=\"data row20 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row20_col19\" class=\"data row20 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row20_col20\" class=\"data row20 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row20_col21\" class=\"data row20 col21\" >0.960231</td>\n",
       "      <td id=\"T_ef068_row20_col22\" class=\"data row20 col22\" >0.716910</td>\n",
       "      <td id=\"T_ef068_row20_col23\" class=\"data row20 col23\" >0.073398</td>\n",
       "      <td id=\"T_ef068_row20_col24\" class=\"data row20 col24\" >0.922363</td>\n",
       "      <td id=\"T_ef068_row20_col25\" class=\"data row20 col25\" >0.522461</td>\n",
       "      <td id=\"T_ef068_row20_col26\" class=\"data row20 col26\" >0.144273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row21\" class=\"row_heading level0 row21\" >10</th>\n",
       "      <td id=\"T_ef068_row21_col0\" class=\"data row21 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row21_col1\" class=\"data row21 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row21_col2\" class=\"data row21 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row21_col3\" class=\"data row21 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row21_col4\" class=\"data row21 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row21_col5\" class=\"data row21 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row21_col6\" class=\"data row21 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row21_col7\" class=\"data row21 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row21_col8\" class=\"data row21 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row21_col9\" class=\"data row21 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row21_col10\" class=\"data row21 col10\" >True</td>\n",
       "      <td id=\"T_ef068_row21_col11\" class=\"data row21 col11\" >False</td>\n",
       "      <td id=\"T_ef068_row21_col12\" class=\"data row21 col12\" >True</td>\n",
       "      <td id=\"T_ef068_row21_col13\" class=\"data row21 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row21_col14\" class=\"data row21 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row21_col15\" class=\"data row21 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row21_col16\" class=\"data row21 col16\" >adam</td>\n",
       "      <td id=\"T_ef068_row21_col17\" class=\"data row21 col17\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row21_col18\" class=\"data row21 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row21_col19\" class=\"data row21 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row21_col20\" class=\"data row21 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row21_col21\" class=\"data row21 col21\" >0.960990</td>\n",
       "      <td id=\"T_ef068_row21_col22\" class=\"data row21 col22\" >0.716302</td>\n",
       "      <td id=\"T_ef068_row21_col23\" class=\"data row21 col23\" >0.073048</td>\n",
       "      <td id=\"T_ef068_row21_col24\" class=\"data row21 col24\" >0.917969</td>\n",
       "      <td id=\"T_ef068_row21_col25\" class=\"data row21 col25\" >0.523926</td>\n",
       "      <td id=\"T_ef068_row21_col26\" class=\"data row21 col26\" >0.143515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row22\" class=\"row_heading level0 row22\" >5</th>\n",
       "      <td id=\"T_ef068_row22_col0\" class=\"data row22 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row22_col1\" class=\"data row22 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row22_col2\" class=\"data row22 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row22_col3\" class=\"data row22 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row22_col4\" class=\"data row22 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row22_col5\" class=\"data row22 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row22_col6\" class=\"data row22 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row22_col7\" class=\"data row22 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row22_col8\" class=\"data row22 col8\" >8</td>\n",
       "      <td id=\"T_ef068_row22_col9\" class=\"data row22 col9\" >8</td>\n",
       "      <td id=\"T_ef068_row22_col10\" class=\"data row22 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row22_col11\" class=\"data row22 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row22_col12\" class=\"data row22 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row22_col13\" class=\"data row22 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row22_col14\" class=\"data row22 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row22_col15\" class=\"data row22 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row22_col16\" class=\"data row22 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row22_col17\" class=\"data row22 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row22_col18\" class=\"data row22 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row22_col19\" class=\"data row22 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row22_col20\" class=\"data row22 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row22_col21\" class=\"data row22 col21\" >0.979053</td>\n",
       "      <td id=\"T_ef068_row22_col22\" class=\"data row22 col22\" >0.860049</td>\n",
       "      <td id=\"T_ef068_row22_col23\" class=\"data row22 col23\" >0.047189</td>\n",
       "      <td id=\"T_ef068_row22_col24\" class=\"data row22 col24\" >0.943848</td>\n",
       "      <td id=\"T_ef068_row22_col25\" class=\"data row22 col25\" >0.691406</td>\n",
       "      <td id=\"T_ef068_row22_col26\" class=\"data row22 col26\" >0.123346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row23\" class=\"row_heading level0 row23\" >0</th>\n",
       "      <td id=\"T_ef068_row23_col0\" class=\"data row23 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row23_col1\" class=\"data row23 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row23_col2\" class=\"data row23 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row23_col3\" class=\"data row23 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row23_col4\" class=\"data row23 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row23_col5\" class=\"data row23 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row23_col6\" class=\"data row23 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row23_col7\" class=\"data row23 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row23_col8\" class=\"data row23 col8\" >10</td>\n",
       "      <td id=\"T_ef068_row23_col9\" class=\"data row23 col9\" >10</td>\n",
       "      <td id=\"T_ef068_row23_col10\" class=\"data row23 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row23_col11\" class=\"data row23 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row23_col12\" class=\"data row23 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row23_col13\" class=\"data row23 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row23_col14\" class=\"data row23 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row23_col15\" class=\"data row23 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row23_col16\" class=\"data row23 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row23_col17\" class=\"data row23 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row23_col18\" class=\"data row23 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row23_col19\" class=\"data row23 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row23_col20\" class=\"data row23 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row23_col21\" class=\"data row23 col21\" >0.979356</td>\n",
       "      <td id=\"T_ef068_row23_col22\" class=\"data row23 col22\" >0.861415</td>\n",
       "      <td id=\"T_ef068_row23_col23\" class=\"data row23 col23\" >0.047529</td>\n",
       "      <td id=\"T_ef068_row23_col24\" class=\"data row23 col24\" >0.933594</td>\n",
       "      <td id=\"T_ef068_row23_col25\" class=\"data row23 col25\" >0.694824</td>\n",
       "      <td id=\"T_ef068_row23_col26\" class=\"data row23 col26\" >0.119473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row24\" class=\"row_heading level0 row24\" >1</th>\n",
       "      <td id=\"T_ef068_row24_col0\" class=\"data row24 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row24_col1\" class=\"data row24 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row24_col2\" class=\"data row24 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row24_col3\" class=\"data row24 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row24_col4\" class=\"data row24 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row24_col5\" class=\"data row24 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row24_col6\" class=\"data row24 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row24_col7\" class=\"data row24 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row24_col8\" class=\"data row24 col8\" >12</td>\n",
       "      <td id=\"T_ef068_row24_col9\" class=\"data row24 col9\" >12</td>\n",
       "      <td id=\"T_ef068_row24_col10\" class=\"data row24 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row24_col11\" class=\"data row24 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row24_col12\" class=\"data row24 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row24_col13\" class=\"data row24 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row24_col14\" class=\"data row24 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row24_col15\" class=\"data row24 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row24_col16\" class=\"data row24 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row24_col17\" class=\"data row24 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row24_col18\" class=\"data row24 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row24_col19\" class=\"data row24 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row24_col20\" class=\"data row24 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row24_col21\" class=\"data row24 col21\" >0.974954</td>\n",
       "      <td id=\"T_ef068_row24_col22\" class=\"data row24 col22\" >0.857468</td>\n",
       "      <td id=\"T_ef068_row24_col23\" class=\"data row24 col23\" >0.048018</td>\n",
       "      <td id=\"T_ef068_row24_col24\" class=\"data row24 col24\" >0.912598</td>\n",
       "      <td id=\"T_ef068_row24_col25\" class=\"data row24 col25\" >0.677246</td>\n",
       "      <td id=\"T_ef068_row24_col26\" class=\"data row24 col26\" >0.124622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row25\" class=\"row_heading level0 row25\" >2</th>\n",
       "      <td id=\"T_ef068_row25_col0\" class=\"data row25 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row25_col1\" class=\"data row25 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row25_col2\" class=\"data row25 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row25_col3\" class=\"data row25 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row25_col4\" class=\"data row25 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row25_col5\" class=\"data row25 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row25_col6\" class=\"data row25 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row25_col7\" class=\"data row25 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row25_col8\" class=\"data row25 col8\" >16</td>\n",
       "      <td id=\"T_ef068_row25_col9\" class=\"data row25 col9\" >16</td>\n",
       "      <td id=\"T_ef068_row25_col10\" class=\"data row25 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row25_col11\" class=\"data row25 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row25_col12\" class=\"data row25 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row25_col13\" class=\"data row25 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row25_col14\" class=\"data row25 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row25_col15\" class=\"data row25 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row25_col16\" class=\"data row25 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row25_col17\" class=\"data row25 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row25_col18\" class=\"data row25 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row25_col19\" class=\"data row25 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row25_col20\" class=\"data row25 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row25_col21\" class=\"data row25 col21\" >0.974803</td>\n",
       "      <td id=\"T_ef068_row25_col22\" class=\"data row25 col22\" >0.857013</td>\n",
       "      <td id=\"T_ef068_row25_col23\" class=\"data row25 col23\" >0.048752</td>\n",
       "      <td id=\"T_ef068_row25_col24\" class=\"data row25 col24\" >0.757812</td>\n",
       "      <td id=\"T_ef068_row25_col25\" class=\"data row25 col25\" >0.595703</td>\n",
       "      <td id=\"T_ef068_row25_col26\" class=\"data row25 col26\" >0.158729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row26\" class=\"row_heading level0 row26\" >21</th>\n",
       "      <td id=\"T_ef068_row26_col0\" class=\"data row26 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row26_col1\" class=\"data row26 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row26_col2\" class=\"data row26 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row26_col3\" class=\"data row26 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row26_col4\" class=\"data row26 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row26_col5\" class=\"data row26 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row26_col6\" class=\"data row26 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row26_col7\" class=\"data row26 col7\" >True</td>\n",
       "      <td id=\"T_ef068_row26_col8\" class=\"data row26 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row26_col9\" class=\"data row26 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row26_col10\" class=\"data row26 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row26_col11\" class=\"data row26 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row26_col12\" class=\"data row26 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row26_col13\" class=\"data row26 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row26_col14\" class=\"data row26 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row26_col15\" class=\"data row26 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row26_col16\" class=\"data row26 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row26_col17\" class=\"data row26 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row26_col18\" class=\"data row26 col18\" >10000</td>\n",
       "      <td id=\"T_ef068_row26_col19\" class=\"data row26 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row26_col20\" class=\"data row26 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row26_col21\" class=\"data row26 col21\" >0.978597</td>\n",
       "      <td id=\"T_ef068_row26_col22\" class=\"data row26 col22\" >0.861263</td>\n",
       "      <td id=\"T_ef068_row26_col23\" class=\"data row26 col23\" >0.040617</td>\n",
       "      <td id=\"T_ef068_row26_col24\" class=\"data row26 col24\" >0.805664</td>\n",
       "      <td id=\"T_ef068_row26_col25\" class=\"data row26 col25\" >0.633301</td>\n",
       "      <td id=\"T_ef068_row26_col26\" class=\"data row26 col26\" >0.127682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row27\" class=\"row_heading level0 row27\" >29</th>\n",
       "      <td id=\"T_ef068_row27_col0\" class=\"data row27 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row27_col1\" class=\"data row27 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row27_col2\" class=\"data row27 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row27_col3\" class=\"data row27 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row27_col4\" class=\"data row27 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row27_col5\" class=\"data row27 col5\" >xavier</td>\n",
       "      <td id=\"T_ef068_row27_col6\" class=\"data row27 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row27_col7\" class=\"data row27 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row27_col8\" class=\"data row27 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row27_col9\" class=\"data row27 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row27_col10\" class=\"data row27 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row27_col11\" class=\"data row27 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row27_col12\" class=\"data row27 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row27_col13\" class=\"data row27 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row27_col14\" class=\"data row27 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row27_col15\" class=\"data row27 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row27_col16\" class=\"data row27 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row27_col17\" class=\"data row27 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row27_col18\" class=\"data row27 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row27_col19\" class=\"data row27 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row27_col20\" class=\"data row27 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row27_col21\" class=\"data row27 col21\" >0.978901</td>\n",
       "      <td id=\"T_ef068_row27_col22\" class=\"data row27 col22\" >0.855798</td>\n",
       "      <td id=\"T_ef068_row27_col23\" class=\"data row27 col23\" >0.046261</td>\n",
       "      <td id=\"T_ef068_row27_col24\" class=\"data row27 col24\" >0.945801</td>\n",
       "      <td id=\"T_ef068_row27_col25\" class=\"data row27 col25\" >0.697754</td>\n",
       "      <td id=\"T_ef068_row27_col26\" class=\"data row27 col26\" >0.114236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row28\" class=\"row_heading level0 row28\" >30</th>\n",
       "      <td id=\"T_ef068_row28_col0\" class=\"data row28 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row28_col1\" class=\"data row28 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row28_col2\" class=\"data row28 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row28_col3\" class=\"data row28 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row28_col4\" class=\"data row28 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row28_col5\" class=\"data row28 col5\" >xavier</td>\n",
       "      <td id=\"T_ef068_row28_col6\" class=\"data row28 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row28_col7\" class=\"data row28 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row28_col8\" class=\"data row28 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row28_col9\" class=\"data row28 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row28_col10\" class=\"data row28 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row28_col11\" class=\"data row28 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row28_col12\" class=\"data row28 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row28_col13\" class=\"data row28 col13\" >True</td>\n",
       "      <td id=\"T_ef068_row28_col14\" class=\"data row28 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row28_col15\" class=\"data row28 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row28_col16\" class=\"data row28 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row28_col17\" class=\"data row28 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row28_col18\" class=\"data row28 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row28_col19\" class=\"data row28 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row28_col20\" class=\"data row28 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row28_col21\" class=\"data row28 col21\" >0.969186</td>\n",
       "      <td id=\"T_ef068_row28_col22\" class=\"data row28 col22\" >0.850789</td>\n",
       "      <td id=\"T_ef068_row28_col23\" class=\"data row28 col23\" >0.048823</td>\n",
       "      <td id=\"T_ef068_row28_col24\" class=\"data row28 col24\" >0.905273</td>\n",
       "      <td id=\"T_ef068_row28_col25\" class=\"data row28 col25\" >0.655273</td>\n",
       "      <td id=\"T_ef068_row28_col26\" class=\"data row28 col26\" >0.128929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row29\" class=\"row_heading level0 row29\" >31</th>\n",
       "      <td id=\"T_ef068_row29_col0\" class=\"data row29 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row29_col1\" class=\"data row29 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row29_col2\" class=\"data row29 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row29_col3\" class=\"data row29 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row29_col4\" class=\"data row29 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row29_col5\" class=\"data row29 col5\" >xavier</td>\n",
       "      <td id=\"T_ef068_row29_col6\" class=\"data row29 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row29_col7\" class=\"data row29 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row29_col8\" class=\"data row29 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row29_col9\" class=\"data row29 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row29_col10\" class=\"data row29 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row29_col11\" class=\"data row29 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row29_col12\" class=\"data row29 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row29_col13\" class=\"data row29 col13\" >True</td>\n",
       "      <td id=\"T_ef068_row29_col14\" class=\"data row29 col14\" >True</td>\n",
       "      <td id=\"T_ef068_row29_col15\" class=\"data row29 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row29_col16\" class=\"data row29 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row29_col17\" class=\"data row29 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row29_col18\" class=\"data row29 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row29_col19\" class=\"data row29 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row29_col20\" class=\"data row29 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row29_col21\" class=\"data row29 col21\" >0.976776</td>\n",
       "      <td id=\"T_ef068_row29_col22\" class=\"data row29 col22\" >0.852307</td>\n",
       "      <td id=\"T_ef068_row29_col23\" class=\"data row29 col23\" >0.046058</td>\n",
       "      <td id=\"T_ef068_row29_col24\" class=\"data row29 col24\" >0.903320</td>\n",
       "      <td id=\"T_ef068_row29_col25\" class=\"data row29 col25\" >0.653320</td>\n",
       "      <td id=\"T_ef068_row29_col26\" class=\"data row29 col26\" >0.126217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row30\" class=\"row_heading level0 row30\" >17</th>\n",
       "      <td id=\"T_ef068_row30_col0\" class=\"data row30 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row30_col1\" class=\"data row30 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row30_col2\" class=\"data row30 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row30_col3\" class=\"data row30 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row30_col4\" class=\"data row30 col4\" >256</td>\n",
       "      <td id=\"T_ef068_row30_col5\" class=\"data row30 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row30_col6\" class=\"data row30 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row30_col7\" class=\"data row30 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row30_col8\" class=\"data row30 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row30_col9\" class=\"data row30 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row30_col10\" class=\"data row30 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row30_col11\" class=\"data row30 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row30_col12\" class=\"data row30 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row30_col13\" class=\"data row30 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row30_col14\" class=\"data row30 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row30_col15\" class=\"data row30 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row30_col16\" class=\"data row30 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row30_col17\" class=\"data row30 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row30_col18\" class=\"data row30 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row30_col19\" class=\"data row30 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row30_col20\" class=\"data row30 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row30_col21\" class=\"data row30 col21\" >0.980419</td>\n",
       "      <td id=\"T_ef068_row30_col22\" class=\"data row30 col22\" >0.887826</td>\n",
       "      <td id=\"T_ef068_row30_col23\" class=\"data row30 col23\" >0.045192</td>\n",
       "      <td id=\"T_ef068_row30_col24\" class=\"data row30 col24\" >0.869629</td>\n",
       "      <td id=\"T_ef068_row30_col25\" class=\"data row30 col25\" >0.656738</td>\n",
       "      <td id=\"T_ef068_row30_col26\" class=\"data row30 col26\" >0.161693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row31\" class=\"row_heading level0 row31\" >18</th>\n",
       "      <td id=\"T_ef068_row31_col0\" class=\"data row31 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row31_col1\" class=\"data row31 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row31_col2\" class=\"data row31 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row31_col3\" class=\"data row31 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row31_col4\" class=\"data row31 col4\" >512</td>\n",
       "      <td id=\"T_ef068_row31_col5\" class=\"data row31 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row31_col6\" class=\"data row31 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row31_col7\" class=\"data row31 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row31_col8\" class=\"data row31 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row31_col9\" class=\"data row31 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row31_col10\" class=\"data row31 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row31_col11\" class=\"data row31 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row31_col12\" class=\"data row31 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row31_col13\" class=\"data row31 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row31_col14\" class=\"data row31 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row31_col15\" class=\"data row31 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row31_col16\" class=\"data row31 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row31_col17\" class=\"data row31 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row31_col18\" class=\"data row31 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row31_col19\" class=\"data row31 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row31_col20\" class=\"data row31 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row31_col21\" class=\"data row31 col21\" >0.000152</td>\n",
       "      <td id=\"T_ef068_row31_col22\" class=\"data row31 col22\" >0.000152</td>\n",
       "      <td id=\"T_ef068_row31_col23\" class=\"data row31 col23\" >0.790861</td>\n",
       "      <td id=\"T_ef068_row31_col24\" class=\"data row31 col24\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row31_col25\" class=\"data row31 col25\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row31_col26\" class=\"data row31 col26\" >0.798695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row32\" class=\"row_heading level0 row32\" >20</th>\n",
       "      <td id=\"T_ef068_row32_col0\" class=\"data row32 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row32_col1\" class=\"data row32 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row32_col2\" class=\"data row32 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row32_col3\" class=\"data row32 col3\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row32_col4\" class=\"data row32 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row32_col5\" class=\"data row32 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row32_col6\" class=\"data row32 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row32_col7\" class=\"data row32 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row32_col8\" class=\"data row32 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row32_col9\" class=\"data row32 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row32_col10\" class=\"data row32 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row32_col11\" class=\"data row32 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row32_col12\" class=\"data row32 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row32_col13\" class=\"data row32 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row32_col14\" class=\"data row32 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row32_col15\" class=\"data row32 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row32_col16\" class=\"data row32 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row32_col17\" class=\"data row32 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row32_col18\" class=\"data row32 col18\" >6000</td>\n",
       "      <td id=\"T_ef068_row32_col19\" class=\"data row32 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row32_col20\" class=\"data row32 col20\" >256</td>\n",
       "      <td id=\"T_ef068_row32_col21\" class=\"data row32 col21\" >0.966910</td>\n",
       "      <td id=\"T_ef068_row32_col22\" class=\"data row32 col22\" >0.822860</td>\n",
       "      <td id=\"T_ef068_row32_col23\" class=\"data row32 col23\" >0.051705</td>\n",
       "      <td id=\"T_ef068_row32_col24\" class=\"data row32 col24\" >0.922852</td>\n",
       "      <td id=\"T_ef068_row32_col25\" class=\"data row32 col25\" >0.640137</td>\n",
       "      <td id=\"T_ef068_row32_col26\" class=\"data row32 col26\" >0.117378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row33\" class=\"row_heading level0 row33\" >7</th>\n",
       "      <td id=\"T_ef068_row33_col0\" class=\"data row33 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row33_col1\" class=\"data row33 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row33_col2\" class=\"data row33 col2\" >1.000000</td>\n",
       "      <td id=\"T_ef068_row33_col3\" class=\"data row33 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row33_col4\" class=\"data row33 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row33_col5\" class=\"data row33 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row33_col6\" class=\"data row33 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row33_col7\" class=\"data row33 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row33_col8\" class=\"data row33 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row33_col9\" class=\"data row33 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row33_col10\" class=\"data row33 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row33_col11\" class=\"data row33 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row33_col12\" class=\"data row33 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row33_col13\" class=\"data row33 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row33_col14\" class=\"data row33 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row33_col15\" class=\"data row33 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row33_col16\" class=\"data row33 col16\" >adam</td>\n",
       "      <td id=\"T_ef068_row33_col17\" class=\"data row33 col17\" >0.000000</td>\n",
       "      <td id=\"T_ef068_row33_col18\" class=\"data row33 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row33_col19\" class=\"data row33 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row33_col20\" class=\"data row33 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row33_col21\" class=\"data row33 col21\" >0.934730</td>\n",
       "      <td id=\"T_ef068_row33_col22\" class=\"data row33 col22\" >0.658470</td>\n",
       "      <td id=\"T_ef068_row33_col23\" class=\"data row33 col23\" >0.088125</td>\n",
       "      <td id=\"T_ef068_row33_col24\" class=\"data row33 col24\" >0.859375</td>\n",
       "      <td id=\"T_ef068_row33_col25\" class=\"data row33 col25\" >0.448242</td>\n",
       "      <td id=\"T_ef068_row33_col26\" class=\"data row33 col26\" >0.166683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row34\" class=\"row_heading level0 row34\" >37</th>\n",
       "      <td id=\"T_ef068_row34_col0\" class=\"data row34 col0\" >30</td>\n",
       "      <td id=\"T_ef068_row34_col1\" class=\"data row34 col1\" >data/train_data_2^20.npy</td>\n",
       "      <td id=\"T_ef068_row34_col2\" class=\"data row34 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row34_col3\" class=\"data row34 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row34_col4\" class=\"data row34 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row34_col5\" class=\"data row34 col5\" >xavier</td>\n",
       "      <td id=\"T_ef068_row34_col6\" class=\"data row34 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row34_col7\" class=\"data row34 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row34_col8\" class=\"data row34 col8\" >10</td>\n",
       "      <td id=\"T_ef068_row34_col9\" class=\"data row34 col9\" >10</td>\n",
       "      <td id=\"T_ef068_row34_col10\" class=\"data row34 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row34_col11\" class=\"data row34 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row34_col12\" class=\"data row34 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row34_col13\" class=\"data row34 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row34_col14\" class=\"data row34 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row34_col15\" class=\"data row34 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row34_col16\" class=\"data row34 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row34_col17\" class=\"data row34 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row34_col18\" class=\"data row34 col18\" >1200</td>\n",
       "      <td id=\"T_ef068_row34_col19\" class=\"data row34 col19\" >300</td>\n",
       "      <td id=\"T_ef068_row34_col20\" class=\"data row34 col20\" >2048</td>\n",
       "      <td id=\"T_ef068_row34_col21\" class=\"data row34 col21\" >0.984165</td>\n",
       "      <td id=\"T_ef068_row34_col22\" class=\"data row34 col22\" >0.776742</td>\n",
       "      <td id=\"T_ef068_row34_col23\" class=\"data row34 col23\" >0.055534</td>\n",
       "      <td id=\"T_ef068_row34_col24\" class=\"data row34 col24\" >0.979492</td>\n",
       "      <td id=\"T_ef068_row34_col25\" class=\"data row34 col25\" >0.628174</td>\n",
       "      <td id=\"T_ef068_row34_col26\" class=\"data row34 col26\" >0.090952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row35\" class=\"row_heading level0 row35\" >16</th>\n",
       "      <td id=\"T_ef068_row35_col0\" class=\"data row35 col0\" >90</td>\n",
       "      <td id=\"T_ef068_row35_col1\" class=\"data row35 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row35_col2\" class=\"data row35 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row35_col3\" class=\"data row35 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row35_col4\" class=\"data row35 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row35_col5\" class=\"data row35 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row35_col6\" class=\"data row35 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row35_col7\" class=\"data row35 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row35_col8\" class=\"data row35 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row35_col9\" class=\"data row35 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row35_col10\" class=\"data row35 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row35_col11\" class=\"data row35 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row35_col12\" class=\"data row35 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row35_col13\" class=\"data row35 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row35_col14\" class=\"data row35 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row35_col15\" class=\"data row35 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row35_col16\" class=\"data row35 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row35_col17\" class=\"data row35 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row35_col18\" class=\"data row35 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row35_col19\" class=\"data row35 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row35_col20\" class=\"data row35 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row35_col21\" class=\"data row35 col21\" >0.985124</td>\n",
       "      <td id=\"T_ef068_row35_col22\" class=\"data row35 col22\" >0.848057</td>\n",
       "      <td id=\"T_ef068_row35_col23\" class=\"data row35 col23\" >0.042097</td>\n",
       "      <td id=\"T_ef068_row35_col24\" class=\"data row35 col24\" >0.587891</td>\n",
       "      <td id=\"T_ef068_row35_col25\" class=\"data row35 col25\" >0.341797</td>\n",
       "      <td id=\"T_ef068_row35_col26\" class=\"data row35 col26\" >0.222875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row36\" class=\"row_heading level0 row36\" >13</th>\n",
       "      <td id=\"T_ef068_row36_col0\" class=\"data row36 col0\" >210</td>\n",
       "      <td id=\"T_ef068_row36_col1\" class=\"data row36 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row36_col2\" class=\"data row36 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row36_col3\" class=\"data row36 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row36_col4\" class=\"data row36 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row36_col5\" class=\"data row36 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row36_col6\" class=\"data row36 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row36_col7\" class=\"data row36 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row36_col8\" class=\"data row36 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row36_col9\" class=\"data row36 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row36_col10\" class=\"data row36 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row36_col11\" class=\"data row36 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row36_col12\" class=\"data row36 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row36_col13\" class=\"data row36 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row36_col14\" class=\"data row36 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row36_col15\" class=\"data row36 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row36_col16\" class=\"data row36 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row36_col17\" class=\"data row36 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row36_col18\" class=\"data row36 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row36_col19\" class=\"data row36 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row36_col20\" class=\"data row36 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row36_col21\" class=\"data row36 col21\" >0.987553</td>\n",
       "      <td id=\"T_ef068_row36_col22\" class=\"data row36 col22\" >0.906497</td>\n",
       "      <td id=\"T_ef068_row36_col23\" class=\"data row36 col23\" >0.032362</td>\n",
       "      <td id=\"T_ef068_row36_col24\" class=\"data row36 col24\" >0.287109</td>\n",
       "      <td id=\"T_ef068_row36_col25\" class=\"data row36 col25\" >0.211426</td>\n",
       "      <td id=\"T_ef068_row36_col26\" class=\"data row36 col26\" >0.512774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef068_level0_row37\" class=\"row_heading level0 row37\" >14</th>\n",
       "      <td id=\"T_ef068_row37_col0\" class=\"data row37 col0\" >237</td>\n",
       "      <td id=\"T_ef068_row37_col1\" class=\"data row37 col1\" >data/train_data_2^16.npy</td>\n",
       "      <td id=\"T_ef068_row37_col2\" class=\"data row37 col2\" >0.500000</td>\n",
       "      <td id=\"T_ef068_row37_col3\" class=\"data row37 col3\" >0.050000</td>\n",
       "      <td id=\"T_ef068_row37_col4\" class=\"data row37 col4\" >128</td>\n",
       "      <td id=\"T_ef068_row37_col5\" class=\"data row37 col5\" >normal</td>\n",
       "      <td id=\"T_ef068_row37_col6\" class=\"data row37 col6\" >True</td>\n",
       "      <td id=\"T_ef068_row37_col7\" class=\"data row37 col7\" >False</td>\n",
       "      <td id=\"T_ef068_row37_col8\" class=\"data row37 col8\" >6</td>\n",
       "      <td id=\"T_ef068_row37_col9\" class=\"data row37 col9\" >6</td>\n",
       "      <td id=\"T_ef068_row37_col10\" class=\"data row37 col10\" >False</td>\n",
       "      <td id=\"T_ef068_row37_col11\" class=\"data row37 col11\" >True</td>\n",
       "      <td id=\"T_ef068_row37_col12\" class=\"data row37 col12\" >False</td>\n",
       "      <td id=\"T_ef068_row37_col13\" class=\"data row37 col13\" >False</td>\n",
       "      <td id=\"T_ef068_row37_col14\" class=\"data row37 col14\" >False</td>\n",
       "      <td id=\"T_ef068_row37_col15\" class=\"data row37 col15\" >True</td>\n",
       "      <td id=\"T_ef068_row37_col16\" class=\"data row37 col16\" >AdamW</td>\n",
       "      <td id=\"T_ef068_row37_col17\" class=\"data row37 col17\" >0.100000</td>\n",
       "      <td id=\"T_ef068_row37_col18\" class=\"data row37 col18\" >24000</td>\n",
       "      <td id=\"T_ef068_row37_col19\" class=\"data row37 col19\" >200</td>\n",
       "      <td id=\"T_ef068_row37_col20\" class=\"data row37 col20\" >64</td>\n",
       "      <td id=\"T_ef068_row37_col21\" class=\"data row37 col21\" >0.957498</td>\n",
       "      <td id=\"T_ef068_row37_col22\" class=\"data row37 col22\" >0.853673</td>\n",
       "      <td id=\"T_ef068_row37_col23\" class=\"data row37 col23\" >0.047474</td>\n",
       "      <td id=\"T_ef068_row37_col24\" class=\"data row37 col24\" >0.164062</td>\n",
       "      <td id=\"T_ef068_row37_col25\" class=\"data row37 col25\" >0.106445</td>\n",
       "      <td id=\"T_ef068_row37_col26\" class=\"data row37 col26\" >0.509020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eb82e1bfa0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df.sort_values(hyperparam_cols).style.apply(style_col_axis_1, axis=0, subset=metrics_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rework this:\n",
    "* There should be a function that subset the dataframe to the rows we care about\n",
    "* That function should get used in abalte hyperparamater + ablate loss hist plot\n",
    "* Right now there are two functiuons and they kinda work differently... they should just be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_identifier_for_hparam_sets(df, hparam_cols, values, col_name='color'): \n",
    "    df['groupby_hps'] = df[hparam_cols].apply(lambda x: '_'.join([str(y) for y in x]), axis=1)\n",
    "#     df.sort_values('groupby_hps', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df[col_name] = values[0]\n",
    "    value_counter = 0\n",
    "    for i in range(1, df.shape[0]):\n",
    "        this_row_hps = df.iloc[i]['groupby_hps']\n",
    "        prev_row_hps = df.iloc[i-1]['groupby_hps']\n",
    "        if not this_row_hps==prev_row_hps:\n",
    "            value_counter +=1\n",
    "        df.loc[i, col_name] = values[value_counter%len(values)]\n",
    "        if value_counter>=len(values):\n",
    "            warnings.warn(f'More unique combinations of hyperparams found than unique {col_name}; {col_name} will not be unique')\n",
    "    df.drop('groupby_hps', axis=1, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['rgba(255,0,0,.5)', 'rgba(48,213,200,.5)', 'rgba(159,43,104,.5)', 'rgba(230,190,138,.5)']\n",
    "\n",
    "def ablate_hyperparameter(metric_df, hparams, show_specific_hparams=None, show_all_other_hparams=False, show_if_nonconstant=True):\n",
    "    id_col_name = 'color'\n",
    "    if isinstance(hparams, str):\n",
    "        hparams = [hparams]\n",
    "    hparams = hparams\n",
    "    groupby_hps = [c for c in hyperparam_cols if not c in hparams]\n",
    "    grouped = metric_df.groupby(groupby_hps)\n",
    "    grouped = grouped.filter(lambda x: len(x) > 1)\n",
    "    grouped = add_identifier_for_hparam_sets(grouped, groupby_hps, colors, id_col_name)\n",
    "\n",
    "    \n",
    "    # Have a list of params want to show\n",
    "    # Want to show just ones that have unique values\n",
    "    # Show all of them\n",
    "    \n",
    "    if show_specific_hparams:\n",
    "          if isinstance(show_specific_hparams, str):\n",
    "            show_specific_hparams = [show_specific_hparams]\n",
    "    else:\n",
    "        show_specific_hparams = []\n",
    "    \n",
    "    show_cols = [c for c in grouped.columns if not (c in groupby_hps) or c==id_col_name]\n",
    "    for c in groupby_hps:\n",
    "        if (show_all_other_hparams) or (show_specific_hparams in show_specific_hparams) or (show_if_nonconstant and grouped[c].nunique() > 1):\n",
    "            show_cols.append(c)\n",
    "            \n",
    "    grouped = grouped[[c for c in show_cols]]\n",
    "    grouped.sort_values(hparams, inplace=True)\n",
    "\n",
    "    \n",
    "#     hide_params = [id_col_name]\n",
    "#     for c in grouped.columns:\n",
    "#         if (not show_all_other_hparams) or (not c in show_specific_hparams) or \\\n",
    "#            (hide_just_constant_hparams and grouped[c].nunique() == 1):\n",
    "#             hide_params.append(c)\n",
    "            \n",
    "#     grouped = grouped[c for c in grouped.columns if not c in hide_params]\n",
    "    \n",
    "    \n",
    "#     if show_specific_hparams:\n",
    "#         if isinstance(show_specific_hparams, str):\n",
    "#             show_specific_hparams = [show_specific_hparams]\n",
    "#         grouped = grouped[[c for c in metric_df.columns if (not c in groupby_hps) or (c in show_specific_hparams) or (c=='color')]]\n",
    "#     elif not show_all_other_hparams:\n",
    "#         grouped = grouped[[c for c in grouped.columns if (not c in groupby_hps) or c==id_col_name]]\n",
    "        \n",
    "    return grouped.style.hide_columns([id_col_name]).apply(style_df, axis=None, ablated_hparams = hparams, n_highlight=1)\n",
    "#     return grouped.style.apply(style_col, axis=0, subset=metrics_full + [id_col_name], n_highlight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-b9323a2d0d65>:18: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  to_return = np.zeros_like(df.values, dtype=np.object)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_52b5f_row0_col1, #T_52b5f_row0_col2, #T_52b5f_row0_col3, #T_52b5f_row0_col4, #T_52b5f_row0_col5, #T_52b5f_row0_col6, #T_52b5f_row0_col7, #T_52b5f_row1_col7, #T_52b5f_row2_col1, #T_52b5f_row2_col2, #T_52b5f_row2_col3, #T_52b5f_row2_col4, #T_52b5f_row2_col5, #T_52b5f_row2_col6, #T_52b5f_row2_col7, #T_52b5f_row3_col1, #T_52b5f_row3_col2, #T_52b5f_row3_col3, #T_52b5f_row3_col4, #T_52b5f_row3_col5, #T_52b5f_row3_col6 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "#T_52b5f_row0_col8, #T_52b5f_row0_col9, #T_52b5f_row0_col10, #T_52b5f_row0_col11, #T_52b5f_row0_col12, #T_52b5f_row2_col8, #T_52b5f_row2_col9, #T_52b5f_row2_col10, #T_52b5f_row2_col11, #T_52b5f_row2_col12 {\n",
       "  background-color: rgba(255,0,0,.5);\n",
       "}\n",
       "#T_52b5f_row1_col1, #T_52b5f_row1_col2, #T_52b5f_row1_col3, #T_52b5f_row1_col4, #T_52b5f_row1_col5, #T_52b5f_row1_col6, #T_52b5f_row3_col7 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "#T_52b5f_row1_col8, #T_52b5f_row1_col9, #T_52b5f_row1_col10, #T_52b5f_row1_col11, #T_52b5f_row1_col12, #T_52b5f_row3_col8, #T_52b5f_row3_col9, #T_52b5f_row3_col10, #T_52b5f_row3_col11, #T_52b5f_row3_col12 {\n",
       "  background-color: rgba(48,213,200,.5);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_52b5f_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >scale_embeddings</th>\n",
       "      <th class=\"col_heading level0 col1\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col2\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col3\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col4\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col5\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col6\" >loss_oos</th>\n",
       "      <th class=\"col_heading level0 col8\" >embedding_initialization</th>\n",
       "      <th class=\"col_heading level0 col9\" >optimizer</th>\n",
       "      <th class=\"col_heading level0 col10\" >weight_decay</th>\n",
       "      <th class=\"col_heading level0 col11\" >num_warmup_steps</th>\n",
       "      <th class=\"col_heading level0 col12\" >effective_train_batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_52b5f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_52b5f_row0_col0\" class=\"data row0 col0\" >False</td>\n",
       "      <td id=\"T_52b5f_row0_col1\" class=\"data row0 col1\" >0.959168</td>\n",
       "      <td id=\"T_52b5f_row0_col2\" class=\"data row0 col2\" >0.727838</td>\n",
       "      <td id=\"T_52b5f_row0_col3\" class=\"data row0 col3\" >0.070385</td>\n",
       "      <td id=\"T_52b5f_row0_col4\" class=\"data row0 col4\" >0.896973</td>\n",
       "      <td id=\"T_52b5f_row0_col5\" class=\"data row0 col5\" >0.516113</td>\n",
       "      <td id=\"T_52b5f_row0_col6\" class=\"data row0 col6\" >0.166403</td>\n",
       "      <td id=\"T_52b5f_row0_col8\" class=\"data row0 col8\" >normal</td>\n",
       "      <td id=\"T_52b5f_row0_col9\" class=\"data row0 col9\" >adam</td>\n",
       "      <td id=\"T_52b5f_row0_col10\" class=\"data row0 col10\" >0.000000</td>\n",
       "      <td id=\"T_52b5f_row0_col11\" class=\"data row0 col11\" >24000</td>\n",
       "      <td id=\"T_52b5f_row0_col12\" class=\"data row0 col12\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52b5f_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_52b5f_row1_col0\" class=\"data row1 col0\" >False</td>\n",
       "      <td id=\"T_52b5f_row1_col1\" class=\"data row1 col1\" >0.978901</td>\n",
       "      <td id=\"T_52b5f_row1_col2\" class=\"data row1 col2\" >0.855798</td>\n",
       "      <td id=\"T_52b5f_row1_col3\" class=\"data row1 col3\" >0.046261</td>\n",
       "      <td id=\"T_52b5f_row1_col4\" class=\"data row1 col4\" >0.945801</td>\n",
       "      <td id=\"T_52b5f_row1_col5\" class=\"data row1 col5\" >0.697754</td>\n",
       "      <td id=\"T_52b5f_row1_col6\" class=\"data row1 col6\" >0.114236</td>\n",
       "      <td id=\"T_52b5f_row1_col8\" class=\"data row1 col8\" >xavier</td>\n",
       "      <td id=\"T_52b5f_row1_col9\" class=\"data row1 col9\" >AdamW</td>\n",
       "      <td id=\"T_52b5f_row1_col10\" class=\"data row1 col10\" >0.100000</td>\n",
       "      <td id=\"T_52b5f_row1_col11\" class=\"data row1 col11\" >6000</td>\n",
       "      <td id=\"T_52b5f_row1_col12\" class=\"data row1 col12\" >256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52b5f_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_52b5f_row2_col0\" class=\"data row2 col0\" >True</td>\n",
       "      <td id=\"T_52b5f_row2_col1\" class=\"data row2 col1\" >0.960231</td>\n",
       "      <td id=\"T_52b5f_row2_col2\" class=\"data row2 col2\" >0.716910</td>\n",
       "      <td id=\"T_52b5f_row2_col3\" class=\"data row2 col3\" >0.073398</td>\n",
       "      <td id=\"T_52b5f_row2_col4\" class=\"data row2 col4\" >0.922363</td>\n",
       "      <td id=\"T_52b5f_row2_col5\" class=\"data row2 col5\" >0.522461</td>\n",
       "      <td id=\"T_52b5f_row2_col6\" class=\"data row2 col6\" >0.144273</td>\n",
       "      <td id=\"T_52b5f_row2_col8\" class=\"data row2 col8\" >normal</td>\n",
       "      <td id=\"T_52b5f_row2_col9\" class=\"data row2 col9\" >adam</td>\n",
       "      <td id=\"T_52b5f_row2_col10\" class=\"data row2 col10\" >0.000000</td>\n",
       "      <td id=\"T_52b5f_row2_col11\" class=\"data row2 col11\" >24000</td>\n",
       "      <td id=\"T_52b5f_row2_col12\" class=\"data row2 col12\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52b5f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_52b5f_row3_col0\" class=\"data row3 col0\" >True</td>\n",
       "      <td id=\"T_52b5f_row3_col1\" class=\"data row3 col1\" >0.969186</td>\n",
       "      <td id=\"T_52b5f_row3_col2\" class=\"data row3 col2\" >0.850789</td>\n",
       "      <td id=\"T_52b5f_row3_col3\" class=\"data row3 col3\" >0.048823</td>\n",
       "      <td id=\"T_52b5f_row3_col4\" class=\"data row3 col4\" >0.905273</td>\n",
       "      <td id=\"T_52b5f_row3_col5\" class=\"data row3 col5\" >0.655273</td>\n",
       "      <td id=\"T_52b5f_row3_col6\" class=\"data row3 col6\" >0.128929</td>\n",
       "      <td id=\"T_52b5f_row3_col8\" class=\"data row3 col8\" >xavier</td>\n",
       "      <td id=\"T_52b5f_row3_col9\" class=\"data row3 col9\" >AdamW</td>\n",
       "      <td id=\"T_52b5f_row3_col10\" class=\"data row3 col10\" >0.100000</td>\n",
       "      <td id=\"T_52b5f_row3_col11\" class=\"data row3 col11\" >6000</td>\n",
       "      <td id=\"T_52b5f_row3_col12\" class=\"data row3 col12\" >256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eb83179c70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_hyperparameter(metric_df, 'scale_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-b9323a2d0d65>:18: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  to_return = np.zeros_like(df.values, dtype=np.object)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4996_row0_col2, #T_d4996_row0_col3, #T_d4996_row0_col4, #T_d4996_row0_col5, #T_d4996_row0_col6, #T_d4996_row0_col7, #T_d4996_row0_col8, #T_d4996_row1_col2, #T_d4996_row1_col3, #T_d4996_row1_col4, #T_d4996_row1_col5, #T_d4996_row1_col6, #T_d4996_row1_col7, #T_d4996_row1_col8, #T_d4996_row2_col2, #T_d4996_row2_col5, #T_d4996_row2_col7, #T_d4996_row2_col8, #T_d4996_row3_col3, #T_d4996_row3_col4, #T_d4996_row3_col5, #T_d4996_row3_col6, #T_d4996_row3_col7, #T_d4996_row3_col8, #T_d4996_row4_col2, #T_d4996_row4_col3, #T_d4996_row4_col4, #T_d4996_row4_col6 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "#T_d4996_row2_col3, #T_d4996_row2_col4, #T_d4996_row2_col6, #T_d4996_row3_col2, #T_d4996_row4_col5, #T_d4996_row4_col7, #T_d4996_row4_col8 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4996_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >optimizer</th>\n",
       "      <th class=\"col_heading level0 col1\" >weight_decay</th>\n",
       "      <th class=\"col_heading level0 col2\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col3\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col4\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col5\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col6\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col7\" >loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4996_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d4996_row0_col0\" class=\"data row0 col0\" >adam</td>\n",
       "      <td id=\"T_d4996_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_d4996_row0_col2\" class=\"data row0 col2\" >0.959168</td>\n",
       "      <td id=\"T_d4996_row0_col3\" class=\"data row0 col3\" >0.727838</td>\n",
       "      <td id=\"T_d4996_row0_col4\" class=\"data row0 col4\" >0.070385</td>\n",
       "      <td id=\"T_d4996_row0_col5\" class=\"data row0 col5\" >0.896973</td>\n",
       "      <td id=\"T_d4996_row0_col6\" class=\"data row0 col6\" >0.516113</td>\n",
       "      <td id=\"T_d4996_row0_col7\" class=\"data row0 col7\" >0.166403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4996_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d4996_row1_col0\" class=\"data row1 col0\" >AdamW</td>\n",
       "      <td id=\"T_d4996_row1_col1\" class=\"data row1 col1\" >0.010000</td>\n",
       "      <td id=\"T_d4996_row1_col2\" class=\"data row1 col2\" >0.959927</td>\n",
       "      <td id=\"T_d4996_row1_col3\" class=\"data row1 col3\" >0.761081</td>\n",
       "      <td id=\"T_d4996_row1_col4\" class=\"data row1 col4\" >0.063798</td>\n",
       "      <td id=\"T_d4996_row1_col5\" class=\"data row1 col5\" >0.880859</td>\n",
       "      <td id=\"T_d4996_row1_col6\" class=\"data row1 col6\" >0.530273</td>\n",
       "      <td id=\"T_d4996_row1_col7\" class=\"data row1 col7\" >0.150084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4996_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d4996_row2_col0\" class=\"data row2 col0\" >AdamW</td>\n",
       "      <td id=\"T_d4996_row2_col1\" class=\"data row2 col1\" >0.050000</td>\n",
       "      <td id=\"T_d4996_row2_col2\" class=\"data row2 col2\" >0.964784</td>\n",
       "      <td id=\"T_d4996_row2_col3\" class=\"data row2 col3\" >0.826351</td>\n",
       "      <td id=\"T_d4996_row2_col4\" class=\"data row2 col4\" >0.049212</td>\n",
       "      <td id=\"T_d4996_row2_col5\" class=\"data row2 col5\" >0.900879</td>\n",
       "      <td id=\"T_d4996_row2_col6\" class=\"data row2 col6\" >0.627930</td>\n",
       "      <td id=\"T_d4996_row2_col7\" class=\"data row2 col7\" >0.134887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4996_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d4996_row3_col0\" class=\"data row3 col0\" >AdamW</td>\n",
       "      <td id=\"T_d4996_row3_col1\" class=\"data row3 col1\" >0.100000</td>\n",
       "      <td id=\"T_d4996_row3_col2\" class=\"data row3 col2\" >0.971160</td>\n",
       "      <td id=\"T_d4996_row3_col3\" class=\"data row3 col3\" >0.824833</td>\n",
       "      <td id=\"T_d4996_row3_col4\" class=\"data row3 col4\" >0.050255</td>\n",
       "      <td id=\"T_d4996_row3_col5\" class=\"data row3 col5\" >0.909180</td>\n",
       "      <td id=\"T_d4996_row3_col6\" class=\"data row3 col6\" >0.623535</td>\n",
       "      <td id=\"T_d4996_row3_col7\" class=\"data row3 col7\" >0.125664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4996_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d4996_row4_col0\" class=\"data row4 col0\" >AdamW</td>\n",
       "      <td id=\"T_d4996_row4_col1\" class=\"data row4 col1\" >0.250000</td>\n",
       "      <td id=\"T_d4996_row4_col2\" class=\"data row4 col2\" >0.968579</td>\n",
       "      <td id=\"T_d4996_row4_col3\" class=\"data row4 col3\" >0.709624</td>\n",
       "      <td id=\"T_d4996_row4_col4\" class=\"data row4 col4\" >0.073895</td>\n",
       "      <td id=\"T_d4996_row4_col5\" class=\"data row4 col5\" >0.923828</td>\n",
       "      <td id=\"T_d4996_row4_col6\" class=\"data row4 col6\" >0.521973</td>\n",
       "      <td id=\"T_d4996_row4_col7\" class=\"data row4 col7\" >0.118576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eb8336eee0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_hyperparameter(metric_df, ['weight_decay', 'optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_53c15_row0_col2, #T_53c15_row0_col3, #T_53c15_row0_col4, #T_53c15_row0_col5, #T_53c15_row0_col6, #T_53c15_row0_col7, #T_53c15_row0_col8, #T_53c15_row1_col2, #T_53c15_row1_col3, #T_53c15_row1_col4, #T_53c15_row1_col5, #T_53c15_row1_col6, #T_53c15_row1_col8, #T_53c15_row2_col7, #T_53c15_row2_col8, #T_53c15_row3_col2, #T_53c15_row3_col3, #T_53c15_row3_col4, #T_53c15_row3_col5, #T_53c15_row3_col6, #T_53c15_row3_col7 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "#T_53c15_row1_col7, #T_53c15_row2_col2, #T_53c15_row2_col3, #T_53c15_row2_col4, #T_53c15_row2_col5, #T_53c15_row2_col6, #T_53c15_row3_col8 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_53c15_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >num_warmup_steps</th>\n",
       "      <th class=\"col_heading level0 col1\" >effective_train_batch_size</th>\n",
       "      <th class=\"col_heading level0 col2\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col3\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col4\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col5\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col6\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col7\" >loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_53c15_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_53c15_row0_col0\" class=\"data row0 col0\" >24000</td>\n",
       "      <td id=\"T_53c15_row0_col1\" class=\"data row0 col1\" >64</td>\n",
       "      <td id=\"T_53c15_row0_col2\" class=\"data row0 col2\" >0.971160</td>\n",
       "      <td id=\"T_53c15_row0_col3\" class=\"data row0 col3\" >0.824833</td>\n",
       "      <td id=\"T_53c15_row0_col4\" class=\"data row0 col4\" >0.050255</td>\n",
       "      <td id=\"T_53c15_row0_col5\" class=\"data row0 col5\" >0.909180</td>\n",
       "      <td id=\"T_53c15_row0_col6\" class=\"data row0 col6\" >0.623535</td>\n",
       "      <td id=\"T_53c15_row0_col7\" class=\"data row0 col7\" >0.125664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c15_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_53c15_row1_col0\" class=\"data row1 col0\" >12000</td>\n",
       "      <td id=\"T_53c15_row1_col1\" class=\"data row1 col1\" >128</td>\n",
       "      <td id=\"T_53c15_row1_col2\" class=\"data row1 col2\" >0.970097</td>\n",
       "      <td id=\"T_53c15_row1_col3\" class=\"data row1 col3\" >0.840164</td>\n",
       "      <td id=\"T_53c15_row1_col4\" class=\"data row1 col4\" >0.047680</td>\n",
       "      <td id=\"T_53c15_row1_col5\" class=\"data row1 col5\" >0.879883</td>\n",
       "      <td id=\"T_53c15_row1_col6\" class=\"data row1 col6\" >0.642578</td>\n",
       "      <td id=\"T_53c15_row1_col7\" class=\"data row1 col7\" >0.117346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c15_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_53c15_row2_col0\" class=\"data row2 col0\" >6000</td>\n",
       "      <td id=\"T_53c15_row2_col1\" class=\"data row2 col1\" >256</td>\n",
       "      <td id=\"T_53c15_row2_col2\" class=\"data row2 col2\" >0.978142</td>\n",
       "      <td id=\"T_53c15_row2_col3\" class=\"data row2 col3\" >0.854736</td>\n",
       "      <td id=\"T_53c15_row2_col4\" class=\"data row2 col4\" >0.045719</td>\n",
       "      <td id=\"T_53c15_row2_col5\" class=\"data row2 col5\" >0.920898</td>\n",
       "      <td id=\"T_53c15_row2_col6\" class=\"data row2 col6\" >0.666016</td>\n",
       "      <td id=\"T_53c15_row2_col7\" class=\"data row2 col7\" >0.128519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53c15_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_53c15_row3_col0\" class=\"data row3 col0\" >3000</td>\n",
       "      <td id=\"T_53c15_row3_col1\" class=\"data row3 col1\" >512</td>\n",
       "      <td id=\"T_53c15_row3_col2\" class=\"data row3 col2\" >0.969945</td>\n",
       "      <td id=\"T_53c15_row3_col3\" class=\"data row3 col3\" >0.833789</td>\n",
       "      <td id=\"T_53c15_row3_col4\" class=\"data row3 col4\" >0.052237</td>\n",
       "      <td id=\"T_53c15_row3_col5\" class=\"data row3 col5\" >0.878418</td>\n",
       "      <td id=\"T_53c15_row3_col6\" class=\"data row3 col6\" >0.616211</td>\n",
       "      <td id=\"T_53c15_row3_col7\" class=\"data row3 col7\" >0.150475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21fd135c070>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_hyperparameter(metric_df, ['effective_train_batch_size', 'num_warmup_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_969d9_row0_col2, #T_969d9_row0_col3, #T_969d9_row0_col4, #T_969d9_row0_col5, #T_969d9_row0_col6, #T_969d9_row0_col7, #T_969d9_row0_col8, #T_969d9_row1_col2, #T_969d9_row1_col3, #T_969d9_row1_col4, #T_969d9_row1_col5, #T_969d9_row1_col6, #T_969d9_row1_col8, #T_969d9_row2_col7 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "#T_969d9_row1_col7, #T_969d9_row2_col2, #T_969d9_row2_col3, #T_969d9_row2_col4, #T_969d9_row2_col5, #T_969d9_row2_col6, #T_969d9_row2_col8 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_969d9_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >num_warmup_steps</th>\n",
       "      <th class=\"col_heading level0 col1\" >nb_epochs</th>\n",
       "      <th class=\"col_heading level0 col2\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col3\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col4\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col5\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col6\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col7\" >loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_969d9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_969d9_row0_col0\" class=\"data row0 col0\" >3000</td>\n",
       "      <td id=\"T_969d9_row0_col1\" class=\"data row0 col1\" >200</td>\n",
       "      <td id=\"T_969d9_row0_col2\" class=\"data row0 col2\" >0.969945</td>\n",
       "      <td id=\"T_969d9_row0_col3\" class=\"data row0 col3\" >0.833789</td>\n",
       "      <td id=\"T_969d9_row0_col4\" class=\"data row0 col4\" >0.052237</td>\n",
       "      <td id=\"T_969d9_row0_col5\" class=\"data row0 col5\" >0.878418</td>\n",
       "      <td id=\"T_969d9_row0_col6\" class=\"data row0 col6\" >0.616211</td>\n",
       "      <td id=\"T_969d9_row0_col7\" class=\"data row0 col7\" >0.150475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_969d9_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_969d9_row1_col0\" class=\"data row1 col0\" >12000</td>\n",
       "      <td id=\"T_969d9_row1_col1\" class=\"data row1 col1\" >800</td>\n",
       "      <td id=\"T_969d9_row1_col2\" class=\"data row1 col2\" >0.976624</td>\n",
       "      <td id=\"T_969d9_row1_col3\" class=\"data row1 col3\" >0.859745</td>\n",
       "      <td id=\"T_969d9_row1_col4\" class=\"data row1 col4\" >0.044800</td>\n",
       "      <td id=\"T_969d9_row1_col5\" class=\"data row1 col5\" >0.901855</td>\n",
       "      <td id=\"T_969d9_row1_col6\" class=\"data row1 col6\" >0.656738</td>\n",
       "      <td id=\"T_969d9_row1_col7\" class=\"data row1 col7\" >0.140578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_969d9_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_969d9_row2_col0\" class=\"data row2 col0\" >24000</td>\n",
       "      <td id=\"T_969d9_row2_col1\" class=\"data row2 col1\" >3200</td>\n",
       "      <td id=\"T_969d9_row2_col2\" class=\"data row2 col2\" >0.987705</td>\n",
       "      <td id=\"T_969d9_row2_col3\" class=\"data row2 col3\" >0.899666</td>\n",
       "      <td id=\"T_969d9_row2_col4\" class=\"data row2 col4\" >0.044012</td>\n",
       "      <td id=\"T_969d9_row2_col5\" class=\"data row2 col5\" >0.907715</td>\n",
       "      <td id=\"T_969d9_row2_col6\" class=\"data row2 col6\" >0.720703</td>\n",
       "      <td id=\"T_969d9_row2_col7\" class=\"data row2 col7\" >0.143123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21fd1346490>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_hyperparameter(metric_df, ['nb_epochs', 'num_warmup_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bc21c_row0_col3, #T_bc21c_row0_col4, #T_bc21c_row0_col5, #T_bc21c_row0_col6, #T_bc21c_row0_col7, #T_bc21c_row0_col8, #T_bc21c_row0_col9, #T_bc21c_row1_col3, #T_bc21c_row1_col4, #T_bc21c_row1_col6, #T_bc21c_row1_col7, #T_bc21c_row1_col8, #T_bc21c_row1_col9, #T_bc21c_row2_col3, #T_bc21c_row2_col4, #T_bc21c_row2_col5, #T_bc21c_row2_col6, #T_bc21c_row2_col7, #T_bc21c_row2_col8, #T_bc21c_row2_col9, #T_bc21c_row3_col5, #T_bc21c_row3_col9, #T_bc21c_row4_col3, #T_bc21c_row4_col4, #T_bc21c_row4_col5, #T_bc21c_row4_col6, #T_bc21c_row4_col7, #T_bc21c_row4_col8, #T_bc21c_row4_col9, #T_bc21c_row5_col3, #T_bc21c_row5_col4, #T_bc21c_row5_col5, #T_bc21c_row5_col6, #T_bc21c_row5_col7, #T_bc21c_row5_col8 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "#T_bc21c_row0_col10, #T_bc21c_row0_col11, #T_bc21c_row0_col12, #T_bc21c_row0_col13, #T_bc21c_row2_col10, #T_bc21c_row2_col11, #T_bc21c_row2_col12, #T_bc21c_row2_col13 {\n",
       "  background-color: rgba(255,0,0,.5);\n",
       "}\n",
       "#T_bc21c_row1_col5, #T_bc21c_row3_col3, #T_bc21c_row3_col4, #T_bc21c_row3_col6, #T_bc21c_row3_col7, #T_bc21c_row3_col8, #T_bc21c_row5_col9 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "#T_bc21c_row1_col10, #T_bc21c_row1_col11, #T_bc21c_row1_col12, #T_bc21c_row1_col13, #T_bc21c_row3_col10, #T_bc21c_row3_col11, #T_bc21c_row3_col12, #T_bc21c_row3_col13, #T_bc21c_row4_col10, #T_bc21c_row4_col11, #T_bc21c_row4_col12, #T_bc21c_row4_col13, #T_bc21c_row5_col10, #T_bc21c_row5_col11, #T_bc21c_row5_col12, #T_bc21c_row5_col13 {\n",
       "  background-color: rgba(48,213,200,.5);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bc21c_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >embedding_initialization</th>\n",
       "      <th class=\"col_heading level0 col1\" >scale_embeddings</th>\n",
       "      <th class=\"col_heading level0 col2\" >scale_embeddings_at_init</th>\n",
       "      <th class=\"col_heading level0 col3\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col4\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col5\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col6\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col7\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col8\" >loss_oos</th>\n",
       "      <th class=\"col_heading level0 col10\" >optimizer</th>\n",
       "      <th class=\"col_heading level0 col11\" >weight_decay</th>\n",
       "      <th class=\"col_heading level0 col12\" >num_warmup_steps</th>\n",
       "      <th class=\"col_heading level0 col13\" >effective_train_batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bc21c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bc21c_row0_col0\" class=\"data row0 col0\" >normal</td>\n",
       "      <td id=\"T_bc21c_row0_col1\" class=\"data row0 col1\" >False</td>\n",
       "      <td id=\"T_bc21c_row0_col2\" class=\"data row0 col2\" >False</td>\n",
       "      <td id=\"T_bc21c_row0_col3\" class=\"data row0 col3\" >0.959168</td>\n",
       "      <td id=\"T_bc21c_row0_col4\" class=\"data row0 col4\" >0.727838</td>\n",
       "      <td id=\"T_bc21c_row0_col5\" class=\"data row0 col5\" >0.070385</td>\n",
       "      <td id=\"T_bc21c_row0_col6\" class=\"data row0 col6\" >0.896973</td>\n",
       "      <td id=\"T_bc21c_row0_col7\" class=\"data row0 col7\" >0.516113</td>\n",
       "      <td id=\"T_bc21c_row0_col8\" class=\"data row0 col8\" >0.166403</td>\n",
       "      <td id=\"T_bc21c_row0_col10\" class=\"data row0 col10\" >adam</td>\n",
       "      <td id=\"T_bc21c_row0_col11\" class=\"data row0 col11\" >0.000000</td>\n",
       "      <td id=\"T_bc21c_row0_col12\" class=\"data row0 col12\" >24000</td>\n",
       "      <td id=\"T_bc21c_row0_col13\" class=\"data row0 col13\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc21c_level0_row1\" class=\"row_heading level0 row1\" >5</th>\n",
       "      <td id=\"T_bc21c_row1_col0\" class=\"data row1 col0\" >normal</td>\n",
       "      <td id=\"T_bc21c_row1_col1\" class=\"data row1 col1\" >False</td>\n",
       "      <td id=\"T_bc21c_row1_col2\" class=\"data row1 col2\" >False</td>\n",
       "      <td id=\"T_bc21c_row1_col3\" class=\"data row1 col3\" >0.978142</td>\n",
       "      <td id=\"T_bc21c_row1_col4\" class=\"data row1 col4\" >0.854736</td>\n",
       "      <td id=\"T_bc21c_row1_col5\" class=\"data row1 col5\" >0.045719</td>\n",
       "      <td id=\"T_bc21c_row1_col6\" class=\"data row1 col6\" >0.920898</td>\n",
       "      <td id=\"T_bc21c_row1_col7\" class=\"data row1 col7\" >0.666016</td>\n",
       "      <td id=\"T_bc21c_row1_col8\" class=\"data row1 col8\" >0.128519</td>\n",
       "      <td id=\"T_bc21c_row1_col10\" class=\"data row1 col10\" >AdamW</td>\n",
       "      <td id=\"T_bc21c_row1_col11\" class=\"data row1 col11\" >0.100000</td>\n",
       "      <td id=\"T_bc21c_row1_col12\" class=\"data row1 col12\" >6000</td>\n",
       "      <td id=\"T_bc21c_row1_col13\" class=\"data row1 col13\" >256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc21c_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_bc21c_row2_col0\" class=\"data row2 col0\" >normal</td>\n",
       "      <td id=\"T_bc21c_row2_col1\" class=\"data row2 col1\" >True</td>\n",
       "      <td id=\"T_bc21c_row2_col2\" class=\"data row2 col2\" >False</td>\n",
       "      <td id=\"T_bc21c_row2_col3\" class=\"data row2 col3\" >0.960231</td>\n",
       "      <td id=\"T_bc21c_row2_col4\" class=\"data row2 col4\" >0.716910</td>\n",
       "      <td id=\"T_bc21c_row2_col5\" class=\"data row2 col5\" >0.073398</td>\n",
       "      <td id=\"T_bc21c_row2_col6\" class=\"data row2 col6\" >0.922363</td>\n",
       "      <td id=\"T_bc21c_row2_col7\" class=\"data row2 col7\" >0.522461</td>\n",
       "      <td id=\"T_bc21c_row2_col8\" class=\"data row2 col8\" >0.144273</td>\n",
       "      <td id=\"T_bc21c_row2_col10\" class=\"data row2 col10\" >adam</td>\n",
       "      <td id=\"T_bc21c_row2_col11\" class=\"data row2 col11\" >0.000000</td>\n",
       "      <td id=\"T_bc21c_row2_col12\" class=\"data row2 col12\" >24000</td>\n",
       "      <td id=\"T_bc21c_row2_col13\" class=\"data row2 col13\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc21c_level0_row3\" class=\"row_heading level0 row3\" >2</th>\n",
       "      <td id=\"T_bc21c_row3_col0\" class=\"data row3 col0\" >xavier</td>\n",
       "      <td id=\"T_bc21c_row3_col1\" class=\"data row3 col1\" >False</td>\n",
       "      <td id=\"T_bc21c_row3_col2\" class=\"data row3 col2\" >False</td>\n",
       "      <td id=\"T_bc21c_row3_col3\" class=\"data row3 col3\" >0.978901</td>\n",
       "      <td id=\"T_bc21c_row3_col4\" class=\"data row3 col4\" >0.855798</td>\n",
       "      <td id=\"T_bc21c_row3_col5\" class=\"data row3 col5\" >0.046261</td>\n",
       "      <td id=\"T_bc21c_row3_col6\" class=\"data row3 col6\" >0.945801</td>\n",
       "      <td id=\"T_bc21c_row3_col7\" class=\"data row3 col7\" >0.697754</td>\n",
       "      <td id=\"T_bc21c_row3_col8\" class=\"data row3 col8\" >0.114236</td>\n",
       "      <td id=\"T_bc21c_row3_col10\" class=\"data row3 col10\" >AdamW</td>\n",
       "      <td id=\"T_bc21c_row3_col11\" class=\"data row3 col11\" >0.100000</td>\n",
       "      <td id=\"T_bc21c_row3_col12\" class=\"data row3 col12\" >6000</td>\n",
       "      <td id=\"T_bc21c_row3_col13\" class=\"data row3 col13\" >256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc21c_level0_row4\" class=\"row_heading level0 row4\" >3</th>\n",
       "      <td id=\"T_bc21c_row4_col0\" class=\"data row4 col0\" >xavier</td>\n",
       "      <td id=\"T_bc21c_row4_col1\" class=\"data row4 col1\" >True</td>\n",
       "      <td id=\"T_bc21c_row4_col2\" class=\"data row4 col2\" >False</td>\n",
       "      <td id=\"T_bc21c_row4_col3\" class=\"data row4 col3\" >0.969186</td>\n",
       "      <td id=\"T_bc21c_row4_col4\" class=\"data row4 col4\" >0.850789</td>\n",
       "      <td id=\"T_bc21c_row4_col5\" class=\"data row4 col5\" >0.048823</td>\n",
       "      <td id=\"T_bc21c_row4_col6\" class=\"data row4 col6\" >0.905273</td>\n",
       "      <td id=\"T_bc21c_row4_col7\" class=\"data row4 col7\" >0.655273</td>\n",
       "      <td id=\"T_bc21c_row4_col8\" class=\"data row4 col8\" >0.128929</td>\n",
       "      <td id=\"T_bc21c_row4_col10\" class=\"data row4 col10\" >AdamW</td>\n",
       "      <td id=\"T_bc21c_row4_col11\" class=\"data row4 col11\" >0.100000</td>\n",
       "      <td id=\"T_bc21c_row4_col12\" class=\"data row4 col12\" >6000</td>\n",
       "      <td id=\"T_bc21c_row4_col13\" class=\"data row4 col13\" >256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc21c_level0_row5\" class=\"row_heading level0 row5\" >4</th>\n",
       "      <td id=\"T_bc21c_row5_col0\" class=\"data row5 col0\" >xavier</td>\n",
       "      <td id=\"T_bc21c_row5_col1\" class=\"data row5 col1\" >True</td>\n",
       "      <td id=\"T_bc21c_row5_col2\" class=\"data row5 col2\" >True</td>\n",
       "      <td id=\"T_bc21c_row5_col3\" class=\"data row5 col3\" >0.976776</td>\n",
       "      <td id=\"T_bc21c_row5_col4\" class=\"data row5 col4\" >0.852307</td>\n",
       "      <td id=\"T_bc21c_row5_col5\" class=\"data row5 col5\" >0.046058</td>\n",
       "      <td id=\"T_bc21c_row5_col6\" class=\"data row5 col6\" >0.903320</td>\n",
       "      <td id=\"T_bc21c_row5_col7\" class=\"data row5 col7\" >0.653320</td>\n",
       "      <td id=\"T_bc21c_row5_col8\" class=\"data row5 col8\" >0.126217</td>\n",
       "      <td id=\"T_bc21c_row5_col10\" class=\"data row5 col10\" >AdamW</td>\n",
       "      <td id=\"T_bc21c_row5_col11\" class=\"data row5 col11\" >0.100000</td>\n",
       "      <td id=\"T_bc21c_row5_col12\" class=\"data row5 col12\" >6000</td>\n",
       "      <td id=\"T_bc21c_row5_col13\" class=\"data row5 col13\" >256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21fd0fdf520>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_hyperparameter(metric_df, ['embedding_initialization', 'scale_embeddings', 'scale_embeddings_at_init'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9639b_row0_col1, #T_9639b_row0_col2, #T_9639b_row0_col3, #T_9639b_row0_col5, #T_9639b_row1_col4, #T_9639b_row1_col6, #T_9639b_row1_col7 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "#T_9639b_row0_col4, #T_9639b_row0_col6, #T_9639b_row0_col7, #T_9639b_row1_col1, #T_9639b_row1_col2, #T_9639b_row1_col3, #T_9639b_row1_col5 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9639b_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >dropout</th>\n",
       "      <th class=\"col_heading level0 col1\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col2\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col3\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col4\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col5\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col6\" >loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9639b_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_9639b_row0_col0\" class=\"data row0 col0\" >0.050000</td>\n",
       "      <td id=\"T_9639b_row0_col1\" class=\"data row0 col1\" >0.978142</td>\n",
       "      <td id=\"T_9639b_row0_col2\" class=\"data row0 col2\" >0.854736</td>\n",
       "      <td id=\"T_9639b_row0_col3\" class=\"data row0 col3\" >0.045719</td>\n",
       "      <td id=\"T_9639b_row0_col4\" class=\"data row0 col4\" >0.920898</td>\n",
       "      <td id=\"T_9639b_row0_col5\" class=\"data row0 col5\" >0.666016</td>\n",
       "      <td id=\"T_9639b_row0_col6\" class=\"data row0 col6\" >0.128519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9639b_level0_row1\" class=\"row_heading level0 row1\" >0</th>\n",
       "      <td id=\"T_9639b_row1_col0\" class=\"data row1 col0\" >0.100000</td>\n",
       "      <td id=\"T_9639b_row1_col1\" class=\"data row1 col1\" >0.966910</td>\n",
       "      <td id=\"T_9639b_row1_col2\" class=\"data row1 col2\" >0.822860</td>\n",
       "      <td id=\"T_9639b_row1_col3\" class=\"data row1 col3\" >0.051705</td>\n",
       "      <td id=\"T_9639b_row1_col4\" class=\"data row1 col4\" >0.922852</td>\n",
       "      <td id=\"T_9639b_row1_col5\" class=\"data row1 col5\" >0.640137</td>\n",
       "      <td id=\"T_9639b_row1_col6\" class=\"data row1 col6\" >0.117378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bcf8fae910>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_hyperparameter(metric_df, ['dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_61235_row0_col1, #T_61235_row0_col2, #T_61235_row0_col4, #T_61235_row0_col5, #T_61235_row1_col3, #T_61235_row1_col6, #T_61235_row1_col7 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "#T_61235_row0_col3, #T_61235_row0_col6, #T_61235_row0_col7, #T_61235_row1_col1, #T_61235_row1_col2, #T_61235_row1_col4, #T_61235_row1_col5 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_61235_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >shared_embeddings</th>\n",
       "      <th class=\"col_heading level0 col1\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col2\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col3\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col4\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col5\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col6\" >loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_61235_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_61235_row0_col0\" class=\"data row0 col0\" >False</td>\n",
       "      <td id=\"T_61235_row0_col1\" class=\"data row0 col1\" >0.980115</td>\n",
       "      <td id=\"T_61235_row0_col2\" class=\"data row0 col2\" >0.862174</td>\n",
       "      <td id=\"T_61235_row0_col3\" class=\"data row0 col3\" >0.045891</td>\n",
       "      <td id=\"T_61235_row0_col4\" class=\"data row0 col4\" >0.925293</td>\n",
       "      <td id=\"T_61235_row0_col5\" class=\"data row0 col5\" >0.682617</td>\n",
       "      <td id=\"T_61235_row0_col6\" class=\"data row0 col6\" >0.131770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61235_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_61235_row1_col0\" class=\"data row1 col0\" >True</td>\n",
       "      <td id=\"T_61235_row1_col1\" class=\"data row1 col1\" >0.978142</td>\n",
       "      <td id=\"T_61235_row1_col2\" class=\"data row1 col2\" >0.854736</td>\n",
       "      <td id=\"T_61235_row1_col3\" class=\"data row1 col3\" >0.045719</td>\n",
       "      <td id=\"T_61235_row1_col4\" class=\"data row1 col4\" >0.920898</td>\n",
       "      <td id=\"T_61235_row1_col5\" class=\"data row1 col5\" >0.666016</td>\n",
       "      <td id=\"T_61235_row1_col6\" class=\"data row1 col6\" >0.128519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bcf8c01430>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_hyperparameter(metric_df, ['shared_embeddings'], show_specific_hparams = ['dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_79d19_row0_col1, #T_79d19_row0_col2, #T_79d19_row0_col4, #T_79d19_row0_col5, #T_79d19_row1_col3, #T_79d19_row1_col6, #T_79d19_row1_col7 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "#T_79d19_row0_col3, #T_79d19_row0_col6, #T_79d19_row0_col7, #T_79d19_row1_col1, #T_79d19_row1_col2, #T_79d19_row1_col4, #T_79d19_row1_col5 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_79d19_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >shared_embeddings</th>\n",
       "      <th class=\"col_heading level0 col1\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col2\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col3\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col4\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col5\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col6\" >loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_79d19_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_79d19_row0_col0\" class=\"data row0 col0\" >False</td>\n",
       "      <td id=\"T_79d19_row0_col1\" class=\"data row0 col1\" >0.980115</td>\n",
       "      <td id=\"T_79d19_row0_col2\" class=\"data row0 col2\" >0.862174</td>\n",
       "      <td id=\"T_79d19_row0_col3\" class=\"data row0 col3\" >0.045891</td>\n",
       "      <td id=\"T_79d19_row0_col4\" class=\"data row0 col4\" >0.925293</td>\n",
       "      <td id=\"T_79d19_row0_col5\" class=\"data row0 col5\" >0.682617</td>\n",
       "      <td id=\"T_79d19_row0_col6\" class=\"data row0 col6\" >0.131770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_79d19_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_79d19_row1_col0\" class=\"data row1 col0\" >True</td>\n",
       "      <td id=\"T_79d19_row1_col1\" class=\"data row1 col1\" >0.978142</td>\n",
       "      <td id=\"T_79d19_row1_col2\" class=\"data row1 col2\" >0.854736</td>\n",
       "      <td id=\"T_79d19_row1_col3\" class=\"data row1 col3\" >0.045719</td>\n",
       "      <td id=\"T_79d19_row1_col4\" class=\"data row1 col4\" >0.920898</td>\n",
       "      <td id=\"T_79d19_row1_col5\" class=\"data row1 col5\" >0.666016</td>\n",
       "      <td id=\"T_79d19_row1_col6\" class=\"data row1 col6\" >0.128519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21fd10edd30>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_hyperparameter(metric_df, ['shared_embeddings'], show_specific_hparams = ['dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e219c_row0_col2, #T_e219c_row0_col3, #T_e219c_row0_col4, #T_e219c_row0_col5, #T_e219c_row0_col6, #T_e219c_row0_col7, #T_e219c_row0_col8, #T_e219c_row1_col2, #T_e219c_row1_col3, #T_e219c_row1_col4, #T_e219c_row1_col5, #T_e219c_row1_col6, #T_e219c_row1_col7, #T_e219c_row1_col8, #T_e219c_row2_col2, #T_e219c_row2_col3, #T_e219c_row2_col5, #T_e219c_row2_col6, #T_e219c_row2_col7, #T_e219c_row2_col8, #T_e219c_row3_col2, #T_e219c_row3_col3, #T_e219c_row3_col4, #T_e219c_row3_col6, #T_e219c_row3_col7, #T_e219c_row3_col8, #T_e219c_row4_col4, #T_e219c_row4_col5, #T_e219c_row4_col8, #T_e219c_row5_col2, #T_e219c_row5_col3, #T_e219c_row5_col4, #T_e219c_row5_col5, #T_e219c_row5_col6, #T_e219c_row5_col7, #T_e219c_row5_col8, #T_e219c_row6_col2, #T_e219c_row6_col3, #T_e219c_row6_col4, #T_e219c_row6_col5, #T_e219c_row6_col6, #T_e219c_row6_col7 {\n",
       "  background-color: rgba(0,169,0,0.0);\n",
       "}\n",
       "#T_e219c_row2_col4, #T_e219c_row3_col5, #T_e219c_row4_col2, #T_e219c_row4_col3, #T_e219c_row4_col6, #T_e219c_row4_col7, #T_e219c_row6_col8 {\n",
       "  background-color: rgba(0,169,0,1.0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e219c_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >num_decoder_layers</th>\n",
       "      <th class=\"col_heading level0 col1\" >num_encoder_layers</th>\n",
       "      <th class=\"col_heading level0 col2\" >correct_product_test</th>\n",
       "      <th class=\"col_heading level0 col3\" >correct_factorization_test</th>\n",
       "      <th class=\"col_heading level0 col4\" >loss_test</th>\n",
       "      <th class=\"col_heading level0 col5\" >correct_product_oos</th>\n",
       "      <th class=\"col_heading level0 col6\" >correct_factorization_oos</th>\n",
       "      <th class=\"col_heading level0 col7\" >loss_oos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e219c_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_e219c_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_e219c_row0_col1\" class=\"data row0 col1\" >2</td>\n",
       "      <td id=\"T_e219c_row0_col2\" class=\"data row0 col2\" >0.945507</td>\n",
       "      <td id=\"T_e219c_row0_col3\" class=\"data row0 col3\" >0.561779</td>\n",
       "      <td id=\"T_e219c_row0_col4\" class=\"data row0 col4\" >0.110729</td>\n",
       "      <td id=\"T_e219c_row0_col5\" class=\"data row0 col5\" >0.806152</td>\n",
       "      <td id=\"T_e219c_row0_col6\" class=\"data row0 col6\" >0.370117</td>\n",
       "      <td id=\"T_e219c_row0_col7\" class=\"data row0 col7\" >0.174067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e219c_level0_row1\" class=\"row_heading level0 row1\" >4</th>\n",
       "      <td id=\"T_e219c_row1_col0\" class=\"data row1 col0\" >4</td>\n",
       "      <td id=\"T_e219c_row1_col1\" class=\"data row1 col1\" >4</td>\n",
       "      <td id=\"T_e219c_row1_col2\" class=\"data row1 col2\" >0.962356</td>\n",
       "      <td id=\"T_e219c_row1_col3\" class=\"data row1 col3\" >0.796752</td>\n",
       "      <td id=\"T_e219c_row1_col4\" class=\"data row1 col4\" >0.057410</td>\n",
       "      <td id=\"T_e219c_row1_col5\" class=\"data row1 col5\" >0.770020</td>\n",
       "      <td id=\"T_e219c_row1_col6\" class=\"data row1 col6\" >0.521973</td>\n",
       "      <td id=\"T_e219c_row1_col7\" class=\"data row1 col7\" >0.151557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e219c_level0_row2\" class=\"row_heading level0 row2\" >6</th>\n",
       "      <td id=\"T_e219c_row2_col0\" class=\"data row2 col0\" >6</td>\n",
       "      <td id=\"T_e219c_row2_col1\" class=\"data row2 col1\" >6</td>\n",
       "      <td id=\"T_e219c_row2_col2\" class=\"data row2 col2\" >0.978142</td>\n",
       "      <td id=\"T_e219c_row2_col3\" class=\"data row2 col3\" >0.854736</td>\n",
       "      <td id=\"T_e219c_row2_col4\" class=\"data row2 col4\" >0.045719</td>\n",
       "      <td id=\"T_e219c_row2_col5\" class=\"data row2 col5\" >0.920898</td>\n",
       "      <td id=\"T_e219c_row2_col6\" class=\"data row2 col6\" >0.666016</td>\n",
       "      <td id=\"T_e219c_row2_col7\" class=\"data row2 col7\" >0.128519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e219c_level0_row3\" class=\"row_heading level0 row3\" >5</th>\n",
       "      <td id=\"T_e219c_row3_col0\" class=\"data row3 col0\" >8</td>\n",
       "      <td id=\"T_e219c_row3_col1\" class=\"data row3 col1\" >8</td>\n",
       "      <td id=\"T_e219c_row3_col2\" class=\"data row3 col2\" >0.979053</td>\n",
       "      <td id=\"T_e219c_row3_col3\" class=\"data row3 col3\" >0.860049</td>\n",
       "      <td id=\"T_e219c_row3_col4\" class=\"data row3 col4\" >0.047189</td>\n",
       "      <td id=\"T_e219c_row3_col5\" class=\"data row3 col5\" >0.943848</td>\n",
       "      <td id=\"T_e219c_row3_col6\" class=\"data row3 col6\" >0.691406</td>\n",
       "      <td id=\"T_e219c_row3_col7\" class=\"data row3 col7\" >0.123346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e219c_level0_row4\" class=\"row_heading level0 row4\" >0</th>\n",
       "      <td id=\"T_e219c_row4_col0\" class=\"data row4 col0\" >10</td>\n",
       "      <td id=\"T_e219c_row4_col1\" class=\"data row4 col1\" >10</td>\n",
       "      <td id=\"T_e219c_row4_col2\" class=\"data row4 col2\" >0.979356</td>\n",
       "      <td id=\"T_e219c_row4_col3\" class=\"data row4 col3\" >0.861415</td>\n",
       "      <td id=\"T_e219c_row4_col4\" class=\"data row4 col4\" >0.047529</td>\n",
       "      <td id=\"T_e219c_row4_col5\" class=\"data row4 col5\" >0.933594</td>\n",
       "      <td id=\"T_e219c_row4_col6\" class=\"data row4 col6\" >0.694824</td>\n",
       "      <td id=\"T_e219c_row4_col7\" class=\"data row4 col7\" >0.119473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e219c_level0_row5\" class=\"row_heading level0 row5\" >1</th>\n",
       "      <td id=\"T_e219c_row5_col0\" class=\"data row5 col0\" >12</td>\n",
       "      <td id=\"T_e219c_row5_col1\" class=\"data row5 col1\" >12</td>\n",
       "      <td id=\"T_e219c_row5_col2\" class=\"data row5 col2\" >0.974954</td>\n",
       "      <td id=\"T_e219c_row5_col3\" class=\"data row5 col3\" >0.857468</td>\n",
       "      <td id=\"T_e219c_row5_col4\" class=\"data row5 col4\" >0.048018</td>\n",
       "      <td id=\"T_e219c_row5_col5\" class=\"data row5 col5\" >0.912598</td>\n",
       "      <td id=\"T_e219c_row5_col6\" class=\"data row5 col6\" >0.677246</td>\n",
       "      <td id=\"T_e219c_row5_col7\" class=\"data row5 col7\" >0.124622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e219c_level0_row6\" class=\"row_heading level0 row6\" >2</th>\n",
       "      <td id=\"T_e219c_row6_col0\" class=\"data row6 col0\" >16</td>\n",
       "      <td id=\"T_e219c_row6_col1\" class=\"data row6 col1\" >16</td>\n",
       "      <td id=\"T_e219c_row6_col2\" class=\"data row6 col2\" >0.974803</td>\n",
       "      <td id=\"T_e219c_row6_col3\" class=\"data row6 col3\" >0.857013</td>\n",
       "      <td id=\"T_e219c_row6_col4\" class=\"data row6 col4\" >0.048752</td>\n",
       "      <td id=\"T_e219c_row6_col5\" class=\"data row6 col5\" >0.757812</td>\n",
       "      <td id=\"T_e219c_row6_col6\" class=\"data row6 col6\" >0.595703</td>\n",
       "      <td id=\"T_e219c_row6_col7\" class=\"data row6 col7\" >0.158729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21fd1173730>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_hyperparameter(metric_df, ['num_encoder_layers', 'num_decoder_layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-86e3364fd793>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = metric_df[metric_df['dropout']==.1][hyperparam_cols].to_dict(orient='index')[14]\n",
    "# del values['base']\n",
    "# del values['norm_first']\n",
    "# del values['effective_train_batch_size']\n",
    "# del values['attn_weight_xavier_init_constant']\n",
    "# del values['dropout']\n",
    "# del values['extra_positional_encoding_relative_decoder_mha']\n",
    "# del values['positional_encoding_query_key_only']\n",
    "# del values['repeat_positional_encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nonunique_hparams(df):\n",
    "    for c in hyperparam_cols:\n",
    "        if not c in df:\n",
    "            continue\n",
    "        if df[c].nunique()==1:\n",
    "            df.drop(c, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_identifier_for_hparam_sets(df, hparam_cols, values, col_name='id'):\n",
    "#     df['groupby_hps'] = df[hparam_cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "#     df.sort('groupby_hps')\n",
    "    \n",
    "#     df[col_name] = values[0]\n",
    "#     marker_counter = 0\n",
    "#     for i in range(1, grouped.shape[0]):\n",
    "#         this_row_hps = grouped.iloc[i]['groupby_hps'].to_dict()\n",
    "#         prev_row_hps = grouped.iloc[i-1]['groupby_hps'].to_dict()\n",
    "#         if not this_row_hps==prev_row_hps:\n",
    "#             marker_counter +=1\n",
    "#         grouped.loc[i, col_name] = valid_markers[marker_counter%len(values)]\n",
    "#         if marker_counter>=len(values):\n",
    "#             warnings.warn(f'More unique combinations of hyperparams found than unique {col_name}; {col_name} will not be unique')\n",
    "#     return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_markers = ['o', 's', '*', 'p', 'D']\n",
    "def ablate_loss_hist_plot(metric_df, hparams, plot_metric = 'test_loss'):\n",
    "#     def add_marker()\n",
    "    if isinstance(hparams, str):\n",
    "        hparams = [hparams]\n",
    "    groupby_hps = [c for c in hyperparam_cols if not c in hparams]\n",
    "    grouped = metric_df.groupby(groupby_hps)\n",
    "    grouped = grouped.filter(lambda x: len(x) > 1).reset_index(drop=True)\n",
    "    display(grouped)\n",
    "    grouped = add_identifier_for_hparam_sets(grouped, groupby_hps, valid_markers, col_name='marker')\n",
    "    display(grouped)\n",
    "    \n",
    "#     grouped['marker'] = valid_markers[0]\n",
    "#     marker_counter = 0\n",
    "#     for i in range(1, grouped.shape[0]):\n",
    "#         this_row_hps = grouped.iloc[i][groupby_hps].to_dict()\n",
    "#         prev_row_hps = grouped.iloc[i-1][groupby_hps].to_dict()\n",
    "#         if not this_row_hps==prev_row_hps:\n",
    "#             marker_counter +=1\n",
    "#         grouped.loc[i, 'marker'] = valid_markers[marker_counter%len(valid_markers)]\n",
    "    \n",
    "    grouped = drop_nonunique_hparams(grouped)\n",
    "    grouped.reset_index(drop=True, inplace=True)\n",
    "    remaining_hparams = [c for c in list(grouped) if c in hyperparam_cols]\n",
    "    \n",
    "    \n",
    "    \n",
    "    grouped['mpl_label'] = grouped[remaining_hparams].apply(lambda x: ', '.join([f\"{c}: {x[c]}\" for c in remaining_hparams]),axis=1)\n",
    "\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(8,8)\n",
    "    marker_idx = 0\n",
    "    for i in range(grouped.shape[0]):\n",
    "        row = grouped.iloc[i]\n",
    "        loss_hist_list[i].plot(x='step', y=plot_metric, label = row['mpl_label'], ax=ax, marker=row['marker'])\n",
    "\n",
    "    \n",
    "    plt.ylabel(plot_metric)\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This plot looks wrong to me!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ablate_loss_hist_plot(metric_df, 'base', 'oos_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ablate_loss_hist_plot(metric_df, ['weight_decay', 'optimizer'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablate_loss_hist_plot(metric_df, ['effective_train_batch_size', 'num_warmup_steps'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablate_loss_hist_plot(metric_df, ['dropout'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are some hard numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_factor_df_list)):\n",
    "    test_factor_df_list[i]['id'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factor_dfs = pd.concat(test_factor_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_factor_dfs(n, metric = 'loss_oos', descending=False):\n",
    "    ordering = np.argsort(metric_df[metric]).values\n",
    "    if descending:\n",
    "        ordering = ordering[::-1]\n",
    "        \n",
    "    top_indicies = set(list(ordering[:n]))\n",
    "    \n",
    "    all_factor_dfs['keep'] = all_factor_dfs.apply(lambda x: x['id'] in top_indicies, axis=1)\n",
    "    subs_df = all_factor_dfs[all_factor_dfs['keep']].copy()\n",
    "    \n",
    "    all_factor_dfs.drop('keep', axis=1, inplace=True)\n",
    "    subs_df.drop('keep', axis=1, inplace=True)\n",
    "    \n",
    "    return subs_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_n_factor_dfs(3, 'correct_factorization_oos', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_correctly_factored = all_factor_dfs.groupby(['input_num', 'id']).agg({'correct_factorization' : 'any'}).groupby(['input_num']).agg({'correct_factorization' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_correctly_factored['correct_factorization'].hist(bins=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_correctly_factored[num_times_correctly_factored['correct_factorization']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_correctly_factored[num_times_correctly_factored['correct_factorization']==0].reset_index()['input_num'].apply(lambda x: x % 2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
