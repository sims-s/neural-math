{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import warnings\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics to look at:\n",
    "* Metrics over time\n",
    "* Comparison of Hyperparameters\n",
    "* Metrics at the beginning of training:\n",
    "    * Why does scaling embeddings screw things up so much? Even when it's just the initialization --> must be an issue at the beginning of training, could be something interesting to look into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_colwidth', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/factorization/2^22/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoints', 'config.yaml', 'test_1', 'test_2', 'test_3', 'test_4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = []\n",
    "test_metric_list = []\n",
    "oos_metric_list = []\n",
    "loss_hist_list = []\n",
    "test_factor_df_list = []\n",
    "\n",
    "\n",
    "def find_metrics_in_dir(base_path):\n",
    "    for f in os.listdir(base_path):\n",
    "        if f in ['300s', '.gitignore', 'addition_baselines', 'addition_small_as_possible']: continue\n",
    "        print(f)\n",
    "        subdir_path = base_path + f + '/'\n",
    "        \n",
    "        if os.path.exists(subdir_path + 'checkpoints/'):\n",
    "            config_path = subdir_path + 'config.yaml'\n",
    "            metrics_path = subdir_path + 'metrics_test.json'\n",
    "            metrics_oos_path = subdir_path + 'metrics_oos.json'\n",
    "            loss_hist_path = subdir_path + 'loss_hist.csv'\n",
    "            \n",
    "            if not os.path.exists(metrics_path):\n",
    "                print(f'FAILED TO LOAD {f}')\n",
    "                continue\n",
    "\n",
    "            config_list.append(load_yaml(config_path))\n",
    "            test_metric_list.append(load_json(metrics_path))\n",
    "            oos_metric_list.append(load_json(metrics_oos_path))\n",
    "            loss_hist_list.append(pd.read_csv(loss_hist_path))\n",
    "            \n",
    "            test_factor_df_list.append(pd.read_csv(subdir_path + 'pred_df_test.csv'))\n",
    "            \n",
    "        elif os.path.isdir(subdir_path) and not f=='checkpoints':\n",
    "            find_metrics_in_dir(subdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints\n",
      "config.yaml\n",
      "test_1\n",
      "FAILED TO LOAD test_1\n",
      "test_2\n",
      "FAILED TO LOAD test_2\n",
      "test_3\n",
      "FAILED TO LOAD test_3\n",
      "test_4\n",
      "FAILED TO LOAD test_4\n"
     ]
    }
   ],
   "source": [
    "find_metrics_in_dir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2, 2, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config_list), len(test_metric_list), len(oos_metric_list), len(loss_hist_list), len(test_factor_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_config(config_item):\n",
    "    expanded = {}\n",
    "    expanded['base'] = config_item['data']['base']\n",
    "    expanded['train_data'] = config_item['data']['train_path']\n",
    "    expanded['train_batch_size'] = config_item['loader']['train']['batch_size']\n",
    "    for k, v in config_item['model_args'].items():\n",
    "        expanded[k] = v\n",
    "    if not 'embedding_initialization' in expanded:\n",
    "        expanded['embedding_initialization'] = 'normal'\n",
    "    expanded['optimizer'] = config_item['optimizer']['type']\n",
    "    for k, v in config_item['optimizer']['opt_args'].items():\n",
    "        expanded[k] = v\n",
    "    if not 'weight_decay' in expanded:\n",
    "        expanded['weight_decay'] = 0\n",
    "    expanded['gradient_accumulation_steps'] = config_item['optimizer']['gradient_accumulation_steps']\n",
    "#     handle all model args\n",
    "#     handle all opt args\n",
    "    try:\n",
    "        expanded['num_warmup_steps'] = config_item['scheduler']['n_warmup_steps']\n",
    "    except KeyError:\n",
    "        expanded['num_warmup_steps'] = config_item['scheduler']['scheduler_args']['num_warmup_steps']\n",
    "    expanded['nb_epochs'] = config_item['scheduler']['nb_epochs']\n",
    "    expanded['max_grad_norm'] = config_item['optimizer']['max_grad_norm']\n",
    "    \n",
    "    expanded['effective_train_batch_size'] = expanded['train_batch_size'] * expanded['gradient_accumulation_steps']\n",
    "    del expanded['train_batch_size']\n",
    "    del expanded['gradient_accumulation_steps']\n",
    "    \n",
    "    \n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [flatten_config(c) for c in config_list]\n",
    "config_df = pd.DataFrame.from_dict(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_metric_list[0]['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nice_metrics(metric_list, suffix = '', just_factorization=True):\n",
    "    if just_factorization:\n",
    "        correct = pd.DataFrame.from_dict([{'correct_factorization' : l['correct']['correct_factorization']} for l in metric_list])\n",
    "    else:\n",
    "        correct = pd.DataFrame.from_dict([l['correct'] for l in metric_list])\n",
    "    n_beams = pd.DataFrame.from_dict([l['meta']['n_beams'] for l in metric_list])\n",
    "    \n",
    "    def get_loss(metric_dict):\n",
    "        try:\n",
    "            return metric_dict['loss']\n",
    "        except KeyError:\n",
    "            return metric_dict['test_loss']\n",
    "        \n",
    "    loss_df = pd.DataFrame.from_dict([get_loss(l) for l in metric_list])\n",
    "    \n",
    "    n_beams.columns = ['n_beams']\n",
    "    loss_df.columns = ['loss']\n",
    "    to_return = [correct, n_beams, loss_df]\n",
    "    if suffix:\n",
    "        for tmp_df in to_return:\n",
    "            tmp_df.columns = [str(c) + f'_{suffix}' for c in tmp_df.columns]\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([config_df] + get_nice_metrics(test_metric_list, 'test') + get_nice_metrics(oos_metric_list, 'oos') + \n",
    "                   [pd.DataFrame({'loss_hist' : loss_hist_list})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = ['loss_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (merged['n_beams_test']==merged['n_beams_oos']).all()\n",
    "merged['n_beams'] = merged['n_beams_oos']\n",
    "merged.drop(['n_beams_test', 'n_beams_oos'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all confiuraiton columns that have no variantion b/c that's not super helpful\n",
    "drop_cols = []\n",
    "for c in list(config_df) + ['n_beams']:\n",
    "    if not c in merged: continue\n",
    "    if merged[c].nunique()==1:\n",
    "        drop_cols.append(c)\n",
    "metric_df_loss_hist = merged.drop(drop_cols, axis=1)\n",
    "metric_df = metric_df_loss_hist.copy()\n",
    "metric_df.drop('loss_hist', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['correct_factorization', 'loss']\n",
    "splits = ['test', 'oos']\n",
    "metrics_full = [f'{metric}_{split}' for split in splits for metric in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correlation_plot(metric_df, x, y, clip_outliers = True):\n",
    "    x_col = metric_df[x]\n",
    "    y_col = metric_df[y]\n",
    "    \n",
    "    is_outlier = (x_col > x_col.mean() + x_col.std() * 5) | (x_col < x_col.mean() - x_col.std() * 5)\n",
    "    x_col = x_col[~is_outlier]\n",
    "    y_col = y_col[~is_outlier]\n",
    "    \n",
    "    metric_df[~is_outlier].plot.scatter(x=x, y=y)\n",
    "    \n",
    "    m, b = np.polyfit(x_col, y_col, 1)\n",
    "    ax = plt.gca()\n",
    "    x_vals = np.array(ax.get_xlim())\n",
    "    plt.plot(x_vals, m*x_vals + b, color='black', linestyle='--', alpha=.5)\n",
    "    plt.title(f'Correlation between {x} and {y}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at some correlations\n",
    "#### In general:\n",
    "* Correlation using correct_product is not very strong in many places.\n",
    "    * I think this makes sense because of the issue where when the model is unable to factor the number, it returns the number because it could be prime\n",
    "\n",
    "#### Test metrics vs OoS Metrics:\n",
    "* Test loss is very correlated with Oos. Same for factorization, but not quite as much\n",
    "\n",
    "#### Is loss correlated of correct factorizatoin?\n",
    "* Yes! Loss is very correlated with correct factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in metrics:\n",
    "    make_correlation_plot(metric_df, x=m + f'_{splits[0]}', y=m + f'_{splits[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in metrics:\n",
    "    if m == 'loss' : continue\n",
    "    for s in splits:\n",
    "        make_correlation_plot(metric_df, x=f'loss_{s}', y = f'{m}_{s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_cols = [c for c in metric_df.columns if not c in metrics_full + ignore_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hyperparam_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_lower_is_better = {'loss'}\n",
    "\n",
    "def style_col_axis_1(col, n_highlight=3, col_id_name=\"id\"):\n",
    "#     if col.name==col_id_name:\n",
    "#         return [f'background-color: {col[i]}' for i in range(len(col))]\n",
    "    if len(set(col.name.split('_')).intersection(metrics_lower_is_better)):\n",
    "        top_indicies = np.argsort(col.values)[:n_highlight]\n",
    "    else:\n",
    "        top_indicies = np.argsort(col.values)[::-1][:n_highlight]\n",
    "    alphas = np.zeros(len(col))\n",
    "    for i in range(len(top_indicies)):\n",
    "        alphas[top_indicies[i]] = 1 - i/n_highlight\n",
    "    return np.array([f'background-color: rgba(0,169,0,{alphas[i]})' for i in range(len(col))])\n",
    "\n",
    "def style_df(df, ablated_hparams = None, n_highlight=3, col_id_name=\"color\"):\n",
    "    if ablated_hparams is None:\n",
    "        ablated_hparams = []\n",
    "    to_return = np.zeros_like(df.values, dtype=np.object)\n",
    "    df_cols = df.columns\n",
    "#     display(df)\n",
    "    for i in range(df.shape[1]):\n",
    "        this_col = df_cols[i]\n",
    "        if this_col in ablated_hparams: continue\n",
    "        if this_col in hyperparam_cols:\n",
    "            to_return[:,i] = np.array([f'background-color: {df[col_id_name].iloc[j]}' for j in range(df.shape[0])])\n",
    "#             print(to_return)\n",
    "        else:\n",
    "            to_return[:,i] = style_col_axis_1(df.iloc[:,i], n_highlight, col_id_name)\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_mapper = {\n",
    "    'num_heads' : 8\n",
    "}\n",
    "\n",
    "for k, v in default_mapper.items():\n",
    "    if k in metric_df:\n",
    "        metric_df[k] = metric_df[k].fillna(v)\n",
    "        metric_df_loss_hist[k] = metric_df_loss_hist[k].fillna(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_df.sort_values(hyperparam_cols).style.apply(style_col_axis_1, axis=0, subset=metrics_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_identifier_for_hparam_sets(df, hparam_cols, values, col_name='color'):\n",
    "    df['groupby_hps'] = df[hparam_cols].apply(lambda x: '_'.join([str(y) for y in x]), axis=1)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df[col_name] = values[0]\n",
    "    value_counter = 0\n",
    "    df.sort_values('groupby_hps', inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    for i in range(1, df.shape[0]):\n",
    "        this_row_hps = df.iloc[i]['groupby_hps']\n",
    "        prev_row_hps = df.iloc[i-1]['groupby_hps']\n",
    "        if not this_row_hps==prev_row_hps:\n",
    "            value_counter +=1\n",
    "#         print(i, col_name, values[value_counter])\n",
    "        df.loc[i, col_name] = values[value_counter%len(values)]\n",
    "        if value_counter>=len(values):\n",
    "            warnings.warn(f'More unique combinations of hyperparams found than unique {col_name}; {col_name} will not be unique')\n",
    "    df.drop('groupby_hps', axis=1, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nonunique_hparams(df):\n",
    "    for c in hyperparam_cols:\n",
    "        if not c in df:\n",
    "            continue\n",
    "        if df[c].nunique()==1:\n",
    "            df.drop(c, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfReturnDict(dict):\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self:\n",
    "            return super().__getitem__(idx)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    'rgba(255,0,0,.5)', \n",
    "    'rgba(0,255,0,.5)',\n",
    "    'rgba(0,0,255,.5)',\n",
    "    'rgba(48,213,200,.5)', \n",
    "    'rgba(159,43,104,.5)', \n",
    "    'rgba(230,190,138,.5)',\n",
    "    'rgba(123,255,0)'\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "def ablate_hyperparameter(metric_df, hparams, show_specific_hparams=None, show_all_other_hparams=False, show_if_nonconstant=True, sort_by='other'):\n",
    "    if not sort_by in ['inputs', 'other']:\n",
    "        raise ValueError('expected sortby to be inputs or other')\n",
    "    id_col_name = 'color'\n",
    "    if isinstance(hparams, str):\n",
    "        hparams = [hparams]\n",
    "    hparams = hparams\n",
    "    groupby_hps = [c for c in hyperparam_cols if not c in hparams]\n",
    "    grouped = metric_df.groupby(groupby_hps)\n",
    "    grouped = grouped.filter(lambda x: len(x) > 1)\n",
    "    grouped = add_identifier_for_hparam_sets(grouped, groupby_hps, colors, id_col_name)\n",
    "\n",
    "    \n",
    "    # Have a list of params want to show\n",
    "    # Want to show just ones that have unique values\n",
    "    # Show all of them\n",
    "    \n",
    "    if show_specific_hparams:\n",
    "          if isinstance(show_specific_hparams, str):\n",
    "            show_specific_hparams = [show_specific_hparams]\n",
    "    else:\n",
    "        show_specific_hparams = []\n",
    "    \n",
    "    show_cols = [c for c in grouped.columns if not (c in groupby_hps) or c==id_col_name]\n",
    "    for c in groupby_hps:\n",
    "        if (show_all_other_hparams) or (c in show_specific_hparams) or (show_if_nonconstant and grouped[c].nunique() > 1):\n",
    "            show_cols.append(c)\n",
    "            \n",
    "    grouped = grouped[[c for c in show_cols]]\n",
    "    if sort_by=='inputs':\n",
    "        grouped.sort_values(hparams, inplace=True)\n",
    "        grouped.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "        \n",
    "    return grouped.style.hide_columns([id_col_name]).apply(style_df, axis=None, ablated_hparams = hparams, n_highlight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_markers = ['o', 's', '*', 'p', 'D']\n",
    "def ablate_loss_hist_plot(metric_df, hparams, plot_metric = 'test_loss', max_imgs_per_row = 3, name_mapper = None):\n",
    "    if not name_mapper:\n",
    "        name_mapper = {}\n",
    "    name_mapper = SelfReturnDict(name_mapper)\n",
    "    if isinstance(hparams, str):\n",
    "        hparams = [hparams]\n",
    "    groupby_hps = [c for c in hyperparam_cols if not c in hparams + ['loss_hist']]\n",
    "    if not groupby_hps:\n",
    "        grouped = metric_df\n",
    "    else:\n",
    "        grouped = metric_df.copy().groupby(groupby_hps)\n",
    "        grouped = grouped.filter(lambda x: len(x) > 1).reset_index(drop=True)\n",
    "    grouped = add_identifier_for_hparam_sets(grouped, groupby_hps, valid_markers, col_name='marker')\n",
    "    grouped.sort_values(hparams, inplace=True)\n",
    "    grouped.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    \n",
    "    grouped = drop_nonunique_hparams(grouped)\n",
    "    grouped.reset_index(drop=True, inplace=True)\n",
    "    remaining_hparams = [c for c in list(grouped) if c in hyperparam_cols]\n",
    "    remaining_noninput_hparams = [p for p in remaining_hparams if not p in hparams and not p=='loss_hist']\n",
    "    \n",
    "    other_hyperparam_values = grouped[remaining_noninput_hparams].apply(lambda x: ', '.join([str(y) for y in x]), axis=1).unique().tolist()\n",
    "    n_remaining_noninput_vals = len(other_hyperparam_values)\n",
    "    \n",
    "    if n_remaining_noninput_vals > 1:\n",
    "        n_cols = min(max_imgs_per_row, n_remaining_noninput_vals)\n",
    "        n_rows = n_remaining_noninput_vals // n_cols + int(bool(n_remaining_noninput_vals % n_cols))\n",
    "        fig, ax = plt.subplots(n_rows, n_cols)\n",
    "        if ax.ndim==1:\n",
    "            ax = np.array([ax])\n",
    "        idx_to_ax = lambda idx: ax[idx // n_cols, idx % n_cols]\n",
    "        \n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "        ax = plt.gca()\n",
    "        n_rows = 1\n",
    "        n_cols = 1\n",
    "        def _idx_to_row_col(idx):\n",
    "            assert idx == 0\n",
    "            return ax\n",
    "        idx_to_ax = lambda idx: _idx_to_row_col(idx)\n",
    "    \n",
    "    def add_plot_to_ax(sub_df, ax, title):\n",
    "        for j in range(sub_df.shape[0]):\n",
    "            row = sub_df.iloc[j]\n",
    "            loss_hist = row['loss_hist']\n",
    "            loss_hist.plot(x='step', y=plot_metric, ax=ax, label = row['mpl_label'], marker=row['marker'])\n",
    "        ax.set_ylabel(plot_metric)\n",
    "        ax.legend()\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    grouped['mpl_label'] = grouped[remaining_hparams].apply(lambda x: ', '.join([f\"{name_mapper[c]}: {x[c]}\" for c in hparams]),axis=1)\n",
    "    fig.set_size_inches(6*n_cols,  6* n_rows)\n",
    "    if len(remaining_noninput_hparams):\n",
    "        for i, (name, sub_grouped_df) in enumerate(grouped.groupby(remaining_noninput_hparams)):\n",
    "            if not isinstance(name, tuple):\n",
    "                name = (name,)\n",
    "            plot_title = pprint.pformat({hp : val for hp, val in zip(remaining_noninput_hparams, name)})\n",
    "            add_plot_to_ax(sub_grouped_df, idx_to_ax(i), title=plot_title)\n",
    "    else:\n",
    "        add_plot_to_ax(grouped, idx_to_ax(0), ', '.join(hparams))\n",
    "    \n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Ablate\" some hyperparamaters:\n",
    "* For a given set of hyperparamaters, find sets of runs where all other hyperparameters are the same, but these are varied\n",
    "* Plot a loss hist curve for the same collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display(ablate_hyperparameter(metric_df, 'max_grad_norm', sort_by='other'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, 'max_grad_norm')\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, 'max_grad_norm', 'oos_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, 'base', sort_by='other'))\n",
    "display(ablate_hyperparameter(metric_df, 'base', sort_by='inputs'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, 'base')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablate_loss_hist_plot(metric_df_loss_hist, 'base', plot_metric='oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Encoder/Decoder Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['num_encoder_layers', 'num_decoder_layers'], sort_by='inputs'))\n",
    "display(ablate_hyperparameter(metric_df, ['num_encoder_layers', 'num_decoder_layers'], sort_by='other'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['num_encoder_layers', 'num_decoder_layers'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['num_encoder_layers', 'num_decoder_layers'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['positional_encoding_type', 'repeat_positional_encoding', 'positional_encoding_query_key_only'], \n",
    "                      sort_by='other'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['positional_encoding_type', 'repeat_positional_encoding', 'positional_encoding_query_key_only'],\n",
    "                     name_mapper = {\n",
    "    'positional_encoding_type' : 'PEType',\n",
    "    'repeat_positional_encoding' : 'RepeatPE',\n",
    "    'positional_encoding_query_key_only' : 'PE_QK_Only'\n",
    "})\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['positional_encoding_type', 'repeat_positional_encoding', 'positional_encoding_query_key_only'], 'oos_loss',\n",
    "                     name_mapper = {\n",
    "    'positional_encoding_type' : 'PEType',\n",
    "    'repeat_positional_encoding' : 'RepeatPE',\n",
    "    'positional_encoding_query_key_only' : 'PE_QK_Only'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['learn_positional_encoding'], sort_by='inputs'))\n",
    "display(ablate_hyperparameter(metric_df, ['learn_positional_encoding'], sort_by='other'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['learn_positional_encoding'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['learn_positional_encoding'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, 'shared_embeddings', show_specific_hparams='positional_encoding_type'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, 'shared_embeddings')\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, 'shared_embeddings', 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['extra_positional_encoding_relative_decoder_mha'], sort_by='inputs'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['extra_positional_encoding_relative_decoder_mha'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['extra_positional_encoding_relative_decoder_mha'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed Dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['embed_dim'], sort_by='inputs'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist[metric_df_loss_hist['embed_dim'] < 1024], ['embed_dim'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist[metric_df_loss_hist['embed_dim'] < 1024], ['embed_dim'], 'oos_loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['dropout'], sort_by='inputs'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['dropout'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['dropout'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norm First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, 'norm_first'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['norm_first'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['norm_first'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['weight_decay']))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['weight_decay'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['weight_decay'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dim Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['dim_feedforward'], sort_by='inputs'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['dim_feedforward'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['dim_feedforward'], 'oos_loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['scale_embeddings', 'scale_embeddings_at_init'], sort_by='inputs'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['scale_embeddings', 'scale_embeddings_at_init'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['scale_embeddings', 'scale_embeddings_at_init'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Num Attention Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['num_heads'], sort_by='other'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['num_heads'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist, ['num_heads'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Num warmup steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['num_warmup_steps'], sort_by='other'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist,  ['num_warmup_steps'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist,  ['num_warmup_steps'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nb Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['nb_epochs'], sort_by='other'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist,  ['nb_epochs'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist,  ['nb_epochs'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['nb_epochs'], sort_by='other'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist,  ['nb_epochs', 'weight_decay'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist,  ['nb_epochs', 'weight_decay'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ablate_hyperparameter(metric_df, ['nb_epochs'], sort_by='other'))\n",
    "ablate_loss_hist_plot(metric_df_loss_hist,  ['nb_epochs', 'dropout'])\n",
    "ablate_loss_hist_plot(metric_df_loss_hist,  ['nb_epochs', 'dropout'], 'oos_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are some hard numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_factor_df_list)):\n",
    "    test_factor_df_list[i]['id'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factor_dfs = pd.concat(test_factor_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_factor_dfs(n, metric = 'loss_oos', descending=False):\n",
    "    ordering = np.argsort(metric_df[metric]).values\n",
    "    if descending:\n",
    "        ordering = ordering[::-1]\n",
    "        \n",
    "    top_indicies = set(list(ordering[:n]))\n",
    "    \n",
    "    all_factor_dfs['keep'] = all_factor_dfs.apply(lambda x: x['id'] in top_indicies, axis=1)\n",
    "    subs_df = all_factor_dfs[all_factor_dfs['keep']].copy()\n",
    "    \n",
    "    all_factor_dfs.drop('keep', axis=1, inplace=True)\n",
    "    subs_df.drop('keep', axis=1, inplace=True)\n",
    "    \n",
    "    return subs_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_n_factor_dfs(3, 'correct_factorization_oos', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_correctly_factored = all_factor_dfs.groupby(['input_num', 'id']).agg({'correct_factorization' : 'any'}).groupby(['input_num']).agg({'correct_factorization' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_correctly_factored['correct_factorization'].hist(bins=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_correctly_factored[num_times_correctly_factored['correct_factorization']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_correctly_factored[num_times_correctly_factored['correct_factorization']==0].reset_index()['input_num'].apply(lambda x: x % 2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This plot looks wrong to me!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, _ in pd.DataFrame({'a' : [1,2,3], 'b' : [4,5,6], 'c' : [7,8,9]}).groupby(['a','b']):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
